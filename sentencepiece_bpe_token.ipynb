{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import SentencePieceBPETokenizer\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = \"./demo_1M.txt\"\n",
    "with open(txt_path, 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "special_tokens = [\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<cls>\", \"<sep>\", \"<mask>\"]\n",
    "tk_tokenizer = SentencePieceBPETokenizer()\n",
    "\n",
    "tk_tokenizer.train_from_iterator(\n",
    "    text,\n",
    "    vocab_size=4000,\n",
    "    min_frequency=1,\n",
    "    show_progress=True,\n",
    "    special_tokens=special_tokens\n",
    ")\n",
    "\n",
    "tk_tokenizer.save('tokenizer.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: আমি বাংলায় ক্রিকেট খেলতে ভালোবাসি।\n",
      "Modified Text: আমি বাংলায় [ক্র]িকেট খেলতে ভালোবাসি।\n"
     ]
    }
   ],
   "source": [
    "original_text = \"আমি বাংলায় ক্রিকেট খেলতে ভালোবাসি।\"\n",
    "modified_text = original_text.replace(\"ক্র\", \"[ক্র]\")\n",
    "\n",
    "print(\"Original Text:\", original_text)\n",
    "print(\"Modified Text:\", modified_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sentencepiece BPE tokenizer Help\n",
    "\n",
    "# files: Union[str, List[str]],\n",
    "# vocab_size: int = 30000,\n",
    "# min_frequency: int = 2,\n",
    "# special_tokens: List[Union[str, AddedToken]] = [\"<unk>\"],\n",
    "# limit_alphabet: int = 1000,\n",
    "# initial_alphabet: List[str] = [],\n",
    "# show_progress: bool = True,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁\\n',\n",
       " 'স',\n",
       " 'া',\n",
       " 'ভ',\n",
       " 'া',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'র',\n",
       " '▁ক',\n",
       " 'ব',\n",
       " 'ি',\n",
       " 'র',\n",
       " 'প',\n",
       " 'ু',\n",
       " 'র',\n",
       " '▁ব',\n",
       " 'া',\n",
       " 'ণ',\n",
       " 'ি',\n",
       " 'জ',\n",
       " '্',\n",
       " 'য',\n",
       " 'ি',\n",
       " 'ক',\n",
       " '▁এ',\n",
       " 'ল',\n",
       " 'া',\n",
       " 'ক',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁ন',\n",
       " 'ি',\n",
       " 'জ',\n",
       " 'স',\n",
       " '্',\n",
       " 'ব',\n",
       " '▁ফ',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " 'র',\n",
       " 'ি',\n",
       " 'ত',\n",
       " 'ে',\n",
       " '▁হ',\n",
       " 'য',\n",
       " '়',\n",
       " 'ে',\n",
       " '▁গ',\n",
       " 'ে',\n",
       " 'ল',\n",
       " '▁ই',\n",
       " 'উ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ট',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '▁প',\n",
       " '্',\n",
       " 'র',\n",
       " 'ড',\n",
       " 'া',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " 'স',\n",
       " '▁(',\n",
       " 'ব',\n",
       " 'ি',\n",
       " 'ড',\n",
       " 'ি',\n",
       " ')',\n",
       " '▁ল',\n",
       " 'ি',\n",
       " 'ঃ',\n",
       " '▁এ',\n",
       " 'র',\n",
       " '▁দ',\n",
       " 'ি',\n",
       " 'ন',\n",
       " 'ব',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'প',\n",
       " 'ী',\n",
       " '▁স',\n",
       " 'ে',\n",
       " 'ল',\n",
       " 'স',\n",
       " '▁ক',\n",
       " 'ন',\n",
       " 'ফ',\n",
       " 'া',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '্',\n",
       " 'স',\n",
       " '।',\n",
       " '▁ক',\n",
       " 'ন',\n",
       " 'ফ',\n",
       " 'া',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '্',\n",
       " 'স',\n",
       " 'ট',\n",
       " 'ি',\n",
       " '▁অ',\n",
       " 'ন',\n",
       " 'ু',\n",
       " 'ষ',\n",
       " '্',\n",
       " 'ঠ',\n",
       " 'ি',\n",
       " 'ত',\n",
       " '▁হ',\n",
       " 'য',\n",
       " '়',\n",
       " '▁শ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ব',\n",
       " 'া',\n",
       " 'র',\n",
       " ',',\n",
       " '▁১',\n",
       " '১',\n",
       " 'ই',\n",
       " '▁ম',\n",
       " 'া',\n",
       " 'র',\n",
       " '্',\n",
       " 'চ',\n",
       " ',',\n",
       " '▁স',\n",
       " 'া',\n",
       " 'র',\n",
       " 'া',\n",
       " '▁দ',\n",
       " 'ে',\n",
       " 'শ',\n",
       " '▁থ',\n",
       " 'ে',\n",
       " 'ক',\n",
       " 'ে',\n",
       " '▁প',\n",
       " '্',\n",
       " 'র',\n",
       " 'া',\n",
       " 'য',\n",
       " '়',\n",
       " '▁৩',\n",
       " '১',\n",
       " '০',\n",
       " '▁জ',\n",
       " 'ন',\n",
       " '▁ড',\n",
       " 'ি',\n",
       " 'ল',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁এ',\n",
       " 'ই',\n",
       " '▁ক',\n",
       " 'ন',\n",
       " 'ফ',\n",
       " 'া',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '্',\n",
       " 'স',\n",
       " 'ট',\n",
       " 'ি',\n",
       " 'ত',\n",
       " 'ে',\n",
       " '▁অ',\n",
       " 'ং',\n",
       " 'শ',\n",
       " 'গ',\n",
       " '্',\n",
       " 'র',\n",
       " 'হ',\n",
       " 'ণ',\n",
       " '▁ক',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '▁এ',\n",
       " 'ব',\n",
       " 'ং',\n",
       " '▁ই',\n",
       " 'উ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ট',\n",
       " 'ে',\n",
       " 'ক',\n",
       " 'র',\n",
       " '▁ফ',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " 'র',\n",
       " 'ি',\n",
       " '▁ঘ',\n",
       " 'ু',\n",
       " 'র',\n",
       " 'ে',\n",
       " '▁দ',\n",
       " 'ে',\n",
       " 'খ',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁স',\n",
       " 'ু',\n",
       " 'য',\n",
       " 'ো',\n",
       " 'গ',\n",
       " '▁প',\n",
       " 'া',\n",
       " 'ন',\n",
       " '।',\n",
       " 'এ',\n",
       " 'স',\n",
       " 'ম',\n",
       " 'য',\n",
       " '়',\n",
       " '▁ই',\n",
       " 'উ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ট',\n",
       " 'ে',\n",
       " 'ক',\n",
       " 'র',\n",
       " '▁ব',\n",
       " '্',\n",
       " 'য',\n",
       " 'ব',\n",
       " 'স',\n",
       " '্',\n",
       " 'থ',\n",
       " 'া',\n",
       " 'প',\n",
       " 'ন',\n",
       " 'া',\n",
       " '▁প',\n",
       " 'র',\n",
       " 'ি',\n",
       " 'চ',\n",
       " 'া',\n",
       " 'ল',\n",
       " 'ক',\n",
       " ',',\n",
       " '▁ই',\n",
       " 'ঞ',\n",
       " '্',\n",
       " 'জ',\n",
       " 'ি',\n",
       " ':',\n",
       " '▁আ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'স',\n",
       " '▁আ',\n",
       " 'হ',\n",
       " 'ম',\n",
       " 'ে',\n",
       " 'দ',\n",
       " '▁ড',\n",
       " 'ি',\n",
       " 'ল',\n",
       " 'া',\n",
       " 'র',\n",
       " 'দ',\n",
       " 'ে',\n",
       " 'র',\n",
       " '▁উ',\n",
       " 'দ',\n",
       " '্',\n",
       " 'দ',\n",
       " 'ে',\n",
       " 'শ',\n",
       " 'ে',\n",
       " '▁ব',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ত',\n",
       " 'ব',\n",
       " '্',\n",
       " 'য',\n",
       " '▁র',\n",
       " 'া',\n",
       " 'খ',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '▁এ',\n",
       " 'ব',\n",
       " 'ং',\n",
       " '▁ই',\n",
       " 'উ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ট',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '▁ক',\n",
       " 'ে',\n",
       " '▁ব',\n",
       " 'া',\n",
       " 'ং',\n",
       " 'ল',\n",
       " 'া',\n",
       " 'দ',\n",
       " 'ে',\n",
       " 'শ',\n",
       " 'ে',\n",
       " 'র',\n",
       " '▁স',\n",
       " 'ে',\n",
       " 'র',\n",
       " 'া',\n",
       " '▁ই',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " '্',\n",
       " 'র',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ক',\n",
       " '▁ব',\n",
       " '্',\n",
       " 'র',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ড',\n",
       " '▁হ',\n",
       " 'ি',\n",
       " 'স',\n",
       " 'ে',\n",
       " 'ব',\n",
       " 'ে',\n",
       " '▁গ',\n",
       " 'ড',\n",
       " '়',\n",
       " 'ে',\n",
       " '▁ত',\n",
       " 'ো',\n",
       " 'ল',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁আ',\n",
       " 'শ',\n",
       " '্',\n",
       " 'ব',\n",
       " 'া',\n",
       " 'স',\n",
       " '▁ব',\n",
       " '্',\n",
       " 'য',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ত',\n",
       " '▁ক',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '।',\n",
       " '▁ই',\n",
       " 'ঞ',\n",
       " '্',\n",
       " 'জ',\n",
       " 'ি',\n",
       " ':',\n",
       " '▁আ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'স',\n",
       " '▁আ',\n",
       " 'হ',\n",
       " 'ম',\n",
       " 'ে',\n",
       " 'দ',\n",
       " ',',\n",
       " '▁জ',\n",
       " 'া',\n",
       " 'ত',\n",
       " 'ী',\n",
       " 'য',\n",
       " '়',\n",
       " '▁এ',\n",
       " 'ব',\n",
       " 'ং',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'ভ',\n",
       " 'া',\n",
       " 'গ',\n",
       " 'ী',\n",
       " 'য',\n",
       " '়',\n",
       " '▁প',\n",
       " 'র',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'য',\n",
       " '়',\n",
       " 'ে',\n",
       " '▁স',\n",
       " 'ে',\n",
       " 'র',\n",
       " 'া',\n",
       " '▁ড',\n",
       " 'ি',\n",
       " 'ল',\n",
       " 'া',\n",
       " 'র',\n",
       " 'দ',\n",
       " 'ে',\n",
       " 'র',\n",
       " '▁হ',\n",
       " 'া',\n",
       " 'ত',\n",
       " 'ে',\n",
       " '▁স',\n",
       " 'া',\n",
       " 'র',\n",
       " '্',\n",
       " 'ট',\n",
       " 'ি',\n",
       " 'ফ',\n",
       " 'ি',\n",
       " 'ক',\n",
       " 'ে',\n",
       " 'ট',\n",
       " ',',\n",
       " '▁ক',\n",
       " '্',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'স',\n",
       " '্',\n",
       " 'ট',\n",
       " '▁ও',\n",
       " '▁প',\n",
       " '্',\n",
       " 'র',\n",
       " 'া',\n",
       " 'ই',\n",
       " 'জ',\n",
       " '▁ব',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ড',\n",
       " '▁ত',\n",
       " 'ু',\n",
       " 'ল',\n",
       " 'ে',\n",
       " '▁দ',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '।',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'জ',\n",
       " 'য',\n",
       " '়',\n",
       " 'ী',\n",
       " 'র',\n",
       " 'া',\n",
       " '▁হ',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '▁র',\n",
       " 'ু',\n",
       " 'প',\n",
       " 'া',\n",
       " 'ল',\n",
       " 'ি',\n",
       " '▁ই',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " '্',\n",
       " 'র',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ক',\n",
       " '্',\n",
       " 'স',\n",
       " '▁(',\n",
       " 'জ',\n",
       " 'া',\n",
       " 'ত',\n",
       " 'ী',\n",
       " 'য',\n",
       " '়',\n",
       " '▁স',\n",
       " 'ে',\n",
       " 'র',\n",
       " 'া',\n",
       " ')',\n",
       " ',',\n",
       " '▁ল',\n",
       " 'ি',\n",
       " 'য',\n",
       " '়',\n",
       " 'া',\n",
       " '▁এ',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ট',\n",
       " 'া',\n",
       " 'র',\n",
       " 'প',\n",
       " '্',\n",
       " 'র',\n",
       " 'া',\n",
       " 'ই',\n",
       " 'জ',\n",
       " '▁(',\n",
       " 'দ',\n",
       " '্',\n",
       " 'ব',\n",
       " 'ি',\n",
       " 'ত',\n",
       " 'ী',\n",
       " 'য',\n",
       " '়',\n",
       " '▁জ',\n",
       " 'া',\n",
       " 'ত',\n",
       " 'ী',\n",
       " 'য',\n",
       " '়',\n",
       " '▁স',\n",
       " 'ে',\n",
       " 'র',\n",
       " 'া',\n",
       " ')',\n",
       " ',',\n",
       " '▁ম',\n",
       " 'দ',\n",
       " 'ি',\n",
       " 'ন',\n",
       " 'া',\n",
       " '▁ই',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " '্',\n",
       " 'র',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ক',\n",
       " '্',\n",
       " 'স',\n",
       " '▁(',\n",
       " 'ত',\n",
       " 'ৃ',\n",
       " 'ত',\n",
       " 'ী',\n",
       " 'য',\n",
       " '়',\n",
       " '▁জ',\n",
       " 'া',\n",
       " 'ত',\n",
       " 'ী',\n",
       " 'য',\n",
       " '়',\n",
       " '▁স',\n",
       " 'ে',\n",
       " 'র',\n",
       " 'া',\n",
       " ')',\n",
       " ',',\n",
       " '▁স',\n",
       " 'ু',\n",
       " 'ন',\n",
       " '্',\n",
       " 'দ',\n",
       " 'র',\n",
       " 'ব',\n",
       " 'ন',\n",
       " '▁ই',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " '্',\n",
       " 'র',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ক',\n",
       " '্',\n",
       " 'স',\n",
       " '▁(',\n",
       " 'ঢ',\n",
       " 'া',\n",
       " 'ক',\n",
       " 'া',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'ভ',\n",
       " 'া',\n",
       " 'গ',\n",
       " ')',\n",
       " ',',\n",
       " '▁আ',\n",
       " 'ল',\n",
       " 'া',\n",
       " 'উ',\n",
       " 'দ',\n",
       " '্',\n",
       " 'দ',\n",
       " 'ি',\n",
       " 'ন',\n",
       " '▁ই',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " '্',\n",
       " 'র',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ক',\n",
       " '্',\n",
       " 'স',\n",
       " '▁(',\n",
       " 'চ',\n",
       " 'ি',\n",
       " 'ট',\n",
       " 'া',\n",
       " 'গ',\n",
       " 'ং',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'ভ',\n",
       " 'া',\n",
       " 'গ',\n",
       " ')',\n",
       " ',',\n",
       " '▁শ',\n",
       " 'া',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ত',\n",
       " '▁ই',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " '্',\n",
       " 'র',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ক',\n",
       " '্',\n",
       " 'স',\n",
       " '▁(',\n",
       " 'র',\n",
       " 'া',\n",
       " 'জ',\n",
       " 'শ',\n",
       " 'া',\n",
       " 'হ',\n",
       " 'ী',\n",
       " '▁র',\n",
       " 'ং',\n",
       " 'প',\n",
       " 'ু',\n",
       " 'র',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'ভ',\n",
       " 'া',\n",
       " 'গ',\n",
       " ')',\n",
       " ',',\n",
       " '▁ন',\n",
       " 'ু',\n",
       " 'র',\n",
       " 'ু',\n",
       " 'ল',\n",
       " '▁এ',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ট',\n",
       " 'া',\n",
       " 'র',\n",
       " 'প',\n",
       " '্',\n",
       " 'র',\n",
       " 'া',\n",
       " 'ই',\n",
       " 'জ',\n",
       " '▁(',\n",
       " 'খ',\n",
       " 'ু',\n",
       " 'ল',\n",
       " 'ন',\n",
       " 'া',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'ভ',\n",
       " 'া',\n",
       " 'গ',\n",
       " ')',\n",
       " ',',\n",
       " '▁ফ',\n",
       " 'ে',\n",
       " 'য',\n",
       " '়',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁ভ',\n",
       " 'ি',\n",
       " 'উ',\n",
       " '▁ই',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ট',\n",
       " '্',\n",
       " 'র',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ক',\n",
       " '্',\n",
       " 'স',\n",
       " '▁(',\n",
       " 'ব',\n",
       " 'র',\n",
       " 'ি',\n",
       " 'শ',\n",
       " 'া',\n",
       " 'ল',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'ভ',\n",
       " 'া',\n",
       " 'গ',\n",
       " ')',\n",
       " '▁ও',\n",
       " '▁ফ',\n",
       " 'ি',\n",
       " 'ড',\n",
       " 'ব',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ক',\n",
       " '▁ক',\n",
       " 'ম',\n",
       " 'ি',\n",
       " 'উ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ক',\n",
       " 'ে',\n",
       " 'স',\n",
       " 'ন',\n",
       " '▁(',\n",
       " 'স',\n",
       " 'ি',\n",
       " 'ল',\n",
       " 'ে',\n",
       " 'ট',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'ভ',\n",
       " 'া',\n",
       " 'গ',\n",
       " ')',\n",
       " '।',\n",
       " '▁ক',\n",
       " 'ন',\n",
       " 'ফ',\n",
       " 'া',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '্',\n",
       " 'স',\n",
       " 'ট',\n",
       " 'ি',\n",
       " 'ত',\n",
       " 'ে',\n",
       " '▁আ',\n",
       " 'র',\n",
       " 'ও',\n",
       " '▁ব',\n",
       " 'ক',\n",
       " '্',\n",
       " 'ত',\n",
       " 'ব',\n",
       " '্',\n",
       " 'য',\n",
       " '▁র',\n",
       " 'া',\n",
       " 'খ',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '▁ই',\n",
       " 'উ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ট',\n",
       " 'ে',\n",
       " 'ক',\n",
       " 'ে',\n",
       " 'র',\n",
       " '▁ব',\n",
       " 'ি',\n",
       " 'জ',\n",
       " 'ন',\n",
       " 'ে',\n",
       " 'স',\n",
       " '▁ড',\n",
       " 'ে',\n",
       " 'ভ',\n",
       " 'ে',\n",
       " 'ল',\n",
       " 'প',\n",
       " 'ম',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ট',\n",
       " '▁অ',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ড',\n",
       " '▁প',\n",
       " '্',\n",
       " 'ল',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ং',\n",
       " '▁ম',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ন',\n",
       " 'ে',\n",
       " 'জ',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁এ',\n",
       " '▁ক',\n",
       " 'ে',\n",
       " '▁এ',\n",
       " 'ম',\n",
       " '▁হ',\n",
       " 'া',\n",
       " 'ম',\n",
       " 'ি',\n",
       " 'দ',\n",
       " 'ু',\n",
       " 'র',\n",
       " '▁র',\n",
       " 'হ',\n",
       " 'ম',\n",
       " 'া',\n",
       " 'ন',\n",
       " ',',\n",
       " '▁স',\n",
       " 'ে',\n",
       " 'ল',\n",
       " 'স',\n",
       " '▁অ',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ড',\n",
       " '▁ড',\n",
       " 'ে',\n",
       " 'ভ',\n",
       " 'ে',\n",
       " 'ল',\n",
       " 'প',\n",
       " 'ম',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '্',\n",
       " 'ট',\n",
       " '▁ম',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ন',\n",
       " 'ে',\n",
       " 'জ',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁এ',\n",
       " '▁ট',\n",
       " 'ি',\n",
       " '▁এ',\n",
       " 'ম',\n",
       " '▁আ',\n",
       " 'খ',\n",
       " 'ত',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁হ',\n",
       " 'ো',\n",
       " 'স',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '▁ও',\n",
       " '▁ই',\n",
       " 'উ',\n",
       " 'ন',\n",
       " 'ি',\n",
       " 'ট',\n",
       " 'ে',\n",
       " 'ক',\n",
       " 'ে',\n",
       " 'র',\n",
       " '▁স',\n",
       " 'ে',\n",
       " 'ল',\n",
       " 'স',\n",
       " '▁ম',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ন',\n",
       " 'ে',\n",
       " 'জ',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁ড',\n",
       " 'ি',\n",
       " 'ল',\n",
       " 'া',\n",
       " 'র',\n",
       " '▁চ',\n",
       " '্',\n",
       " 'য',\n",
       " 'া',\n",
       " 'ন',\n",
       " 'ে',\n",
       " 'ল',\n",
       " '▁জ',\n",
       " 'া',\n",
       " 'ক',\n",
       " 'ি',\n",
       " 'র',\n",
       " '▁হ',\n",
       " 'ো',\n",
       " 'স',\n",
       " 'ে',\n",
       " 'ন',\n",
       " '।',\n",
       " '▁-',\n",
       " 'প',\n",
       " '্',\n",
       " 'র',\n",
       " 'ে',\n",
       " 'স',\n",
       " '▁ব',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_txt = \"\"\"\n",
    "সাভারের কবিরপুর বাণিজ্যিক এলাকার নিজস্ব ফ্যাক্টরিতে হয়ে গেল ইউনিটেক প্রডাক্টস (বিডি) লিঃ এর দিনব্যাপী সেলস কনফারেন্স। কনফারেন্সটি অনুষ্ঠিত হয় শনিবার, ১১ই মার্চ, সারা দেশ থেকে প্রায় ৩১০ জন ডিলার এই কনফারেন্সটিতে অংশগ্রহণ করেন এবং ইউনিটেকর ফ্যাক্টরি ঘুরে দেখার সুযোগ পান।এসময় ইউনিটেকর ব্যবস্থাপনা পরিচালক, ইঞ্জি: আনিস আহমেদ ডিলারদের উদ্দেশে বক্তব্য রাখেন এবং ইউনিটেক কে বাংলাদেশের সেরা ইলেক্ট্রনিক ব্র্যান্ড হিসেবে গড়ে তোলার আশ্বাস ব্যক্ত করেন। ইঞ্জি: আনিস আহমেদ, জাতীয় এবং বিভাগীয় পর্যায়ে সেরা ডিলারদের হাতে সার্টিফিকেট, ক্রেস্ট ও প্রাইজ বন্ড তুলে দেন। বিজয়ীরা হলেন রুপালি ইলেক্ট্রনিক্স (জাতীয় সেরা), লিয়া এন্টারপ্রাইজ (দ্বিতীয় জাতীয় সেরা), মদিনা ইলেক্ট্রনিক্স (তৃতীয় জাতীয় সেরা), সুন্দরবন ইলেক্ট্রনিক্স (ঢাকা বিভাগ), আলাউদ্দিন ইলেক্ট্রনিক্স (চিটাগং বিভাগ), শান্ত ইলেক্ট্রনিক্স (রাজশাহী রংপুর বিভাগ), নুরুল এন্টারপ্রাইজ (খুলনা বিভাগ), ফেয়ার ভিউ ইলেক্ট্রনিক্স (বরিশাল বিভাগ) ও ফিডব্যাক কমিউনিকেসন (সিলেট বিভাগ)। কনফারেন্সটিতে আরও বক্তব্য রাখেন ইউনিটেকের বিজনেস ডেভেলপমেন্ট অ্যান্ড প্ল্যানিং ম্যানেজার এ কে এম হামিদুর রহমান, সেলস অ্যান্ড ডেভেলপমেন্ট ম্যানেজার এ টি এম আখতার হোসেন ও ইউনিটেকের সেলস ম্যানেজার ডিলার চ্যানেল জাকির হোসেন। -প্রেস বিজ্ঞপ্তি\n",
    "\"\"\"\n",
    "tk_tokenizer.encode(test_txt).tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert\n",
    "tokenizer = transformers.PreTrainedTokenizerFast(tokenizer_object=tk_tokenizer, model_max_length=model_length, special_tokens=special_tokens)\n",
    "tokenizer.bos_token = \"<s>\"\n",
    "tokenizer.bos_token_id = tk_tokenizer.token_to_id(\"<s>\")\n",
    "tokenizer.pad_token = \"<pad>\"\n",
    "tokenizer.pad_token_id = tk_tokenizer.token_to_id(\"<pad>\")\n",
    "tokenizer.eos_token = \"</s>\"\n",
    "tokenizer.eos_token_id = tk_tokenizer.token_to_id(\"</s>\")\n",
    "tokenizer.unk_token = \"<unk>\"\n",
    "tokenizer.unk_token_id = tk_tokenizer.token_to_id(\"<unk>\")\n",
    "tokenizer.cls_token = \"<cls>\"\n",
    "tokenizer.cls_token_id = tk_tokenizer.token_to_id(\"<cls>\")\n",
    "tokenizer.sep_token = \"<sep>\"\n",
    "tokenizer.sep_token_id = tk_tokenizer.token_to_id(\"<sep>\")\n",
    "tokenizer.mask_token = \"<mask>\"\n",
    "tokenizer.mask_token_id = tk_tokenizer.token_to_id(\"<mask>\")\n",
    "# and save for later!\n",
    "tokenizer.save_pretrained(\"./path/to/transformers/version/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function custom:\n",
      "\n",
      "custom(pretok)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(PreTokenizer.custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomPreTokenizer(PreTokenizer):\n",
    "    def pre_tokenize(self, pretok):\n",
    "        sequence = pretok.split()[0]  # Get the sequence to be tokenized\n",
    "        sequence = re.sub(r'2', ' ', sequence)  # Replace '2' with space\n",
    "        pretok.replace(sequence)  # Replace the sequence in place\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import PreTokenizer\n",
    "from tokenizers.normalizers import NFC\n",
    "# from tokenizers.processors import BartProcessing\n",
    "\n",
    "from tokenizers import PreTokenizedString\n",
    "\n",
    "class BengaliPreTokenizer(PreTokenizer):\n",
    "    def pre_tokenize(self, pretok):\n",
    "        # Identify and preserve Bengali grapheme clusters\n",
    "        # print(text.get_splits())\n",
    "        sequence = pretok.split()[0]\n",
    "        \n",
    "        sequence = sequence.replace(\"ক্র\", \"[ক্র]\")\n",
    "        \n",
    "        # Add more Bengali-specific rules as needed\n",
    "        \n",
    "        return pretok.replace(sequence)\n",
    "\n",
    "class BengaliTokenizer:\n",
    "    def __init__(self, vocab_size=30000, min_frequency=2, special_tokens=None):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.min_frequency = min_frequency\n",
    "        self.special_tokens = special_tokens or []\n",
    "\n",
    "    def train_tokenizer(self, files):\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "\n",
    "        # Unicode normalization\n",
    "        tokenizer.normalizer = NFC()\n",
    "\n",
    "        # Custom Bengali pre-tokenizer\n",
    "        tokenizer.pre_tokenizer = BengaliPreTokenizer() #PreTokenizer.custom(BengaliPreTokenizer())\n",
    "\n",
    "        # SentencePieceBPE tokenization\n",
    "        trainer = BpeTrainer(\n",
    "            vocab_size=self.vocab_size,\n",
    "            min_frequency=self.min_frequency,\n",
    "            special_tokens=self.special_tokens,\n",
    "        )\n",
    "        tokenizer.train(files, trainer)\n",
    "\n",
    "        # # BART post-processing\n",
    "        # tokenizer.post_processor = BartProcessing(\n",
    "        #     sep=(\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "        #     cls=(\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        # )\n",
    "\n",
    "        return tokenizer\n",
    "\n",
    "    def train_tokenizer_from_iterator(self, text_iterator):\n",
    "        tokenizer = Tokenizer(BPE(unk_token=\"<unk>\"))\n",
    "\n",
    "        # Unicode normalization\n",
    "        tokenizer.normalizer = NFC()\n",
    "\n",
    "        # Custom Bengali pre-tokenizer\n",
    "        # tokenizer.pre_tokenizer = PreTokenizer.custom(BengaliPreTokenizer())\n",
    "        tokenizer.pre_tokenizer = BengaliPreTokenizer()\n",
    "\n",
    "        # SentencePieceBPE tokenization\n",
    "        trainer = BpeTrainer(\n",
    "            vocab_size=self.vocab_size,\n",
    "            min_frequency=self.min_frequency,\n",
    "            special_tokens=self.special_tokens,\n",
    "        )\n",
    "        tokenizer.train_from_iterator(text_iterator, trainer)\n",
    "\n",
    "        # # BART post-processing\n",
    "        # tokenizer.post_processor = BartProcessing(\n",
    "        #     sep=(\"</s>\", tokenizer.token_to_id(\"</s>\")),\n",
    "        #     cls=(\"<s>\", tokenizer.token_to_id(\"<s>\")),\n",
    "        # )\n",
    "\n",
    "        return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "No constructor defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m bengali_texts:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m text\n\u001b[0;32m---> 14\u001b[0m trained_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_tokenizer_from_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[45], line 61\u001b[0m, in \u001b[0;36mBengaliTokenizer.train_tokenizer_from_iterator\u001b[0;34m(self, text_iterator)\u001b[0m\n\u001b[1;32m     57\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mnormalizer \u001b[38;5;241m=\u001b[39m NFC()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Custom Bengali pre-tokenizer\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# tokenizer.pre_tokenizer = PreTokenizer.custom(BengaliPreTokenizer())\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpre_tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mBengaliPreTokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# SentencePieceBPE tokenization\u001b[39;00m\n\u001b[1;32m     64\u001b[0m trainer \u001b[38;5;241m=\u001b[39m BpeTrainer(\n\u001b[1;32m     65\u001b[0m     vocab_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size,\n\u001b[1;32m     66\u001b[0m     min_frequency\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_frequency,\n\u001b[1;32m     67\u001b[0m     special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_tokens,\n\u001b[1;32m     68\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: No constructor defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have a list of Bengali text strings\n",
    "bengali_texts = [\n",
    "    \"আমি বাংলায় ক্রিকেট খেলতে ভালোবাসি।\",\n",
    "    \"বাংলাদেশ একটি সুন্দর দেশ।\",\n",
    "    # Add more Bengali text strings\n",
    "]\n",
    "\n",
    "tokenizer = BengaliTokenizer(vocab_size=30000, min_frequency=2, special_tokens=[\"<s>\", \"</s>\", \"<unk>\", \"<pad>\", \"<mask>\"])\n",
    "\n",
    "def text_iterator():\n",
    "    for text in bengali_texts:\n",
    "        yield text\n",
    "\n",
    "trained_tokenizer = tokenizer.train_tokenizer_from_iterator(text_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'get_splits',\n",
       " 'normalize',\n",
       " 'split',\n",
       " 'to_encoding',\n",
       " 'tokenize']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tokenizers\n",
    "dir(tokenizers.PreTokenizedString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HF Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenizers\n",
    "from transformers import AutoTokenizer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3f7c17d1304f25b16afef4557f4721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/virus_proton/Projects/P_Projects/LLM_Mastery/llm_m_env/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a55c535b8b48249eba59aa32ee51c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/586 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7271a06574cb43ec86eb211c148c311f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/528k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2d427b4a694f44a0405615db154b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ElectraTokenizerFast(name_or_path='csebuetnlp/banglabert', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglabert\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[PAD]', 0),\n",
       " ('[UNK]', 1),\n",
       " ('[CLS]', 2),\n",
       " ('[SEP]', 3),\n",
       " ('[MASK]', 4),\n",
       " ('!', 5),\n",
       " ('\"', 6),\n",
       " ('#', 7),\n",
       " ('$', 8),\n",
       " ('%', 9),\n",
       " ('&', 10),\n",
       " (\"'\", 11),\n",
       " ('(', 12),\n",
       " (')', 13),\n",
       " ('*', 14),\n",
       " ('+', 15),\n",
       " (',', 16),\n",
       " ('-', 17),\n",
       " ('.', 18),\n",
       " ('/', 19),\n",
       " ('0', 20),\n",
       " ('1', 21),\n",
       " ('2', 22),\n",
       " ('3', 23),\n",
       " ('4', 24),\n",
       " ('5', 25),\n",
       " ('6', 26),\n",
       " ('7', 27),\n",
       " ('8', 28),\n",
       " ('9', 29),\n",
       " (':', 30),\n",
       " (';', 31),\n",
       " ('<', 32),\n",
       " ('=', 33),\n",
       " ('>', 34),\n",
       " ('?', 35),\n",
       " ('@', 36),\n",
       " ('A', 37),\n",
       " ('B', 38),\n",
       " ('C', 39),\n",
       " ('D', 40),\n",
       " ('E', 41),\n",
       " ('F', 42),\n",
       " ('G', 43),\n",
       " ('H', 44),\n",
       " ('I', 45),\n",
       " ('J', 46),\n",
       " ('K', 47),\n",
       " ('L', 48),\n",
       " ('M', 49),\n",
       " ('N', 50),\n",
       " ('O', 51),\n",
       " ('P', 52),\n",
       " ('Q', 53),\n",
       " ('R', 54),\n",
       " ('S', 55),\n",
       " ('T', 56),\n",
       " ('U', 57),\n",
       " ('V', 58),\n",
       " ('W', 59),\n",
       " ('X', 60),\n",
       " ('Y', 61),\n",
       " ('Z', 62),\n",
       " ('[', 63),\n",
       " ('\\\\', 64),\n",
       " (']', 65),\n",
       " ('^', 66),\n",
       " ('_', 67),\n",
       " ('`', 68),\n",
       " ('a', 69),\n",
       " ('b', 70),\n",
       " ('c', 71),\n",
       " ('d', 72),\n",
       " ('e', 73),\n",
       " ('f', 74),\n",
       " ('g', 75),\n",
       " ('h', 76),\n",
       " ('i', 77),\n",
       " ('j', 78),\n",
       " ('k', 79),\n",
       " ('l', 80),\n",
       " ('m', 81),\n",
       " ('n', 82),\n",
       " ('o', 83),\n",
       " ('p', 84),\n",
       " ('q', 85),\n",
       " ('r', 86),\n",
       " ('s', 87),\n",
       " ('t', 88),\n",
       " ('u', 89),\n",
       " ('v', 90),\n",
       " ('w', 91),\n",
       " ('x', 92),\n",
       " ('y', 93),\n",
       " ('z', 94),\n",
       " ('{', 95),\n",
       " ('|', 96),\n",
       " ('}', 97),\n",
       " ('~', 98),\n",
       " ('¤', 99),\n",
       " ('¦', 100),\n",
       " ('©', 101),\n",
       " ('®', 102),\n",
       " ('°', 103),\n",
       " ('·', 104),\n",
       " ('×', 105),\n",
       " ('þ', 106),\n",
       " ('œ', 107),\n",
       " ('̄', 108),\n",
       " ('а', 109),\n",
       " ('в', 110),\n",
       " ('д', 111),\n",
       " ('е', 112),\n",
       " ('и', 113),\n",
       " ('к', 114),\n",
       " ('л', 115),\n",
       " ('м', 116),\n",
       " ('н', 117),\n",
       " ('о', 118),\n",
       " ('п', 119),\n",
       " ('р', 120),\n",
       " ('с', 121),\n",
       " ('т', 122),\n",
       " ('у', 123),\n",
       " ('،', 124),\n",
       " ('ء', 125),\n",
       " ('آ', 126),\n",
       " ('أ', 127),\n",
       " ('ؤ', 128),\n",
       " ('إ', 129),\n",
       " ('ئ', 130),\n",
       " ('ا', 131),\n",
       " ('ب', 132),\n",
       " ('ة', 133),\n",
       " ('ت', 134),\n",
       " ('ث', 135),\n",
       " ('ج', 136),\n",
       " ('ح', 137),\n",
       " ('خ', 138),\n",
       " ('د', 139),\n",
       " ('ذ', 140),\n",
       " ('ر', 141),\n",
       " ('ز', 142),\n",
       " ('س', 143),\n",
       " ('ش', 144),\n",
       " ('ص', 145),\n",
       " ('ض', 146),\n",
       " ('ط', 147),\n",
       " ('ظ', 148),\n",
       " ('ع', 149),\n",
       " ('غ', 150),\n",
       " ('ف', 151),\n",
       " ('ق', 152),\n",
       " ('ك', 153),\n",
       " ('ل', 154),\n",
       " ('م', 155),\n",
       " ('ن', 156),\n",
       " ('ه', 157),\n",
       " ('و', 158),\n",
       " ('ى', 159),\n",
       " ('ي', 160),\n",
       " ('ً', 161),\n",
       " ('ٌ', 162),\n",
       " ('ٍ', 163),\n",
       " ('َ', 164),\n",
       " ('ُ', 165),\n",
       " ('ِ', 166),\n",
       " ('ّ', 167),\n",
       " ('ْ', 168),\n",
       " ('ٰ', 169),\n",
       " ('ی', 170),\n",
       " ('ۡ', 171),\n",
       " ('ं', 172),\n",
       " ('अ', 173),\n",
       " ('आ', 174),\n",
       " ('क', 175),\n",
       " ('ग', 176),\n",
       " ('च', 177),\n",
       " ('ज', 178),\n",
       " ('ट', 179),\n",
       " ('ड', 180),\n",
       " ('ण', 181),\n",
       " ('त', 182),\n",
       " ('द', 183),\n",
       " ('न', 184),\n",
       " ('प', 185),\n",
       " ('ब', 186),\n",
       " ('भ', 187),\n",
       " ('म', 188),\n",
       " ('य', 189),\n",
       " ('र', 190),\n",
       " ('ल', 191),\n",
       " ('व', 192),\n",
       " ('श', 193),\n",
       " ('स', 194),\n",
       " ('ह', 195),\n",
       " ('ा', 196),\n",
       " ('ि', 197),\n",
       " ('ी', 198),\n",
       " ('ु', 199),\n",
       " ('ू', 200),\n",
       " ('े', 201),\n",
       " ('ै', 202),\n",
       " ('ो', 203),\n",
       " ('्', 204),\n",
       " ('।', 205),\n",
       " ('॥', 206),\n",
       " ('ঁ', 207),\n",
       " ('ং', 208),\n",
       " ('ঃ', 209),\n",
       " ('অ', 210),\n",
       " ('আ', 211),\n",
       " ('ই', 212),\n",
       " ('ঈ', 213),\n",
       " ('উ', 214),\n",
       " ('ঊ', 215),\n",
       " ('ঋ', 216),\n",
       " ('এ', 217),\n",
       " ('ঐ', 218),\n",
       " ('ও', 219),\n",
       " ('ঔ', 220),\n",
       " ('ক', 221),\n",
       " ('খ', 222),\n",
       " ('গ', 223),\n",
       " ('ঘ', 224),\n",
       " ('ঙ', 225),\n",
       " ('চ', 226),\n",
       " ('ছ', 227),\n",
       " ('জ', 228),\n",
       " ('ঝ', 229),\n",
       " ('ঞ', 230),\n",
       " ('ট', 231),\n",
       " ('ঠ', 232),\n",
       " ('ড', 233),\n",
       " ('ঢ', 234),\n",
       " ('ণ', 235),\n",
       " ('ত', 236),\n",
       " ('থ', 237),\n",
       " ('দ', 238),\n",
       " ('ধ', 239),\n",
       " ('ন', 240),\n",
       " ('প', 241),\n",
       " ('ফ', 242),\n",
       " ('ব', 243),\n",
       " ('ভ', 244),\n",
       " ('ম', 245),\n",
       " ('য', 246),\n",
       " ('র', 247),\n",
       " ('ল', 248),\n",
       " ('শ', 249),\n",
       " ('ষ', 250),\n",
       " ('স', 251),\n",
       " ('হ', 252),\n",
       " ('়', 253),\n",
       " ('ঽ', 254),\n",
       " ('া', 255),\n",
       " ('ি', 256),\n",
       " ('ী', 257),\n",
       " ('ু', 258),\n",
       " ('ূ', 259),\n",
       " ('ৃ', 260),\n",
       " ('ে', 261),\n",
       " ('ৈ', 262),\n",
       " ('ো', 263),\n",
       " ('ৌ', 264),\n",
       " ('্', 265),\n",
       " ('ৎ', 266),\n",
       " ('\\u09d0', 267),\n",
       " ('\\u09e4', 268),\n",
       " ('০', 269),\n",
       " ('১', 270),\n",
       " ('২', 271),\n",
       " ('৩', 272),\n",
       " ('৪', 273),\n",
       " ('৫', 274),\n",
       " ('৬', 275),\n",
       " ('৭', 276),\n",
       " ('৮', 277),\n",
       " ('৯', 278),\n",
       " ('ৰ', 279),\n",
       " ('ৱ', 280),\n",
       " ('ં', 281),\n",
       " ('ક', 282),\n",
       " ('જ', 283),\n",
       " ('ત', 284),\n",
       " ('ન', 285),\n",
       " ('પ', 286),\n",
       " ('મ', 287),\n",
       " ('ય', 288),\n",
       " ('ર', 289),\n",
       " ('વ', 290),\n",
       " ('સ', 291),\n",
       " ('હ', 292),\n",
       " ('ા', 293),\n",
       " ('ી', 294),\n",
       " ('ુ', 295),\n",
       " ('ે', 296),\n",
       " ('ો', 297),\n",
       " ('્', 298),\n",
       " ('க', 299),\n",
       " ('ச', 300),\n",
       " ('ட', 301),\n",
       " ('த', 302),\n",
       " ('ந', 303),\n",
       " ('ன', 304),\n",
       " ('ப', 305),\n",
       " ('ம', 306),\n",
       " ('ய', 307),\n",
       " ('ர', 308),\n",
       " ('ற', 309),\n",
       " ('ல', 310),\n",
       " ('வ', 311),\n",
       " ('ா', 312),\n",
       " ('ி', 313),\n",
       " ('ு', 314),\n",
       " ('ை', 315),\n",
       " ('்', 316),\n",
       " ('ం', 317),\n",
       " ('క', 318),\n",
       " ('న', 319),\n",
       " ('ర', 320),\n",
       " ('ా', 321),\n",
       " ('ి', 322),\n",
       " ('ు', 323),\n",
       " ('్', 324),\n",
       " ('ಂ', 325),\n",
       " ('ಕ', 326),\n",
       " ('ಗ', 327),\n",
       " ('ತ', 328),\n",
       " ('ದ', 329),\n",
       " ('ನ', 330),\n",
       " ('ಮ', 331),\n",
       " ('ರ', 332),\n",
       " ('ಲ', 333),\n",
       " ('ವ', 334),\n",
       " ('ಾ', 335),\n",
       " ('ಿ', 336),\n",
       " ('ು', 337),\n",
       " ('ೆ', 338),\n",
       " ('್', 339),\n",
       " ('ക', 340),\n",
       " ('ട', 341),\n",
       " ('ത', 342),\n",
       " ('ന', 343),\n",
       " ('ാ', 344),\n",
       " ('ി', 345),\n",
       " ('ു', 346),\n",
       " ('്', 347),\n",
       " ('―', 348),\n",
       " ('†', 349),\n",
       " ('‡', 350),\n",
       " ('•', 351),\n",
       " ('′', 352),\n",
       " ('→', 353),\n",
       " ('√', 354),\n",
       " ('░', 355),\n",
       " ('■', 356),\n",
       " ('▬', 357),\n",
       " ('►', 358),\n",
       " ('◆', 359),\n",
       " ('●', 360),\n",
       " ('★', 361),\n",
       " ('☆', 362),\n",
       " ('☺', 363),\n",
       " ('♣', 364),\n",
       " ('♥', 365),\n",
       " ('♦', 366),\n",
       " ('✍', 367),\n",
       " ('❏', 368),\n",
       " ('❤', 369),\n",
       " ('➡', 370),\n",
       " ('。', 371),\n",
       " ('的', 372),\n",
       " ('️', 373),\n",
       " ('🌹', 374),\n",
       " ('🍁', 375),\n",
       " ('🎶', 376),\n",
       " ('💐', 377),\n",
       " ('💕', 378),\n",
       " ('💖', 379),\n",
       " ('💝', 380),\n",
       " ('💞', 381),\n",
       " ('😀', 382),\n",
       " ('😁', 383),\n",
       " ('😂', 384),\n",
       " ('😄', 385),\n",
       " ('😅', 386),\n",
       " ('😉', 387),\n",
       " ('😊', 388),\n",
       " ('😍', 389),\n",
       " ('😏', 390),\n",
       " ('😒', 391),\n",
       " ('😔', 392),\n",
       " ('😘', 393),\n",
       " ('😜', 394),\n",
       " ('😠', 395),\n",
       " ('😡', 396),\n",
       " ('😢', 397),\n",
       " ('😭', 398),\n",
       " ('😱', 399),\n",
       " ('🙂', 400),\n",
       " ('🙄', 401),\n",
       " ('🙏', 402),\n",
       " ('🤔', 403),\n",
       " ('🤣', 404),\n",
       " ('##গ', 405),\n",
       " ('##ু', 406),\n",
       " ('##ণ', 407),\n",
       " ('##্', 408),\n",
       " ('##ঠ', 409),\n",
       " ('##ে', 410),\n",
       " ('##র', 411),\n",
       " ('##জ', 412),\n",
       " ('##ো', 413),\n",
       " ('##ল', 414),\n",
       " ('##া', 415),\n",
       " ('##ি', 416),\n",
       " ('##স', 417),\n",
       " ('##ন', 418),\n",
       " ('##য', 419),\n",
       " ('##়', 420),\n",
       " ('##ৌ', 421),\n",
       " ('##ম', 422),\n",
       " ('##ট', 423),\n",
       " ('##ই', 424),\n",
       " ('##ব', 425),\n",
       " ('##প', 426),\n",
       " ('##চ', 427),\n",
       " ('##ী', 428),\n",
       " ('##ড', 429),\n",
       " ('##ভ', 430),\n",
       " ('##ত', 431),\n",
       " ('##ক', 432),\n",
       " ('##ফ', 433),\n",
       " ('##ং', 434),\n",
       " ('##H', 435),\n",
       " ('##K', 436),\n",
       " ('##W', 437),\n",
       " ('##M', 438),\n",
       " ('##😔', 439),\n",
       " ('##এ', 440),\n",
       " ('##উ', 441),\n",
       " ('##হ', 442),\n",
       " ('##e', 443),\n",
       " ('##w', 444),\n",
       " ('##a', 445),\n",
       " ('##h', 446),\n",
       " ('##o', 447),\n",
       " ('##u', 448),\n",
       " ('##g', 449),\n",
       " ('##t', 450),\n",
       " ('##দ', 451),\n",
       " ('##শ', 452),\n",
       " ('##c', 453),\n",
       " ('##p', 454),\n",
       " ('##i', 455),\n",
       " ('##ಂ', 456),\n",
       " ('##ಿ', 457),\n",
       " ('##ಲ', 458),\n",
       " ('##ঃ', 459),\n",
       " ('##ূ', 460),\n",
       " ('##থ', 461),\n",
       " ('##খ', 462),\n",
       " ('##ও', 463),\n",
       " ('##ৃ', 464),\n",
       " ('##d', 465),\n",
       " ('##f', 466),\n",
       " ('##m', 467),\n",
       " ('##l', 468),\n",
       " ('##ঁ', 469),\n",
       " ('##অ', 470),\n",
       " ('##৫', 471),\n",
       " ('##r', 472),\n",
       " ('##B', 473),\n",
       " ('##n', 474),\n",
       " ('##y', 475),\n",
       " ('##ছ', 476),\n",
       " ('##v', 477),\n",
       " ('##s', 478),\n",
       " ('##ঙ', 479),\n",
       " ('##N', 480),\n",
       " ('##🙏', 481),\n",
       " ('##💕', 482),\n",
       " ('##S', 483),\n",
       " ('##C', 484),\n",
       " ('##ষ', 485),\n",
       " ('##ঘ', 486),\n",
       " ('##২', 487),\n",
       " ('##১', 488),\n",
       " ('##০', 489),\n",
       " ('##৭', 490),\n",
       " ('##৬', 491),\n",
       " ('##ا', 492),\n",
       " ('##س', 493),\n",
       " ('##b', 494),\n",
       " ('##ঞ', 495),\n",
       " ('##j', 496),\n",
       " ('##R', 497),\n",
       " ('##ধ', 498),\n",
       " ('##и', 499),\n",
       " ('##н', 500),\n",
       " ('##k', 501),\n",
       " ('##ঈ', 502),\n",
       " ('##ঽ', 503),\n",
       " ('##৪', 504),\n",
       " ('##5', 505),\n",
       " ('##6', 506),\n",
       " ('##0', 507),\n",
       " ('##1', 508),\n",
       " ('##о', 509),\n",
       " ('##л', 510),\n",
       " ('##с', 511),\n",
       " ('##т', 512),\n",
       " ('##в', 513),\n",
       " ('##а', 514),\n",
       " ('##\\u09e4', 515),\n",
       " ('##U', 516),\n",
       " ('##D', 517),\n",
       " ('##A', 518),\n",
       " ('##ु', 519),\n",
       " ('##र', 520),\n",
       " ('##ो', 521),\n",
       " ('##7', 522),\n",
       " ('##4', 523),\n",
       " ('##3', 524),\n",
       " ('##е', 525),\n",
       " ('##8', 526),\n",
       " ('##আ', 527),\n",
       " ('##️', 528),\n",
       " ('##ಾ', 529),\n",
       " ('##ಕ', 530),\n",
       " ('##ವ', 531),\n",
       " ('##ಗ', 532),\n",
       " ('##ل', 533),\n",
       " ('##ْ', 534),\n",
       " ('##ي', 535),\n",
       " ('##َ', 536),\n",
       " ('##و', 537),\n",
       " ('##م', 538),\n",
       " ('##ُ', 539),\n",
       " ('##T', 540),\n",
       " ('##E', 541),\n",
       " ('##P', 542),\n",
       " ('##ৰ', 543),\n",
       " ('##ৈ', 544),\n",
       " ('##I', 545),\n",
       " ('##V', 546),\n",
       " ('##的', 547),\n",
       " ('##2', 548),\n",
       " ('##أ', 549),\n",
       " ('##ت', 550),\n",
       " ('##ৎ', 551),\n",
       " ('##9', 552),\n",
       " ('##Y', 553),\n",
       " ('##★', 554),\n",
       " ('##్', 555),\n",
       " ('##ు', 556),\n",
       " ('##ం', 557),\n",
       " ('##ك', 558),\n",
       " ('##ن', 559),\n",
       " ('##L', 560),\n",
       " ('##F', 561),\n",
       " ('##x', 562),\n",
       " ('##৩', 563),\n",
       " ('##ج', 564),\n",
       " ('##ز', 565),\n",
       " ('##ر', 566),\n",
       " ('##ة', 567),\n",
       " ('##O', 568),\n",
       " ('##z', 569),\n",
       " ('##G', 570),\n",
       " ('##😠', 571),\n",
       " ('##😡', 572),\n",
       " ('##ش', 573),\n",
       " ('##ح', 574),\n",
       " ('##৮', 575),\n",
       " ('##ನ', 576),\n",
       " ('##ತ', 577),\n",
       " ('##್', 578),\n",
       " ('##ು', 579),\n",
       " ('##ന', 580),\n",
       " ('##്', 581),\n",
       " ('##ി', 582),\n",
       " ('##ു', 583),\n",
       " ('##ത', 584),\n",
       " ('##न', 585),\n",
       " ('##म', 586),\n",
       " ('##क', 587),\n",
       " ('##े', 588),\n",
       " ('##ف', 589),\n",
       " ('##ء', 590),\n",
       " ('##ً', 591),\n",
       " ('##৯', 592),\n",
       " ('##ग', 593),\n",
       " ('##ल', 594),\n",
       " ('##న', 595),\n",
       " ('##ి', 596),\n",
       " ('##ِ', 597),\n",
       " ('##°', 598),\n",
       " ('##ص', 599),\n",
       " ('##د', 600),\n",
       " ('##ّ', 601),\n",
       " ('##ق', 602),\n",
       " ('##❤', 603),\n",
       " ('##💖', 604),\n",
       " ('##ு', 605),\n",
       " ('##ர', 606),\n",
       " ('##ன', 607),\n",
       " ('##ா', 608),\n",
       " ('##க', 609),\n",
       " ('##்', 610),\n",
       " ('##ட', 611),\n",
       " ('##ঐ', 612),\n",
       " ('##q', 613),\n",
       " ('##ह', 614),\n",
       " ('##😍', 615),\n",
       " ('##ி', 616),\n",
       " ('##ற', 617),\n",
       " ('##ந', 618),\n",
       " ('##த', 619),\n",
       " ('##வ', 620),\n",
       " ('##ঝ', 621),\n",
       " ('##ৱ', 622),\n",
       " ('##خ', 623),\n",
       " ('##ه', 624),\n",
       " ('##ை', 625),\n",
       " ('##ய', 626),\n",
       " ('##ம', 627),\n",
       " ('##🙄', 628),\n",
       " ('##J', 629),\n",
       " ('##р', 630),\n",
       " ('##д', 631),\n",
       " ('##ல', 632),\n",
       " ('##ঢ', 633),\n",
       " ('##ঊ', 634),\n",
       " ('##ঋ', 635),\n",
       " ('##😭', 636),\n",
       " ('##©', 637),\n",
       " ('##X', 638),\n",
       " ('##Z', 639),\n",
       " ('##ط', 640),\n",
       " ('##к', 641),\n",
       " ('##у', 642),\n",
       " ('##ా', 643),\n",
       " ('##😘', 644),\n",
       " ('##¤', 645),\n",
       " ('##ा', 646),\n",
       " ('##ं', 647),\n",
       " ('##ب', 648),\n",
       " ('##्', 649),\n",
       " ('##ण', 650),\n",
       " ('##غ', 651),\n",
       " ('##ع', 652),\n",
       " ('##ર', 653),\n",
       " ('##ા', 654),\n",
       " ('##વ', 655),\n",
       " ('##ી', 656),\n",
       " ('##ۡ', 657),\n",
       " ('##द', 658),\n",
       " ('##ी', 659),\n",
       " ('##ض', 660),\n",
       " ('##ക', 661),\n",
       " ('##ാ', 662),\n",
       " ('##ട', 663),\n",
       " ('##😉', 664),\n",
       " ('##Q', 665),\n",
       " ('##ન', 666),\n",
       " ('##ಮ', 667),\n",
       " ('##ی', 668),\n",
       " ('##प', 669),\n",
       " ('##😏', 670),\n",
       " ('##ट', 671),\n",
       " ('##×', 672),\n",
       " ('##ય', 673),\n",
       " ('##ો', 674),\n",
       " ('##स', 675),\n",
       " ('##ٌ', 676),\n",
       " ('##ರ', 677),\n",
       " ('##ದ', 678),\n",
       " ('##ٍ', 679),\n",
       " ('##ئ', 680),\n",
       " ('##🎶', 681),\n",
       " ('##►', 682),\n",
       " ('##œ', 683),\n",
       " ('##ப', 684),\n",
       " ('##ि', 685),\n",
       " ('##إ', 686),\n",
       " ('##त', 687),\n",
       " ('##ક', 688),\n",
       " ('##य', 689),\n",
       " ('##श', 690),\n",
       " ('##آ', 691),\n",
       " ('##🤔', 692),\n",
       " ('##ೆ', 693),\n",
       " ('##😊', 694),\n",
       " ('##м', 695),\n",
       " ('##♣', 696),\n",
       " ('##ब', 697),\n",
       " ('##ड', 698),\n",
       " ('##😁', 699),\n",
       " ('##व', 700),\n",
       " ('##п', 701),\n",
       " ('##્', 702),\n",
       " ('##મ', 703),\n",
       " ('##च', 704),\n",
       " ('##भ', 705),\n",
       " ('##ى', 706),\n",
       " ('##ذ', 707),\n",
       " ('##ે', 708),\n",
       " ('##ત', 709),\n",
       " ('##ં', 710),\n",
       " ('##😒', 711),\n",
       " ('##ै', 712),\n",
       " ('##🙂', 713),\n",
       " ('##🍁', 714),\n",
       " ('##¦', 715),\n",
       " ('##ज', 716),\n",
       " ('##ू', 717),\n",
       " ('##ظ', 718),\n",
       " ('##😂', 719),\n",
       " ('##░', 720),\n",
       " ('##→', 721),\n",
       " ('##ث', 722),\n",
       " ('##®', 723),\n",
       " ('##ٰ', 724),\n",
       " ('##ુ', 725),\n",
       " ('##☺', 726),\n",
       " ('##క', 727),\n",
       " ('##😜', 728),\n",
       " ('##જ', 729),\n",
       " ('##🌹', 730),\n",
       " ('##😅', 731),\n",
       " ('##➡', 732),\n",
       " ('##♦', 733),\n",
       " ('##ؤ', 734),\n",
       " ('##♥', 735),\n",
       " ('##ঔ', 736),\n",
       " ('##સ', 737),\n",
       " ('##🤣', 738),\n",
       " ('##હ', 739),\n",
       " ('##😢', 740),\n",
       " ('##💞', 741),\n",
       " ('##ச', 742),\n",
       " ('##😀', 743),\n",
       " ('##◆', 744),\n",
       " ('##ర', 745),\n",
       " ('##😱', 746),\n",
       " ('##💝', 747),\n",
       " ('##▬', 748),\n",
       " ('##अ', 749),\n",
       " ('##✍', 750),\n",
       " ('##■', 751),\n",
       " ('##😄', 752),\n",
       " ('##💐', 753),\n",
       " ('##●', 754),\n",
       " ('##आ', 755),\n",
       " ('##પ', 756),\n",
       " ('##̄', 757),\n",
       " ('##þ', 758),\n",
       " ('##☆', 759),\n",
       " ('##√', 760),\n",
       " ('##\\u09d0', 761),\n",
       " ('##য়', 762),\n",
       " ('##ার', 763),\n",
       " ('##ের', 764),\n",
       " ('##্র', 765),\n",
       " ('##্য', 766),\n",
       " ('##ান', 767),\n",
       " ('##য়ে', 768),\n",
       " ('কর', 769),\n",
       " ('##্ত', 770),\n",
       " ('##লে', 771),\n",
       " ('##কে', 772),\n",
       " ('##তে', 773),\n",
       " ('##ছে', 774),\n",
       " ('##িন', 775),\n",
       " ('##ায়', 776),\n",
       " ('##ড়', 777),\n",
       " ('##বে', 778),\n",
       " ('##াম', 779),\n",
       " ('##াল', 780),\n",
       " ('প্র', 781),\n",
       " ('##িয়ে', 782),\n",
       " ('##িক', 783),\n",
       " ('##ির', 784),\n",
       " ('আম', 785),\n",
       " ('##্ব', 786),\n",
       " ('বা', 787),\n",
       " ('এক', 788),\n",
       " ('##াক', 789),\n",
       " ('##াই', 790),\n",
       " ('##্ট', 791),\n",
       " ('করে', 792),\n",
       " ('##াদ', 793),\n",
       " ('##িল', 794),\n",
       " ('না', 795),\n",
       " ('দে', 796),\n",
       " ('বি', 797),\n",
       " ('##ুর', 798),\n",
       " ('##াস', 799),\n",
       " ('##টা', 800),\n",
       " ('##িত', 801),\n",
       " ('##ন্', 802),\n",
       " ('##নে', 803),\n",
       " ('পর', 804),\n",
       " ('##াত', 805),\n",
       " ('##টি', 806),\n",
       " ('##্ষ', 807),\n",
       " ('##ুল', 808),\n",
       " ('সে', 809),\n",
       " ('##য়া', 810),\n",
       " ('##র্', 811),\n",
       " ('##াজ', 812),\n",
       " ('##াব', 813),\n",
       " ('সম', 814),\n",
       " ('আর', 815),\n",
       " ('তা', 816),\n",
       " ('কি', 817),\n",
       " ('##েন', 818),\n",
       " ('##তি', 819),\n",
       " ('##েল', 820),\n",
       " ('##্যা', 821),\n",
       " ('নি', 822),\n",
       " ('##োন', 823),\n",
       " ('হয়ে', 824),\n",
       " ('##রা', 825),\n",
       " ('তার', 826),\n",
       " ('##েকে', 827),\n",
       " ('বল', 828),\n",
       " ('##বার', 829),\n",
       " ('এই', 830),\n",
       " ('যে', 831),\n",
       " ('##লেন', 832),\n",
       " ('##দের', 833),\n",
       " ('##েশ', 834),\n",
       " ('##চ্', 835),\n",
       " ('##ন্য', 836),\n",
       " ('##রে', 837),\n",
       " ('##িস', 838),\n",
       " ('সা', 839),\n",
       " ('##থা', 840),\n",
       " ('##ঙ্', 841),\n",
       " ('থেকে', 842),\n",
       " ('##্প', 843),\n",
       " ('হয়', 844),\n",
       " ('দেখ', 845),\n",
       " ('তো', 846),\n",
       " ('##ক্ষ', 847),\n",
       " ('##না', 848),\n",
       " ('পা', 849),\n",
       " ('পার', 850),\n",
       " ('##খন', 851),\n",
       " ('##গে', 852),\n",
       " ('##নি', 853),\n",
       " ('##ন্ত', 854),\n",
       " ('মা', 855),\n",
       " ('##াদের', 856),\n",
       " ('আমি', 857),\n",
       " ('কা', 858),\n",
       " ('##্ম', 859),\n",
       " ('##ুক', 860),\n",
       " ('##য়ার', 861),\n",
       " ('##কার', 862),\n",
       " ('##নের', 863),\n",
       " ('##দ্', 864),\n",
       " ('##লো', 865),\n",
       " ('যা', 866),\n",
       " ('##ছেন', 867),\n",
       " ('##্থ', 868),\n",
       " ('##ুম', 869),\n",
       " ('##সে', 870),\n",
       " ('##ছি', 871),\n",
       " ('##ষ্ট', 872),\n",
       " ('##ীর', 873),\n",
       " ('দি', 874),\n",
       " ('##ানে', 875),\n",
       " ('নে', 876),\n",
       " ('কে', 877),\n",
       " ('আমার', 878),\n",
       " ('##লা', 879),\n",
       " ('##ুন', 880),\n",
       " ('##ন্দ', 881),\n",
       " ('##িনি', 882),\n",
       " ('##ধ্য', 883),\n",
       " ('দু', 884),\n",
       " ('জান', 885),\n",
       " ('কোন', 886),\n",
       " ('##াকে', 887),\n",
       " ('নিয়ে', 888),\n",
       " ('সব', 889),\n",
       " ('##িন্ত', 890),\n",
       " ('##ছিল', 891),\n",
       " ('##াগ', 892),\n",
       " ('##বি', 893),\n",
       " ('আস', 894),\n",
       " ('##াপ', 895),\n",
       " ('বলে', 896),\n",
       " ('##ড়ে', 897),\n",
       " ('##ছু', 898),\n",
       " ('##োগ', 899),\n",
       " ('জন্য', 900),\n",
       " ('এব', 901),\n",
       " ('দিয়ে', 902),\n",
       " ('এবং', 903),\n",
       " ('##োর', 904),\n",
       " ('##তা', 905),\n",
       " ('সং', 906),\n",
       " ('##াবে', 907),\n",
       " ('##দ্ধ', 908),\n",
       " ('মে', 909),\n",
       " ('ব্য', 910),\n",
       " ('মু', 911),\n",
       " ('##াড়', 912),\n",
       " ('করা', 913),\n",
       " ('##ুষ', 914),\n",
       " ('##্তি', 915),\n",
       " ('কিছু', 916),\n",
       " ('কথা', 917),\n",
       " ('হবে', 918),\n",
       " ('এর', 919),\n",
       " ('কিন্ত', 920),\n",
       " ('কার', 921),\n",
       " ('##পর', 922),\n",
       " ('##জন', 923),\n",
       " ('করতে', 924),\n",
       " ('কিন্তু', 925),\n",
       " ('##্ন', 926),\n",
       " ('##তো', 927),\n",
       " ('##িশ', 928),\n",
       " ('##ওয়া', 929),\n",
       " ('মান', 930),\n",
       " ('রা', 931),\n",
       " ('##্ল', 932),\n",
       " ('তাঁ', 933),\n",
       " ('অব', 934),\n",
       " ('থাক', 935),\n",
       " ('পরি', 936),\n",
       " ('##কা', 937),\n",
       " ('##মন', 938),\n",
       " ('আপ', 939),\n",
       " ('##্ড', 940),\n",
       " ('সু', 941),\n",
       " ('##ীয়', 942),\n",
       " ('##চ্ছে', 943),\n",
       " ('##দি', 944),\n",
       " ('স্ব', 945),\n",
       " ('##স্ত', 946),\n",
       " ('অন', 947),\n",
       " ('নির', 948),\n",
       " ('একটা', 949),\n",
       " ('##াহ', 950),\n",
       " ('##িয়া', 951),\n",
       " ('##টে', 952),\n",
       " ('##্রে', 953),\n",
       " ('তিনি', 954),\n",
       " ('ছিল', 955),\n",
       " ('বিশ', 956),\n",
       " ('##িতে', 957),\n",
       " ('খু', 958),\n",
       " ('##িম', 959),\n",
       " ('##থে', 960),\n",
       " ('সর', 961),\n",
       " ('##ঙ্গ', 962),\n",
       " ('প্রতি', 963),\n",
       " ('ভাল', 964),\n",
       " ('যায়', 965),\n",
       " ('##ন্ধ', 966),\n",
       " ('##াঁ', 967),\n",
       " ('##্চ', 968),\n",
       " ('নিজ', 969),\n",
       " ('##ারা', 970),\n",
       " ('##েষ', 971),\n",
       " ('আছে', 972),\n",
       " ('উপ', 973),\n",
       " ('অনে', 974),\n",
       " ('হয়েছে', 975),\n",
       " ('##েলে', 976),\n",
       " ('##দিন', 977),\n",
       " ('##ৃত', 978),\n",
       " ('##লাম', 979),\n",
       " ('##মে', 980),\n",
       " ('##খে', 981),\n",
       " ('মধ্য', 982),\n",
       " ('সেই', 983),\n",
       " ('##োক', 984),\n",
       " ('বে', 985),\n",
       " ('শু', 986),\n",
       " ('##াতে', 987),\n",
       " ('কো', 988),\n",
       " ('অভ', 989),\n",
       " ('একটি', 990),\n",
       " ('##ঙ্গে', 991),\n",
       " ('##গুল', 992),\n",
       " ('নাম', 993),\n",
       " ('##্ক', 994),\n",
       " ('চে', 995),\n",
       " ('মনে', 996),\n",
       " ('আজ', 997),\n",
       " ('সময়', 998),\n",
       " ('বাড়', 999),\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "vocab = sorted(vocab.items(), key=lambda i:i[1])\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"', 1000),\n",
       " ('#', 1001),\n",
       " ('$', 1002),\n",
       " ('৳', 1003),\n",
       " ('%', 1004),\n",
       " ('&', 1005),\n",
       " (\"'\", 1006),\n",
       " ('(', 1007),\n",
       " (')', 1008),\n",
       " ('*', 1009),\n",
       " ('+', 1010),\n",
       " (',', 1011),\n",
       " ('-', 1012),\n",
       " ('.', 1013),\n",
       " ('।', 1014),\n",
       " ('/', 1019),\n",
       " ('০', 1020),\n",
       " ('১', 1021),\n",
       " ('২', 1022),\n",
       " ('৩', 1023),\n",
       " ('৪', 1024),\n",
       " ('৫', 1025),\n",
       " ('৬', 1026),\n",
       " ('৭', 1027),\n",
       " ('৮', 1028),\n",
       " ('৯', 1029),\n",
       " ('0', 1030),\n",
       " ('1', 1031),\n",
       " ('2', 1032),\n",
       " ('3', 1033),\n",
       " ('4', 1034),\n",
       " ('5', 1035),\n",
       " ('6', 1036),\n",
       " ('7', 1037),\n",
       " ('8', 1038),\n",
       " ('9', 1039),\n",
       " (':', 1040),\n",
       " (';', 1041),\n",
       " ('<', 1042),\n",
       " ('=', 1043),\n",
       " ('>', 1044),\n",
       " ('?', 1045),\n",
       " ('@', 1046),\n",
       " ('[', 1047),\n",
       " ('\\\\', 1048),\n",
       " (']', 1049),\n",
       " ('^', 1050),\n",
       " ('_', 1051),\n",
       " ('`', 1052),\n",
       " ('ঊ', 1058),\n",
       " ('ঋ', 1059),\n",
       " ('ঔ', 1063),\n",
       " ('ণ', 1078),\n",
       " ('ড়', 1096),\n",
       " ('ঢ়', 1097),\n",
       " ('য়', 1098),\n",
       " ('ং', 1100),\n",
       " ('ঁ', 1102),\n",
       " ('া', 1103),\n",
       " ('ি', 1104),\n",
       " ('ী', 1105),\n",
       " ('ু', 1106),\n",
       " ('ৃ', 1107),\n",
       " ('ে', 1108),\n",
       " ('ৈ', 1109),\n",
       " ('ো', 1110),\n",
       " ('ৌ', 1111),\n",
       " ('্র', 1114),\n",
       " ('্ন', 1115),\n",
       " ('্ম', 1116),\n",
       " ('্ল', 1117),\n",
       " ('্ব', 1118),\n",
       " ('a', 1119),\n",
       " ('b', 1120),\n",
       " ('c', 1121),\n",
       " ('d', 1122),\n",
       " ('e', 1123),\n",
       " ('f', 1124),\n",
       " ('g', 1125),\n",
       " ('h', 1126),\n",
       " ('i', 1127),\n",
       " ('j', 1128),\n",
       " ('k', 1129),\n",
       " ('l', 1130),\n",
       " ('m', 1131),\n",
       " ('n', 1132),\n",
       " ('o', 1133),\n",
       " ('p', 1134),\n",
       " ('q', 1135),\n",
       " ('r', 1136),\n",
       " ('s', 1137),\n",
       " ('t', 1138),\n",
       " ('u', 1139),\n",
       " ('v', 1140),\n",
       " ('w', 1141),\n",
       " ('x', 1142),\n",
       " ('y', 1143),\n",
       " ('z', 1144),\n",
       " ('{', 1145),\n",
       " ('|', 1146),\n",
       " ('}', 1147),\n",
       " ('~', 1148),\n",
       " ('¡', 1149),\n",
       " ('¢', 1150),\n",
       " ('£', 1151),\n",
       " ('¤', 1152),\n",
       " ('¥', 1153),\n",
       " ('¦', 1154),\n",
       " ('§', 1155),\n",
       " ('¨', 1156),\n",
       " ('©', 1157),\n",
       " ('ª', 1158),\n",
       " ('«', 1159),\n",
       " ('¬', 1160),\n",
       " ('®', 1161),\n",
       " ('°', 1162),\n",
       " ('±', 1163),\n",
       " ('²', 1164),\n",
       " ('³', 1165),\n",
       " ('´', 1166),\n",
       " ('µ', 1167),\n",
       " ('¶', 1168),\n",
       " ('·', 1169),\n",
       " ('¹', 1170),\n",
       " ('º', 1171),\n",
       " ('»', 1172),\n",
       " ('¼', 1173),\n",
       " ('½', 1174),\n",
       " ('¾', 1175),\n",
       " ('¿', 1176),\n",
       " ('×', 1177),\n",
       " ('ß', 1178),\n",
       " ('æ', 1179),\n",
       " ('ð', 1180),\n",
       " ('÷', 1181),\n",
       " ('ø', 1182),\n",
       " ('þ', 1183),\n",
       " ('đ', 1184),\n",
       " ('ħ', 1185),\n",
       " ('ı', 1186),\n",
       " ('ł', 1187),\n",
       " ('ŋ', 1188),\n",
       " ('œ', 1189),\n",
       " ('ƒ', 1190),\n",
       " ('ɐ', 1191),\n",
       " ('ɑ', 1192),\n",
       " ('ɒ', 1193),\n",
       " ('ɔ', 1194),\n",
       " ('ɕ', 1195),\n",
       " ('ə', 1196),\n",
       " ('ɛ', 1197),\n",
       " ('ɡ', 1198),\n",
       " ('ɣ', 1199),\n",
       " ('ɨ', 1200),\n",
       " ('ɪ', 1201),\n",
       " ('ɫ', 1202),\n",
       " ('ɬ', 1203),\n",
       " ('ɯ', 1204),\n",
       " ('ɲ', 1205),\n",
       " ('ɴ', 1206),\n",
       " ('ɹ', 1207),\n",
       " ('ɾ', 1208),\n",
       " ('ʀ', 1209),\n",
       " ('ʁ', 1210),\n",
       " ('ʂ', 1211),\n",
       " ('ʃ', 1212),\n",
       " ('ʉ', 1213),\n",
       " ('ʊ', 1214),\n",
       " ('ʋ', 1215),\n",
       " ('ʌ', 1216),\n",
       " ('ʎ', 1217),\n",
       " ('ʐ', 1218),\n",
       " ('ʑ', 1219),\n",
       " ('ʒ', 1220),\n",
       " ('ʔ', 1221),\n",
       " ('ʰ', 1222),\n",
       " ('ʲ', 1223),\n",
       " ('ʳ', 1224),\n",
       " ('ʷ', 1225),\n",
       " ('ʸ', 1226),\n",
       " ('ʻ', 1227),\n",
       " ('ʼ', 1228),\n",
       " ('ʾ', 1229),\n",
       " ('ʿ', 1230),\n",
       " ('ˈ', 1231),\n",
       " ('ː', 1232),\n",
       " ('ˡ', 1233),\n",
       " ('ˢ', 1234),\n",
       " ('ˣ', 1235),\n",
       " ('ˤ', 1236),\n",
       " ('α', 1237),\n",
       " ('β', 1238),\n",
       " ('γ', 1239),\n",
       " ('δ', 1240),\n",
       " ('ε', 1241),\n",
       " ('ζ', 1242),\n",
       " ('η', 1243),\n",
       " ('θ', 1244),\n",
       " ('ι', 1245),\n",
       " ('κ', 1246),\n",
       " ('λ', 1247),\n",
       " ('μ', 1248),\n",
       " ('ν', 1249),\n",
       " ('ξ', 1250),\n",
       " ('ο', 1251),\n",
       " ('π', 1252),\n",
       " ('ρ', 1253),\n",
       " ('ς', 1254),\n",
       " ('σ', 1255),\n",
       " ('τ', 1256),\n",
       " ('υ', 1257),\n",
       " ('φ', 1258),\n",
       " ('χ', 1259),\n",
       " ('ψ', 1260),\n",
       " ('ω', 1261),\n",
       " ('а', 1262),\n",
       " ('б', 1263),\n",
       " ('в', 1264),\n",
       " ('г', 1265),\n",
       " ('д', 1266),\n",
       " ('е', 1267),\n",
       " ('ж', 1268),\n",
       " ('з', 1269),\n",
       " ('и', 1270),\n",
       " ('к', 1271),\n",
       " ('л', 1272),\n",
       " ('м', 1273),\n",
       " ('н', 1274),\n",
       " ('о', 1275),\n",
       " ('п', 1276),\n",
       " ('р', 1277),\n",
       " ('с', 1278),\n",
       " ('т', 1279),\n",
       " ('у', 1280),\n",
       " ('ф', 1281),\n",
       " ('х', 1282),\n",
       " ('ц', 1283),\n",
       " ('ч', 1284),\n",
       " ('ш', 1285),\n",
       " ('щ', 1286),\n",
       " ('ъ', 1287),\n",
       " ('ы', 1288),\n",
       " ('ь', 1289),\n",
       " ('э', 1290),\n",
       " ('ю', 1291),\n",
       " ('я', 1292),\n",
       " ('ђ', 1293),\n",
       " ('є', 1294),\n",
       " ('і', 1295),\n",
       " ('ј', 1296),\n",
       " ('љ', 1297),\n",
       " ('њ', 1298),\n",
       " ('ћ', 1299),\n",
       " ('ӏ', 1300),\n",
       " ('ա', 1301),\n",
       " ('բ', 1302),\n",
       " ('գ', 1303),\n",
       " ('դ', 1304),\n",
       " ('ե', 1305),\n",
       " ('թ', 1306),\n",
       " ('ի', 1307),\n",
       " ('լ', 1308),\n",
       " ('կ', 1309),\n",
       " ('հ', 1310),\n",
       " ('մ', 1311),\n",
       " ('յ', 1312),\n",
       " ('ն', 1313),\n",
       " ('ո', 1314),\n",
       " ('պ', 1315),\n",
       " ('ս', 1316),\n",
       " ('վ', 1317),\n",
       " ('տ', 1318),\n",
       " ('ր', 1319),\n",
       " ('ւ', 1320),\n",
       " ('ք', 1321),\n",
       " ('־', 1322),\n",
       " ('א', 1323),\n",
       " ('ב', 1324),\n",
       " ('ג', 1325),\n",
       " ('ד', 1326),\n",
       " ('ה', 1327),\n",
       " ('ו', 1328),\n",
       " ('ז', 1329),\n",
       " ('ח', 1330),\n",
       " ('ט', 1331),\n",
       " ('י', 1332),\n",
       " ('ך', 1333),\n",
       " ('כ', 1334),\n",
       " ('ל', 1335),\n",
       " ('ם', 1336),\n",
       " ('מ', 1337),\n",
       " ('ן', 1338),\n",
       " ('נ', 1339),\n",
       " ('ס', 1340),\n",
       " ('ע', 1341),\n",
       " ('ף', 1342),\n",
       " ('פ', 1343),\n",
       " ('ץ', 1344),\n",
       " ('צ', 1345),\n",
       " ('ק', 1346),\n",
       " ('ר', 1347),\n",
       " ('ש', 1348),\n",
       " ('ת', 1349),\n",
       " ('،', 1350),\n",
       " ('ء', 1351),\n",
       " ('ا', 1352),\n",
       " ('ب', 1353),\n",
       " ('ة', 1354),\n",
       " ('ت', 1355),\n",
       " ('ث', 1356),\n",
       " ('ج', 1357),\n",
       " ('ح', 1358),\n",
       " ('خ', 1359),\n",
       " ('د', 1360),\n",
       " ('ذ', 1361),\n",
       " ('ر', 1362),\n",
       " ('ز', 1363),\n",
       " ('س', 1364),\n",
       " ('ش', 1365),\n",
       " ('ص', 1366),\n",
       " ('ض', 1367),\n",
       " ('ط', 1368),\n",
       " ('ظ', 1369),\n",
       " ('ع', 1370),\n",
       " ('غ', 1371),\n",
       " ('ـ', 1372),\n",
       " ('ف', 1373),\n",
       " ('ق', 1374),\n",
       " ('ك', 1375),\n",
       " ('ل', 1376),\n",
       " ('م', 1377),\n",
       " ('ن', 1378),\n",
       " ('ه', 1379),\n",
       " ('و', 1380),\n",
       " ('ى', 1381),\n",
       " ('ي', 1382),\n",
       " ('ٹ', 1383),\n",
       " ('پ', 1384),\n",
       " ('چ', 1385),\n",
       " ('ک', 1386),\n",
       " ('گ', 1387),\n",
       " ('ں', 1388),\n",
       " ('ھ', 1389),\n",
       " ('ہ', 1390),\n",
       " ('ی', 1391),\n",
       " ('ے', 1392),\n",
       " ('अ', 1393),\n",
       " ('आ', 1394),\n",
       " ('उ', 1395),\n",
       " ('ए', 1396),\n",
       " ('क', 1397),\n",
       " ('ख', 1398),\n",
       " ('ग', 1399),\n",
       " ('च', 1400),\n",
       " ('ज', 1401),\n",
       " ('ट', 1402),\n",
       " ('ड', 1403),\n",
       " ('ण', 1404),\n",
       " ('त', 1405),\n",
       " ('थ', 1406),\n",
       " ('द', 1407),\n",
       " ('ध', 1408),\n",
       " ('न', 1409),\n",
       " ('प', 1410),\n",
       " ('ब', 1411),\n",
       " ('भ', 1412),\n",
       " ('म', 1413),\n",
       " ('य', 1414),\n",
       " ('र', 1415),\n",
       " ('ल', 1416),\n",
       " ('व', 1417),\n",
       " ('श', 1418),\n",
       " ('ष', 1419),\n",
       " ('स', 1420),\n",
       " ('ह', 1421),\n",
       " ('க', 1422),\n",
       " ('ச', 1423),\n",
       " ('ட', 1424),\n",
       " ('த', 1425),\n",
       " ('ந', 1426),\n",
       " ('ன', 1427),\n",
       " ('ப', 1428),\n",
       " ('ம', 1429),\n",
       " ('ய', 1430),\n",
       " ('ர', 1431),\n",
       " ('ல', 1432),\n",
       " ('ள', 1433),\n",
       " ('வ', 1434),\n",
       " ('ா', 1435),\n",
       " ('ி', 1436),\n",
       " ('ு', 1437),\n",
       " ('ே', 1438),\n",
       " ('ை', 1439),\n",
       " ('ನ', 1440),\n",
       " ('ರ', 1441),\n",
       " ('ಾ', 1442),\n",
       " ('ක', 1443),\n",
       " ('ය', 1444),\n",
       " ('ර', 1445),\n",
       " ('ල', 1446),\n",
       " ('ව', 1447),\n",
       " ('ා', 1448),\n",
       " ('ก', 1449),\n",
       " ('ง', 1450),\n",
       " ('ต', 1451),\n",
       " ('ท', 1452),\n",
       " ('น', 1453),\n",
       " ('พ', 1454),\n",
       " ('ม', 1455),\n",
       " ('ย', 1456),\n",
       " ('ร', 1457),\n",
       " ('ล', 1458),\n",
       " ('ว', 1459),\n",
       " ('ส', 1460),\n",
       " ('อ', 1461),\n",
       " ('า', 1462),\n",
       " ('เ', 1463),\n",
       " ('་', 1464),\n",
       " ('།', 1465),\n",
       " ('ག', 1466),\n",
       " ('ང', 1467),\n",
       " ('ད', 1468),\n",
       " ('ན', 1469),\n",
       " ('པ', 1470),\n",
       " ('བ', 1471),\n",
       " ('མ', 1472),\n",
       " ('འ', 1473),\n",
       " ('ར', 1474),\n",
       " ('ལ', 1475),\n",
       " ('ས', 1476),\n",
       " ('မ', 1477),\n",
       " ('ა', 1478),\n",
       " ('ბ', 1479),\n",
       " ('გ', 1480),\n",
       " ('დ', 1481),\n",
       " ('ე', 1482),\n",
       " ('ვ', 1483),\n",
       " ('თ', 1484),\n",
       " ('ი', 1485),\n",
       " ('კ', 1486),\n",
       " ('ლ', 1487),\n",
       " ('მ', 1488),\n",
       " ('ნ', 1489),\n",
       " ('ო', 1490),\n",
       " ('რ', 1491),\n",
       " ('ს', 1492),\n",
       " ('ტ', 1493),\n",
       " ('უ', 1494),\n",
       " ('ᄀ', 1495),\n",
       " ('ᄂ', 1496),\n",
       " ('ᄃ', 1497),\n",
       " ('ᄅ', 1498),\n",
       " ('ᄆ', 1499),\n",
       " ('ᄇ', 1500),\n",
       " ('ᄉ', 1501),\n",
       " ('ᄊ', 1502),\n",
       " ('ᄋ', 1503),\n",
       " ('ᄌ', 1504),\n",
       " ('ᄎ', 1505),\n",
       " ('ᄏ', 1506),\n",
       " ('ᄐ', 1507),\n",
       " ('ᄑ', 1508),\n",
       " ('ᄒ', 1509),\n",
       " ('ᅡ', 1510),\n",
       " ('ᅢ', 1511),\n",
       " ('ᅥ', 1512),\n",
       " ('ᅦ', 1513),\n",
       " ('ᅧ', 1514),\n",
       " ('ᅩ', 1515),\n",
       " ('ᅪ', 1516),\n",
       " ('ᅭ', 1517),\n",
       " ('ᅮ', 1518),\n",
       " ('ᅯ', 1519),\n",
       " ('ᅲ', 1520),\n",
       " ('ᅳ', 1521),\n",
       " ('ᅴ', 1522),\n",
       " ('ᅵ', 1523),\n",
       " ('ᆨ', 1524),\n",
       " ('ᆫ', 1525),\n",
       " ('ᆯ', 1526),\n",
       " ('ᆷ', 1527),\n",
       " ('ᆸ', 1528),\n",
       " ('ᆼ', 1529),\n",
       " ('ᴬ', 1530),\n",
       " ('ᴮ', 1531),\n",
       " ('ᴰ', 1532),\n",
       " ('ᴵ', 1533),\n",
       " ('ᴺ', 1534),\n",
       " ('ᵀ', 1535),\n",
       " ('ᵃ', 1536),\n",
       " ('ᵇ', 1537),\n",
       " ('ᵈ', 1538),\n",
       " ('ᵉ', 1539),\n",
       " ('ᵍ', 1540),\n",
       " ('ᵏ', 1541),\n",
       " ('ᵐ', 1542),\n",
       " ('ᵒ', 1543),\n",
       " ('ᵖ', 1544),\n",
       " ('ᵗ', 1545),\n",
       " ('ᵘ', 1546),\n",
       " ('ᵢ', 1547),\n",
       " ('ᵣ', 1548),\n",
       " ('ᵤ', 1549),\n",
       " ('ᵥ', 1550),\n",
       " ('ᶜ', 1551),\n",
       " ('ᶠ', 1552),\n",
       " ('‐', 1553),\n",
       " ('‑', 1554),\n",
       " ('‒', 1555),\n",
       " ('―', 1558),\n",
       " ('‖', 1559),\n",
       " ('‘', 1560),\n",
       " ('’', 1561),\n",
       " ('‚', 1562),\n",
       " ('“', 1563),\n",
       " ('”', 1564),\n",
       " ('„', 1565),\n",
       " ('†', 1566),\n",
       " ('‡', 1567),\n",
       " ('…', 1569),\n",
       " ('‰', 1570),\n",
       " ('′', 1571),\n",
       " ('″', 1572),\n",
       " ('›', 1573),\n",
       " ('‿', 1574),\n",
       " ('⁄', 1575),\n",
       " ('⁰', 1576),\n",
       " ('ⁱ', 1577),\n",
       " ('⁴', 1578),\n",
       " ('⁵', 1579),\n",
       " ('⁶', 1580),\n",
       " ('⁷', 1581),\n",
       " ('⁸', 1582),\n",
       " ('⁹', 1583),\n",
       " ('⁺', 1584),\n",
       " ('⁻', 1585),\n",
       " ('ⁿ', 1586),\n",
       " ('₀', 1587),\n",
       " ('₁', 1588),\n",
       " ('₂', 1589),\n",
       " ('₃', 1590),\n",
       " ('₄', 1591),\n",
       " ('₅', 1592),\n",
       " ('₆', 1593),\n",
       " ('₇', 1594),\n",
       " ('₈', 1595),\n",
       " ('₉', 1596),\n",
       " ('₊', 1597),\n",
       " ('₍', 1598),\n",
       " ('₎', 1599),\n",
       " ('ₐ', 1600),\n",
       " ('ₑ', 1601),\n",
       " ('ₒ', 1602),\n",
       " ('ₓ', 1603),\n",
       " ('ₕ', 1604),\n",
       " ('ₖ', 1605),\n",
       " ('ₗ', 1606),\n",
       " ('ₘ', 1607),\n",
       " ('ₙ', 1608),\n",
       " ('ₚ', 1609),\n",
       " ('ₛ', 1610),\n",
       " ('ₜ', 1611),\n",
       " ('₤', 1612),\n",
       " ('₩', 1613),\n",
       " ('€', 1614),\n",
       " ('₱', 1615),\n",
       " ('₹', 1616),\n",
       " ('ℓ', 1617),\n",
       " ('№', 1618),\n",
       " ('ℝ', 1619),\n",
       " ('™', 1620),\n",
       " ('⅓', 1621),\n",
       " ('⅔', 1622),\n",
       " ('←', 1623),\n",
       " ('↑', 1624),\n",
       " ('→', 1625),\n",
       " ('↓', 1626),\n",
       " ('↔', 1627),\n",
       " ('↦', 1628),\n",
       " ('⇄', 1629),\n",
       " ('⇌', 1630),\n",
       " ('⇒', 1631),\n",
       " ('∂', 1632),\n",
       " ('∅', 1633),\n",
       " ('∆', 1634),\n",
       " ('∇', 1635),\n",
       " ('∈', 1636),\n",
       " ('−', 1637),\n",
       " ('∗', 1638),\n",
       " ('∘', 1639),\n",
       " ('√', 1640),\n",
       " ('∞', 1641),\n",
       " ('∧', 1642),\n",
       " ('∨', 1643),\n",
       " ('∩', 1644),\n",
       " ('∪', 1645),\n",
       " ('≈', 1646),\n",
       " ('≡', 1647),\n",
       " ('≤', 1648),\n",
       " ('≥', 1649),\n",
       " ('⊂', 1650),\n",
       " ('⊆', 1651),\n",
       " ('⊕', 1652),\n",
       " ('⊗', 1653),\n",
       " ('⋅', 1654),\n",
       " ('─', 1655),\n",
       " ('│', 1656),\n",
       " ('■', 1657),\n",
       " ('▪', 1658),\n",
       " ('●', 1659),\n",
       " ('★', 1660),\n",
       " ('☆', 1661),\n",
       " ('☉', 1662),\n",
       " ('♠', 1663),\n",
       " ('♣', 1664),\n",
       " ('♥', 1665),\n",
       " ('♦', 1666),\n",
       " ('♭', 1667),\n",
       " ('♯', 1668),\n",
       " ('⟨', 1669),\n",
       " ('⟩', 1670),\n",
       " ('ⱼ', 1671),\n",
       " ('⺩', 1672),\n",
       " ('⺼', 1673),\n",
       " ('⽥', 1674),\n",
       " ('、', 1675),\n",
       " ('。', 1676),\n",
       " ('〈', 1677),\n",
       " ('〉', 1678),\n",
       " ('《', 1679),\n",
       " ('》', 1680),\n",
       " ('「', 1681),\n",
       " ('」', 1682),\n",
       " ('『', 1683),\n",
       " ('•', 1684),\n",
       " ('�', 1685),\n",
       " ('』', 1686),\n",
       " ('〜', 1687),\n",
       " ('あ', 1688),\n",
       " ('い', 1689),\n",
       " ('う', 1690),\n",
       " ('え', 1691),\n",
       " ('お', 1692),\n",
       " ('か', 1693),\n",
       " ('き', 1694),\n",
       " ('く', 1695),\n",
       " ('け', 1696),\n",
       " ('こ', 1697),\n",
       " ('さ', 1698),\n",
       " ('し', 1699),\n",
       " ('す', 1700),\n",
       " ('せ', 1701),\n",
       " ('そ', 1702),\n",
       " ('た', 1703),\n",
       " ('ち', 1704),\n",
       " ('っ', 1705),\n",
       " ('つ', 1706),\n",
       " ('て', 1707),\n",
       " ('と', 1708),\n",
       " ('な', 1709),\n",
       " ('に', 1710),\n",
       " ('ぬ', 1711),\n",
       " ('ね', 1712),\n",
       " ('の', 1713),\n",
       " ('は', 1714),\n",
       " ('ひ', 1715),\n",
       " ('ふ', 1716),\n",
       " ('へ', 1717),\n",
       " ('ほ', 1718),\n",
       " ('ま', 1719),\n",
       " ('み', 1720),\n",
       " ('む', 1721),\n",
       " ('め', 1722),\n",
       " ('も', 1723),\n",
       " ('や', 1724),\n",
       " ('ゆ', 1725),\n",
       " ('よ', 1726),\n",
       " ('ら', 1727),\n",
       " ('り', 1728),\n",
       " ('る', 1729),\n",
       " ('れ', 1730),\n",
       " ('ろ', 1731),\n",
       " ('を', 1732),\n",
       " ('ん', 1733),\n",
       " ('ァ', 1734),\n",
       " ('ア', 1735),\n",
       " ('ィ', 1736),\n",
       " ('イ', 1737),\n",
       " ('ウ', 1738),\n",
       " ('ェ', 1739),\n",
       " ('エ', 1740),\n",
       " ('オ', 1741),\n",
       " ('カ', 1742),\n",
       " ('キ', 1743),\n",
       " ('ク', 1744),\n",
       " ('ケ', 1745),\n",
       " ('コ', 1746),\n",
       " ('サ', 1747),\n",
       " ('シ', 1748),\n",
       " ('ス', 1749),\n",
       " ('セ', 1750),\n",
       " ('タ', 1751),\n",
       " ('チ', 1752),\n",
       " ('ッ', 1753),\n",
       " ('ツ', 1754),\n",
       " ('テ', 1755),\n",
       " ('ト', 1756),\n",
       " ('ナ', 1757),\n",
       " ('ニ', 1758),\n",
       " ('ノ', 1759),\n",
       " ('ハ', 1760),\n",
       " ('ヒ', 1761),\n",
       " ('フ', 1762),\n",
       " ('ヘ', 1763),\n",
       " ('ホ', 1764),\n",
       " ('マ', 1765),\n",
       " ('ミ', 1766),\n",
       " ('ム', 1767),\n",
       " ('メ', 1768),\n",
       " ('モ', 1769),\n",
       " ('ャ', 1770),\n",
       " ('ュ', 1771),\n",
       " ('ョ', 1772),\n",
       " ('ラ', 1773),\n",
       " ('リ', 1774),\n",
       " ('ル', 1775),\n",
       " ('レ', 1776),\n",
       " ('ロ', 1777),\n",
       " ('ワ', 1778),\n",
       " ('ン', 1779),\n",
       " ('・', 1780),\n",
       " ('ー', 1781),\n",
       " ('一', 1782),\n",
       " ('三', 1783),\n",
       " ('上', 1784),\n",
       " ('下', 1785),\n",
       " ('不', 1786),\n",
       " ('世', 1787),\n",
       " ('中', 1788),\n",
       " ('主', 1789),\n",
       " ('久', 1790),\n",
       " ('之', 1791),\n",
       " ('也', 1792),\n",
       " ('事', 1793),\n",
       " ('二', 1794),\n",
       " ('五', 1795),\n",
       " ('井', 1796),\n",
       " ('京', 1797),\n",
       " ('人', 1798),\n",
       " ('亻', 1799),\n",
       " ('仁', 1800),\n",
       " ('介', 1801),\n",
       " ('代', 1802),\n",
       " ('仮', 1803),\n",
       " ('伊', 1804),\n",
       " ('会', 1805),\n",
       " ('佐', 1806),\n",
       " ('侍', 1807),\n",
       " ('保', 1808),\n",
       " ('信', 1809),\n",
       " ('健', 1810),\n",
       " ('元', 1811),\n",
       " ('光', 1812),\n",
       " ('八', 1813),\n",
       " ('公', 1814),\n",
       " ('内', 1815),\n",
       " ('出', 1816),\n",
       " ('分', 1817),\n",
       " ('前', 1818),\n",
       " ('劉', 1819),\n",
       " ('力', 1820),\n",
       " ('加', 1821),\n",
       " ('勝', 1822),\n",
       " ('北', 1823),\n",
       " ('区', 1824),\n",
       " ('十', 1825),\n",
       " ('千', 1826),\n",
       " ('南', 1827),\n",
       " ('博', 1828),\n",
       " ('原', 1829),\n",
       " ('口', 1830),\n",
       " ('古', 1831),\n",
       " ('史', 1832),\n",
       " ('司', 1833),\n",
       " ('合', 1834),\n",
       " ('吉', 1835),\n",
       " ('同', 1836),\n",
       " ('名', 1837),\n",
       " ('和', 1838),\n",
       " ('囗', 1839),\n",
       " ('四', 1840),\n",
       " ('国', 1841),\n",
       " ('國', 1842),\n",
       " ('土', 1843),\n",
       " ('地', 1844),\n",
       " ('坂', 1845),\n",
       " ('城', 1846),\n",
       " ('堂', 1847),\n",
       " ('場', 1848),\n",
       " ('士', 1849),\n",
       " ('夏', 1850),\n",
       " ('外', 1851),\n",
       " ('大', 1852),\n",
       " ('天', 1853),\n",
       " ('太', 1854),\n",
       " ('夫', 1855),\n",
       " ('奈', 1856),\n",
       " ('女', 1857),\n",
       " ('子', 1858),\n",
       " ('学', 1859),\n",
       " ('宀', 1860),\n",
       " ('宇', 1861),\n",
       " ('安', 1862),\n",
       " ('宗', 1863),\n",
       " ('定', 1864),\n",
       " ('宣', 1865),\n",
       " ('宮', 1866),\n",
       " ('家', 1867),\n",
       " ('宿', 1868),\n",
       " ('寺', 1869),\n",
       " ('將', 1870),\n",
       " ('小', 1871),\n",
       " ('尚', 1872),\n",
       " ('山', 1873),\n",
       " ('岡', 1874),\n",
       " ('島', 1875),\n",
       " ('崎', 1876),\n",
       " ('川', 1877),\n",
       " ('州', 1878),\n",
       " ('巿', 1879),\n",
       " ('帝', 1880),\n",
       " ('平', 1881),\n",
       " ('年', 1882),\n",
       " ('幸', 1883),\n",
       " ('广', 1884),\n",
       " ('弘', 1885),\n",
       " ('張', 1886),\n",
       " ('彳', 1887),\n",
       " ('後', 1888),\n",
       " ('御', 1889),\n",
       " ('德', 1890),\n",
       " ('心', 1891),\n",
       " ('忄', 1892),\n",
       " ('志', 1893),\n",
       " ('忠', 1894),\n",
       " ('愛', 1895),\n",
       " ('成', 1896),\n",
       " ('我', 1897),\n",
       " ('戦', 1898),\n",
       " ('戸', 1899),\n",
       " ('手', 1900),\n",
       " ('扌', 1901),\n",
       " ('政', 1902),\n",
       " ('文', 1903),\n",
       " ('新', 1904),\n",
       " ('方', 1905),\n",
       " ('日', 1906),\n",
       " ('明', 1907),\n",
       " ('星', 1908),\n",
       " ('春', 1909),\n",
       " ('昭', 1910),\n",
       " ('智', 1911),\n",
       " ('曲', 1912),\n",
       " ('書', 1913),\n",
       " ('月', 1914),\n",
       " ('有', 1915),\n",
       " ('朝', 1916),\n",
       " ('木', 1917),\n",
       " ('本', 1918),\n",
       " ('李', 1919),\n",
       " ('村', 1920),\n",
       " ('東', 1921),\n",
       " ('松', 1922),\n",
       " ('林', 1923),\n",
       " ('森', 1924),\n",
       " ('楊', 1925),\n",
       " ('樹', 1926),\n",
       " ('橋', 1927),\n",
       " ('歌', 1928),\n",
       " ('止', 1929),\n",
       " ('正', 1930),\n",
       " ('武', 1931),\n",
       " ('比', 1932),\n",
       " ('氏', 1933),\n",
       " ('民', 1934),\n",
       " ('水', 1935),\n",
       " ('氵', 1936),\n",
       " ('氷', 1937),\n",
       " ('永', 1938),\n",
       " ('江', 1939),\n",
       " ('沢', 1940),\n",
       " ('河', 1941),\n",
       " ('治', 1942),\n",
       " ('法', 1943),\n",
       " ('海', 1944),\n",
       " ('清', 1945),\n",
       " ('漢', 1946),\n",
       " ('瀬', 1947),\n",
       " ('火', 1948),\n",
       " ('版', 1949),\n",
       " ('犬', 1950),\n",
       " ('王', 1951),\n",
       " ('生', 1952),\n",
       " ('田', 1953),\n",
       " ('男', 1954),\n",
       " ('疒', 1955),\n",
       " ('発', 1956),\n",
       " ('白', 1957),\n",
       " ('的', 1958),\n",
       " ('皇', 1959),\n",
       " ('目', 1960),\n",
       " ('相', 1961),\n",
       " ('省', 1962),\n",
       " ('真', 1963),\n",
       " ('石', 1964),\n",
       " ('示', 1965),\n",
       " ('社', 1966),\n",
       " ('神', 1967),\n",
       " ('福', 1968),\n",
       " ('禾', 1969),\n",
       " ('秀', 1970),\n",
       " ('秋', 1971),\n",
       " ('空', 1972),\n",
       " ('立', 1973),\n",
       " ('章', 1974),\n",
       " ('竹', 1975),\n",
       " ('糹', 1976),\n",
       " ('美', 1977),\n",
       " ('義', 1978),\n",
       " ('耳', 1979),\n",
       " ('良', 1980),\n",
       " ('艹', 1981),\n",
       " ('花', 1982),\n",
       " ('英', 1983),\n",
       " ('華', 1984),\n",
       " ('葉', 1985),\n",
       " ('藤', 1986),\n",
       " ('行', 1987),\n",
       " ('街', 1988),\n",
       " ('西', 1989),\n",
       " ('見', 1990),\n",
       " ('訁', 1991),\n",
       " ('語', 1992),\n",
       " ('谷', 1993),\n",
       " ('貝', 1994),\n",
       " ('貴', 1995),\n",
       " ('車', 1996),\n",
       " ('軍', 1997),\n",
       " ('辶', 1998),\n",
       " ('道', 1999),\n",
       " ('郎', 2000),\n",
       " ('郡', 2001),\n",
       " ('部', 2002),\n",
       " ('都', 2003),\n",
       " ('里', 2004),\n",
       " ('野', 2005),\n",
       " ('金', 2006),\n",
       " ('鈴', 2007),\n",
       " ('镇', 2008),\n",
       " ('長', 2009),\n",
       " ('門', 2010),\n",
       " ('間', 2011),\n",
       " ('阝', 2012),\n",
       " ('阿', 2013),\n",
       " ('陳', 2014),\n",
       " ('陽', 2015),\n",
       " ('雄', 2016),\n",
       " ('青', 2017),\n",
       " ('面', 2018),\n",
       " ('風', 2019),\n",
       " ('食', 2020),\n",
       " ('香', 2021),\n",
       " ('馬', 2022),\n",
       " ('高', 2023),\n",
       " ('龍', 2024),\n",
       " ('龸', 2025),\n",
       " ('ﬁ', 2026),\n",
       " ('ﬂ', 2027),\n",
       " ('！', 2028),\n",
       " ('（', 2029),\n",
       " ('）', 2030),\n",
       " ('，', 2031),\n",
       " ('－', 2032),\n",
       " ('．', 2033),\n",
       " ('／', 2034),\n",
       " ('：', 2035),\n",
       " ('？', 2036),\n",
       " ('～', 2037),\n",
       " ('ও', 2038),\n",
       " ('করে', 2039),\n",
       " ('##ের', 2040),\n",
       " ('হয়', 2041),\n",
       " ('এবং', 2042),\n",
       " ('থেকে', 2043),\n",
       " ('না', 2044),\n",
       " ('এই', 2045),\n",
       " ('##র', 2046),\n",
       " ('করা', 2047),\n",
       " ('', 2048),\n",
       " ('তিনি', 2049),\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_tokenizer = AutoTokenizer.from_pretrained(\"sagorsarker/bangla-bert-base\")\n",
    "ss_vocab = ss_tokenizer.get_vocab()\n",
    "\n",
    "ss_vocab = sorted(ss_vocab.items(), key=lambda i:i[1])\n",
    "# ss_vocab[800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[unused895]', 900),\n",
       " ('[unused896]', 901),\n",
       " ('[unused897]', 902),\n",
       " ('[unused898]', 903),\n",
       " ('[unused899]', 904),\n",
       " ('[unused900]', 905),\n",
       " ('[unused901]', 906),\n",
       " ('[unused902]', 907),\n",
       " ('[unused903]', 908),\n",
       " ('[unused904]', 909),\n",
       " ('[unused905]', 910),\n",
       " ('[unused906]', 911),\n",
       " ('[unused907]', 912),\n",
       " ('[unused908]', 913),\n",
       " ('[unused909]', 914),\n",
       " ('[unused910]', 915),\n",
       " ('[unused911]', 916),\n",
       " ('[unused912]', 917),\n",
       " ('[unused913]', 918),\n",
       " ('[unused914]', 919),\n",
       " ('[unused915]', 920),\n",
       " ('[unused916]', 921),\n",
       " ('[unused917]', 922),\n",
       " ('[unused918]', 923),\n",
       " ('[unused919]', 924),\n",
       " ('[unused920]', 925),\n",
       " ('[unused921]', 926),\n",
       " ('[unused922]', 927),\n",
       " ('[unused923]', 928),\n",
       " ('[unused924]', 929),\n",
       " ('[unused925]', 930),\n",
       " ('[unused926]', 931),\n",
       " ('[unused927]', 932),\n",
       " ('[unused928]', 933),\n",
       " ('[unused929]', 934),\n",
       " ('[unused930]', 935),\n",
       " ('[unused931]', 936),\n",
       " ('[unused932]', 937),\n",
       " ('[unused933]', 938),\n",
       " ('[unused934]', 939),\n",
       " ('[unused935]', 940),\n",
       " ('[unused936]', 941),\n",
       " ('[unused937]', 942),\n",
       " ('[unused938]', 943),\n",
       " ('[unused939]', 944),\n",
       " ('[unused940]', 945),\n",
       " ('[unused941]', 946),\n",
       " ('[unused942]', 947),\n",
       " ('[unused943]', 948),\n",
       " ('[unused944]', 949),\n",
       " ('[unused945]', 950),\n",
       " ('[unused946]', 951),\n",
       " ('[unused947]', 952),\n",
       " ('[unused948]', 953),\n",
       " ('[unused949]', 954),\n",
       " ('[unused950]', 955),\n",
       " ('[unused951]', 956),\n",
       " ('[unused952]', 957),\n",
       " ('[unused953]', 958),\n",
       " ('[unused954]', 959),\n",
       " ('[unused955]', 960),\n",
       " ('[unused956]', 961),\n",
       " ('[unused957]', 962),\n",
       " ('[unused958]', 963),\n",
       " ('[unused959]', 964),\n",
       " ('[unused960]', 965),\n",
       " ('[unused961]', 966),\n",
       " ('[unused962]', 967),\n",
       " ('[unused963]', 968),\n",
       " ('[unused964]', 969),\n",
       " ('[unused965]', 970),\n",
       " ('[unused966]', 971),\n",
       " ('[unused967]', 972),\n",
       " ('[unused968]', 973),\n",
       " ('[unused969]', 974),\n",
       " ('[unused970]', 975),\n",
       " ('[unused971]', 976),\n",
       " ('[unused972]', 977),\n",
       " ('[unused973]', 978),\n",
       " ('[unused974]', 979),\n",
       " ('[unused975]', 980),\n",
       " ('[unused976]', 981),\n",
       " ('[unused977]', 982),\n",
       " ('[unused978]', 983),\n",
       " ('[unused979]', 984),\n",
       " ('[unused980]', 985),\n",
       " ('[unused981]', 986),\n",
       " ('[unused982]', 987),\n",
       " ('[unused983]', 988),\n",
       " ('[unused984]', 989),\n",
       " ('[unused985]', 990),\n",
       " ('[unused986]', 991),\n",
       " ('[unused987]', 992),\n",
       " ('[unused988]', 993),\n",
       " ('[unused989]', 994),\n",
       " ('[unused990]', 995),\n",
       " ('[unused991]', 996),\n",
       " ('[unused992]', 997),\n",
       " ('[unused993]', 998),\n",
       " ('!', 999),\n",
       " ('\"', 1000),\n",
       " ('#', 1001),\n",
       " ('$', 1002),\n",
       " ('৳', 1003),\n",
       " ('%', 1004),\n",
       " ('&', 1005),\n",
       " (\"'\", 1006),\n",
       " ('(', 1007),\n",
       " (')', 1008),\n",
       " ('*', 1009),\n",
       " ('+', 1010),\n",
       " (',', 1011),\n",
       " ('-', 1012),\n",
       " ('.', 1013),\n",
       " ('।', 1014),\n",
       " ('/', 1019),\n",
       " ('০', 1020),\n",
       " ('১', 1021),\n",
       " ('২', 1022),\n",
       " ('৩', 1023),\n",
       " ('৪', 1024),\n",
       " ('৫', 1025),\n",
       " ('৬', 1026),\n",
       " ('৭', 1027),\n",
       " ('৮', 1028),\n",
       " ('৯', 1029),\n",
       " ('0', 1030),\n",
       " ('1', 1031),\n",
       " ('2', 1032),\n",
       " ('3', 1033),\n",
       " ('4', 1034),\n",
       " ('5', 1035),\n",
       " ('6', 1036),\n",
       " ('7', 1037),\n",
       " ('8', 1038),\n",
       " ('9', 1039),\n",
       " (':', 1040),\n",
       " (';', 1041),\n",
       " ('<', 1042),\n",
       " ('=', 1043),\n",
       " ('>', 1044),\n",
       " ('?', 1045),\n",
       " ('@', 1046),\n",
       " ('[', 1047),\n",
       " ('\\\\', 1048),\n",
       " (']', 1049),\n",
       " ('^', 1050),\n",
       " ('_', 1051),\n",
       " ('`', 1052),\n",
       " ('ঊ', 1058),\n",
       " ('ঋ', 1059),\n",
       " ('ঔ', 1063),\n",
       " ('ণ', 1078),\n",
       " ('ড়', 1096),\n",
       " ('ঢ়', 1097),\n",
       " ('য়', 1098),\n",
       " ('ং', 1100),\n",
       " ('ঁ', 1102),\n",
       " ('া', 1103),\n",
       " ('ি', 1104),\n",
       " ('ী', 1105),\n",
       " ('ু', 1106),\n",
       " ('ৃ', 1107),\n",
       " ('ে', 1108),\n",
       " ('ৈ', 1109),\n",
       " ('ো', 1110),\n",
       " ('ৌ', 1111),\n",
       " ('্র', 1114),\n",
       " ('্ন', 1115),\n",
       " ('্ম', 1116),\n",
       " ('্ল', 1117),\n",
       " ('্ব', 1118),\n",
       " ('a', 1119),\n",
       " ('b', 1120),\n",
       " ('c', 1121),\n",
       " ('d', 1122),\n",
       " ('e', 1123),\n",
       " ('f', 1124),\n",
       " ('g', 1125),\n",
       " ('h', 1126),\n",
       " ('i', 1127),\n",
       " ('j', 1128),\n",
       " ('k', 1129),\n",
       " ('l', 1130),\n",
       " ('m', 1131),\n",
       " ('n', 1132),\n",
       " ('o', 1133),\n",
       " ('p', 1134),\n",
       " ('q', 1135),\n",
       " ('r', 1136),\n",
       " ('s', 1137),\n",
       " ('t', 1138),\n",
       " ('u', 1139),\n",
       " ('v', 1140),\n",
       " ('w', 1141),\n",
       " ('x', 1142),\n",
       " ('y', 1143),\n",
       " ('z', 1144),\n",
       " ('{', 1145),\n",
       " ('|', 1146),\n",
       " ('}', 1147),\n",
       " ('~', 1148),\n",
       " ('¡', 1149),\n",
       " ('¢', 1150),\n",
       " ('£', 1151),\n",
       " ('¤', 1152),\n",
       " ('¥', 1153),\n",
       " ('¦', 1154),\n",
       " ('§', 1155),\n",
       " ('¨', 1156),\n",
       " ('©', 1157),\n",
       " ('ª', 1158),\n",
       " ('«', 1159),\n",
       " ('¬', 1160),\n",
       " ('®', 1161),\n",
       " ('°', 1162),\n",
       " ('±', 1163),\n",
       " ('²', 1164),\n",
       " ('³', 1165),\n",
       " ('´', 1166),\n",
       " ('µ', 1167),\n",
       " ('¶', 1168),\n",
       " ('·', 1169),\n",
       " ('¹', 1170),\n",
       " ('º', 1171),\n",
       " ('»', 1172),\n",
       " ('¼', 1173),\n",
       " ('½', 1174),\n",
       " ('¾', 1175),\n",
       " ('¿', 1176),\n",
       " ('×', 1177),\n",
       " ('ß', 1178),\n",
       " ('æ', 1179),\n",
       " ('ð', 1180),\n",
       " ('÷', 1181),\n",
       " ('ø', 1182),\n",
       " ('þ', 1183),\n",
       " ('đ', 1184),\n",
       " ('ħ', 1185),\n",
       " ('ı', 1186),\n",
       " ('ł', 1187),\n",
       " ('ŋ', 1188),\n",
       " ('œ', 1189),\n",
       " ('ƒ', 1190),\n",
       " ('ɐ', 1191),\n",
       " ('ɑ', 1192),\n",
       " ('ɒ', 1193),\n",
       " ('ɔ', 1194),\n",
       " ('ɕ', 1195),\n",
       " ('ə', 1196),\n",
       " ('ɛ', 1197),\n",
       " ('ɡ', 1198),\n",
       " ('ɣ', 1199),\n",
       " ('ɨ', 1200),\n",
       " ('ɪ', 1201),\n",
       " ('ɫ', 1202),\n",
       " ('ɬ', 1203),\n",
       " ('ɯ', 1204),\n",
       " ('ɲ', 1205),\n",
       " ('ɴ', 1206),\n",
       " ('ɹ', 1207),\n",
       " ('ɾ', 1208),\n",
       " ('ʀ', 1209),\n",
       " ('ʁ', 1210),\n",
       " ('ʂ', 1211),\n",
       " ('ʃ', 1212),\n",
       " ('ʉ', 1213),\n",
       " ('ʊ', 1214),\n",
       " ('ʋ', 1215),\n",
       " ('ʌ', 1216),\n",
       " ('ʎ', 1217),\n",
       " ('ʐ', 1218),\n",
       " ('ʑ', 1219),\n",
       " ('ʒ', 1220),\n",
       " ('ʔ', 1221),\n",
       " ('ʰ', 1222),\n",
       " ('ʲ', 1223),\n",
       " ('ʳ', 1224),\n",
       " ('ʷ', 1225),\n",
       " ('ʸ', 1226),\n",
       " ('ʻ', 1227),\n",
       " ('ʼ', 1228),\n",
       " ('ʾ', 1229),\n",
       " ('ʿ', 1230),\n",
       " ('ˈ', 1231),\n",
       " ('ː', 1232),\n",
       " ('ˡ', 1233),\n",
       " ('ˢ', 1234),\n",
       " ('ˣ', 1235),\n",
       " ('ˤ', 1236),\n",
       " ('α', 1237),\n",
       " ('β', 1238),\n",
       " ('γ', 1239),\n",
       " ('δ', 1240),\n",
       " ('ε', 1241),\n",
       " ('ζ', 1242),\n",
       " ('η', 1243),\n",
       " ('θ', 1244),\n",
       " ('ι', 1245),\n",
       " ('κ', 1246),\n",
       " ('λ', 1247),\n",
       " ('μ', 1248),\n",
       " ('ν', 1249),\n",
       " ('ξ', 1250),\n",
       " ('ο', 1251),\n",
       " ('π', 1252),\n",
       " ('ρ', 1253),\n",
       " ('ς', 1254),\n",
       " ('σ', 1255),\n",
       " ('τ', 1256),\n",
       " ('υ', 1257),\n",
       " ('φ', 1258),\n",
       " ('χ', 1259),\n",
       " ('ψ', 1260),\n",
       " ('ω', 1261),\n",
       " ('а', 1262),\n",
       " ('б', 1263),\n",
       " ('в', 1264),\n",
       " ('г', 1265),\n",
       " ('д', 1266),\n",
       " ('е', 1267),\n",
       " ('ж', 1268),\n",
       " ('з', 1269),\n",
       " ('и', 1270),\n",
       " ('к', 1271),\n",
       " ('л', 1272),\n",
       " ('м', 1273),\n",
       " ('н', 1274),\n",
       " ('о', 1275),\n",
       " ('п', 1276),\n",
       " ('р', 1277),\n",
       " ('с', 1278),\n",
       " ('т', 1279),\n",
       " ('у', 1280),\n",
       " ('ф', 1281),\n",
       " ('х', 1282),\n",
       " ('ц', 1283),\n",
       " ('ч', 1284),\n",
       " ('ш', 1285),\n",
       " ('щ', 1286),\n",
       " ('ъ', 1287),\n",
       " ('ы', 1288),\n",
       " ('ь', 1289),\n",
       " ('э', 1290),\n",
       " ('ю', 1291),\n",
       " ('я', 1292),\n",
       " ('ђ', 1293),\n",
       " ('є', 1294),\n",
       " ('і', 1295),\n",
       " ('ј', 1296),\n",
       " ('љ', 1297),\n",
       " ('њ', 1298),\n",
       " ('ћ', 1299),\n",
       " ('ӏ', 1300),\n",
       " ('ա', 1301),\n",
       " ('բ', 1302),\n",
       " ('գ', 1303),\n",
       " ('դ', 1304),\n",
       " ('ե', 1305),\n",
       " ('թ', 1306),\n",
       " ('ի', 1307),\n",
       " ('լ', 1308),\n",
       " ('կ', 1309),\n",
       " ('հ', 1310),\n",
       " ('մ', 1311),\n",
       " ('յ', 1312),\n",
       " ('ն', 1313),\n",
       " ('ո', 1314),\n",
       " ('պ', 1315),\n",
       " ('ս', 1316),\n",
       " ('վ', 1317),\n",
       " ('տ', 1318),\n",
       " ('ր', 1319),\n",
       " ('ւ', 1320),\n",
       " ('ք', 1321),\n",
       " ('־', 1322),\n",
       " ('א', 1323),\n",
       " ('ב', 1324),\n",
       " ('ג', 1325),\n",
       " ('ד', 1326),\n",
       " ('ה', 1327),\n",
       " ('ו', 1328),\n",
       " ('ז', 1329),\n",
       " ('ח', 1330),\n",
       " ('ט', 1331),\n",
       " ('י', 1332),\n",
       " ('ך', 1333),\n",
       " ('כ', 1334),\n",
       " ('ל', 1335),\n",
       " ('ם', 1336),\n",
       " ('מ', 1337),\n",
       " ('ן', 1338),\n",
       " ('נ', 1339),\n",
       " ('ס', 1340),\n",
       " ('ע', 1341),\n",
       " ('ף', 1342),\n",
       " ('פ', 1343),\n",
       " ('ץ', 1344),\n",
       " ('צ', 1345),\n",
       " ('ק', 1346),\n",
       " ('ר', 1347),\n",
       " ('ש', 1348),\n",
       " ('ת', 1349),\n",
       " ('،', 1350),\n",
       " ('ء', 1351),\n",
       " ('ا', 1352),\n",
       " ('ب', 1353),\n",
       " ('ة', 1354),\n",
       " ('ت', 1355),\n",
       " ('ث', 1356),\n",
       " ('ج', 1357),\n",
       " ('ح', 1358),\n",
       " ('خ', 1359),\n",
       " ('د', 1360),\n",
       " ('ذ', 1361),\n",
       " ('ر', 1362),\n",
       " ('ز', 1363),\n",
       " ('س', 1364),\n",
       " ('ش', 1365),\n",
       " ('ص', 1366),\n",
       " ('ض', 1367),\n",
       " ('ط', 1368),\n",
       " ('ظ', 1369),\n",
       " ('ع', 1370),\n",
       " ('غ', 1371),\n",
       " ('ـ', 1372),\n",
       " ('ف', 1373),\n",
       " ('ق', 1374),\n",
       " ('ك', 1375),\n",
       " ('ل', 1376),\n",
       " ('م', 1377),\n",
       " ('ن', 1378),\n",
       " ('ه', 1379),\n",
       " ('و', 1380),\n",
       " ('ى', 1381),\n",
       " ('ي', 1382),\n",
       " ('ٹ', 1383),\n",
       " ('پ', 1384),\n",
       " ('چ', 1385),\n",
       " ('ک', 1386),\n",
       " ('گ', 1387),\n",
       " ('ں', 1388),\n",
       " ('ھ', 1389),\n",
       " ('ہ', 1390),\n",
       " ('ی', 1391),\n",
       " ('ے', 1392),\n",
       " ('अ', 1393),\n",
       " ('आ', 1394),\n",
       " ('उ', 1395),\n",
       " ('ए', 1396),\n",
       " ('क', 1397),\n",
       " ('ख', 1398),\n",
       " ('ग', 1399),\n",
       " ('च', 1400),\n",
       " ('ज', 1401),\n",
       " ('ट', 1402),\n",
       " ('ड', 1403),\n",
       " ('ण', 1404),\n",
       " ('त', 1405),\n",
       " ('थ', 1406),\n",
       " ('द', 1407),\n",
       " ('ध', 1408),\n",
       " ('न', 1409),\n",
       " ('प', 1410),\n",
       " ('ब', 1411),\n",
       " ('भ', 1412),\n",
       " ('म', 1413),\n",
       " ('य', 1414),\n",
       " ('र', 1415),\n",
       " ('ल', 1416),\n",
       " ('व', 1417),\n",
       " ('श', 1418),\n",
       " ('ष', 1419),\n",
       " ('स', 1420),\n",
       " ('ह', 1421),\n",
       " ('க', 1422),\n",
       " ('ச', 1423),\n",
       " ('ட', 1424),\n",
       " ('த', 1425),\n",
       " ('ந', 1426),\n",
       " ('ன', 1427),\n",
       " ('ப', 1428),\n",
       " ('ம', 1429),\n",
       " ('ய', 1430),\n",
       " ('ர', 1431),\n",
       " ('ல', 1432),\n",
       " ('ள', 1433),\n",
       " ('வ', 1434),\n",
       " ('ா', 1435),\n",
       " ('ி', 1436),\n",
       " ('ு', 1437),\n",
       " ('ே', 1438),\n",
       " ('ை', 1439),\n",
       " ('ನ', 1440),\n",
       " ('ರ', 1441),\n",
       " ('ಾ', 1442),\n",
       " ('ක', 1443),\n",
       " ('ය', 1444),\n",
       " ('ර', 1445),\n",
       " ('ල', 1446),\n",
       " ('ව', 1447),\n",
       " ('ා', 1448),\n",
       " ('ก', 1449),\n",
       " ('ง', 1450),\n",
       " ('ต', 1451),\n",
       " ('ท', 1452),\n",
       " ('น', 1453),\n",
       " ('พ', 1454),\n",
       " ('ม', 1455),\n",
       " ('ย', 1456),\n",
       " ('ร', 1457),\n",
       " ('ล', 1458),\n",
       " ('ว', 1459),\n",
       " ('ส', 1460),\n",
       " ('อ', 1461),\n",
       " ('า', 1462),\n",
       " ('เ', 1463),\n",
       " ('་', 1464),\n",
       " ('།', 1465),\n",
       " ('ག', 1466),\n",
       " ('ང', 1467),\n",
       " ('ད', 1468),\n",
       " ('ན', 1469),\n",
       " ('པ', 1470),\n",
       " ('བ', 1471),\n",
       " ('མ', 1472),\n",
       " ('འ', 1473),\n",
       " ('ར', 1474),\n",
       " ('ལ', 1475),\n",
       " ('ས', 1476),\n",
       " ('မ', 1477),\n",
       " ('ა', 1478),\n",
       " ('ბ', 1479),\n",
       " ('გ', 1480),\n",
       " ('დ', 1481),\n",
       " ('ე', 1482),\n",
       " ('ვ', 1483),\n",
       " ('თ', 1484),\n",
       " ('ი', 1485),\n",
       " ('კ', 1486),\n",
       " ('ლ', 1487),\n",
       " ('მ', 1488),\n",
       " ('ნ', 1489),\n",
       " ('ო', 1490),\n",
       " ('რ', 1491),\n",
       " ('ს', 1492),\n",
       " ('ტ', 1493),\n",
       " ('უ', 1494),\n",
       " ('ᄀ', 1495),\n",
       " ('ᄂ', 1496),\n",
       " ('ᄃ', 1497),\n",
       " ('ᄅ', 1498),\n",
       " ('ᄆ', 1499),\n",
       " ('ᄇ', 1500),\n",
       " ('ᄉ', 1501),\n",
       " ('ᄊ', 1502),\n",
       " ('ᄋ', 1503),\n",
       " ('ᄌ', 1504),\n",
       " ('ᄎ', 1505),\n",
       " ('ᄏ', 1506),\n",
       " ('ᄐ', 1507),\n",
       " ('ᄑ', 1508),\n",
       " ('ᄒ', 1509),\n",
       " ('ᅡ', 1510),\n",
       " ('ᅢ', 1511),\n",
       " ('ᅥ', 1512),\n",
       " ('ᅦ', 1513),\n",
       " ('ᅧ', 1514),\n",
       " ('ᅩ', 1515),\n",
       " ('ᅪ', 1516),\n",
       " ('ᅭ', 1517),\n",
       " ('ᅮ', 1518),\n",
       " ('ᅯ', 1519),\n",
       " ('ᅲ', 1520),\n",
       " ('ᅳ', 1521),\n",
       " ('ᅴ', 1522),\n",
       " ('ᅵ', 1523),\n",
       " ('ᆨ', 1524),\n",
       " ('ᆫ', 1525),\n",
       " ('ᆯ', 1526),\n",
       " ('ᆷ', 1527),\n",
       " ('ᆸ', 1528),\n",
       " ('ᆼ', 1529),\n",
       " ('ᴬ', 1530),\n",
       " ('ᴮ', 1531),\n",
       " ('ᴰ', 1532),\n",
       " ('ᴵ', 1533),\n",
       " ('ᴺ', 1534),\n",
       " ('ᵀ', 1535),\n",
       " ('ᵃ', 1536),\n",
       " ('ᵇ', 1537),\n",
       " ('ᵈ', 1538),\n",
       " ('ᵉ', 1539),\n",
       " ('ᵍ', 1540),\n",
       " ('ᵏ', 1541),\n",
       " ('ᵐ', 1542),\n",
       " ('ᵒ', 1543),\n",
       " ('ᵖ', 1544),\n",
       " ('ᵗ', 1545),\n",
       " ('ᵘ', 1546),\n",
       " ('ᵢ', 1547),\n",
       " ('ᵣ', 1548),\n",
       " ('ᵤ', 1549),\n",
       " ('ᵥ', 1550),\n",
       " ('ᶜ', 1551),\n",
       " ('ᶠ', 1552),\n",
       " ('‐', 1553),\n",
       " ('‑', 1554),\n",
       " ('‒', 1555),\n",
       " ('―', 1558),\n",
       " ('‖', 1559),\n",
       " ('‘', 1560),\n",
       " ('’', 1561),\n",
       " ('‚', 1562),\n",
       " ('“', 1563),\n",
       " ('”', 1564),\n",
       " ('„', 1565),\n",
       " ('†', 1566),\n",
       " ('‡', 1567),\n",
       " ('…', 1569),\n",
       " ('‰', 1570),\n",
       " ('′', 1571),\n",
       " ('″', 1572),\n",
       " ('›', 1573),\n",
       " ('‿', 1574),\n",
       " ('⁄', 1575),\n",
       " ('⁰', 1576),\n",
       " ('ⁱ', 1577),\n",
       " ('⁴', 1578),\n",
       " ('⁵', 1579),\n",
       " ('⁶', 1580),\n",
       " ('⁷', 1581),\n",
       " ('⁸', 1582),\n",
       " ('⁹', 1583),\n",
       " ('⁺', 1584),\n",
       " ('⁻', 1585),\n",
       " ('ⁿ', 1586),\n",
       " ('₀', 1587),\n",
       " ('₁', 1588),\n",
       " ('₂', 1589),\n",
       " ('₃', 1590),\n",
       " ('₄', 1591),\n",
       " ('₅', 1592),\n",
       " ('₆', 1593),\n",
       " ('₇', 1594),\n",
       " ('₈', 1595),\n",
       " ('₉', 1596),\n",
       " ('₊', 1597),\n",
       " ('₍', 1598),\n",
       " ('₎', 1599),\n",
       " ('ₐ', 1600),\n",
       " ('ₑ', 1601),\n",
       " ('ₒ', 1602),\n",
       " ('ₓ', 1603),\n",
       " ('ₕ', 1604),\n",
       " ('ₖ', 1605),\n",
       " ('ₗ', 1606),\n",
       " ('ₘ', 1607),\n",
       " ('ₙ', 1608),\n",
       " ('ₚ', 1609),\n",
       " ('ₛ', 1610),\n",
       " ('ₜ', 1611),\n",
       " ('₤', 1612),\n",
       " ('₩', 1613),\n",
       " ('€', 1614),\n",
       " ('₱', 1615),\n",
       " ('₹', 1616),\n",
       " ('ℓ', 1617),\n",
       " ('№', 1618),\n",
       " ('ℝ', 1619),\n",
       " ('™', 1620),\n",
       " ('⅓', 1621),\n",
       " ('⅔', 1622),\n",
       " ('←', 1623),\n",
       " ('↑', 1624),\n",
       " ('→', 1625),\n",
       " ('↓', 1626),\n",
       " ('↔', 1627),\n",
       " ('↦', 1628),\n",
       " ('⇄', 1629),\n",
       " ('⇌', 1630),\n",
       " ('⇒', 1631),\n",
       " ('∂', 1632),\n",
       " ('∅', 1633),\n",
       " ('∆', 1634),\n",
       " ('∇', 1635),\n",
       " ('∈', 1636),\n",
       " ('−', 1637),\n",
       " ('∗', 1638),\n",
       " ('∘', 1639),\n",
       " ('√', 1640),\n",
       " ('∞', 1641),\n",
       " ('∧', 1642),\n",
       " ('∨', 1643),\n",
       " ('∩', 1644),\n",
       " ('∪', 1645),\n",
       " ('≈', 1646),\n",
       " ('≡', 1647),\n",
       " ('≤', 1648),\n",
       " ('≥', 1649),\n",
       " ('⊂', 1650),\n",
       " ('⊆', 1651),\n",
       " ('⊕', 1652),\n",
       " ('⊗', 1653),\n",
       " ('⋅', 1654),\n",
       " ('─', 1655),\n",
       " ('│', 1656),\n",
       " ('■', 1657),\n",
       " ('▪', 1658),\n",
       " ('●', 1659),\n",
       " ('★', 1660),\n",
       " ('☆', 1661),\n",
       " ('☉', 1662),\n",
       " ('♠', 1663),\n",
       " ('♣', 1664),\n",
       " ('♥', 1665),\n",
       " ('♦', 1666),\n",
       " ('♭', 1667),\n",
       " ('♯', 1668),\n",
       " ('⟨', 1669),\n",
       " ('⟩', 1670),\n",
       " ('ⱼ', 1671),\n",
       " ('⺩', 1672),\n",
       " ('⺼', 1673),\n",
       " ('⽥', 1674),\n",
       " ('、', 1675),\n",
       " ('。', 1676),\n",
       " ('〈', 1677),\n",
       " ('〉', 1678),\n",
       " ('《', 1679),\n",
       " ('》', 1680),\n",
       " ('「', 1681),\n",
       " ('」', 1682),\n",
       " ('『', 1683),\n",
       " ('•', 1684),\n",
       " ('�', 1685),\n",
       " ('』', 1686),\n",
       " ('〜', 1687),\n",
       " ('あ', 1688),\n",
       " ('い', 1689),\n",
       " ('う', 1690),\n",
       " ('え', 1691),\n",
       " ('お', 1692),\n",
       " ('か', 1693),\n",
       " ('き', 1694),\n",
       " ('く', 1695),\n",
       " ('け', 1696),\n",
       " ('こ', 1697),\n",
       " ('さ', 1698),\n",
       " ('し', 1699),\n",
       " ('す', 1700),\n",
       " ('せ', 1701),\n",
       " ('そ', 1702),\n",
       " ('た', 1703),\n",
       " ('ち', 1704),\n",
       " ('っ', 1705),\n",
       " ('つ', 1706),\n",
       " ('て', 1707),\n",
       " ('と', 1708),\n",
       " ('な', 1709),\n",
       " ('に', 1710),\n",
       " ('ぬ', 1711),\n",
       " ('ね', 1712),\n",
       " ('の', 1713),\n",
       " ('は', 1714),\n",
       " ('ひ', 1715),\n",
       " ('ふ', 1716),\n",
       " ('へ', 1717),\n",
       " ('ほ', 1718),\n",
       " ('ま', 1719),\n",
       " ('み', 1720),\n",
       " ('む', 1721),\n",
       " ('め', 1722),\n",
       " ('も', 1723),\n",
       " ('や', 1724),\n",
       " ('ゆ', 1725),\n",
       " ('よ', 1726),\n",
       " ('ら', 1727),\n",
       " ('り', 1728),\n",
       " ('る', 1729),\n",
       " ('れ', 1730),\n",
       " ('ろ', 1731),\n",
       " ('を', 1732),\n",
       " ('ん', 1733),\n",
       " ('ァ', 1734),\n",
       " ('ア', 1735),\n",
       " ('ィ', 1736),\n",
       " ('イ', 1737),\n",
       " ('ウ', 1738),\n",
       " ('ェ', 1739),\n",
       " ('エ', 1740),\n",
       " ('オ', 1741),\n",
       " ('カ', 1742),\n",
       " ('キ', 1743),\n",
       " ('ク', 1744),\n",
       " ('ケ', 1745),\n",
       " ('コ', 1746),\n",
       " ('サ', 1747),\n",
       " ('シ', 1748),\n",
       " ('ス', 1749),\n",
       " ('セ', 1750),\n",
       " ('タ', 1751),\n",
       " ('チ', 1752),\n",
       " ('ッ', 1753),\n",
       " ('ツ', 1754),\n",
       " ('テ', 1755),\n",
       " ('ト', 1756),\n",
       " ('ナ', 1757),\n",
       " ('ニ', 1758),\n",
       " ('ノ', 1759),\n",
       " ('ハ', 1760),\n",
       " ('ヒ', 1761),\n",
       " ('フ', 1762),\n",
       " ('ヘ', 1763),\n",
       " ('ホ', 1764),\n",
       " ('マ', 1765),\n",
       " ('ミ', 1766),\n",
       " ('ム', 1767),\n",
       " ('メ', 1768),\n",
       " ('モ', 1769),\n",
       " ('ャ', 1770),\n",
       " ('ュ', 1771),\n",
       " ('ョ', 1772),\n",
       " ('ラ', 1773),\n",
       " ('リ', 1774),\n",
       " ('ル', 1775),\n",
       " ('レ', 1776),\n",
       " ('ロ', 1777),\n",
       " ('ワ', 1778),\n",
       " ('ン', 1779),\n",
       " ('・', 1780),\n",
       " ('ー', 1781),\n",
       " ('一', 1782),\n",
       " ('三', 1783),\n",
       " ('上', 1784),\n",
       " ('下', 1785),\n",
       " ('不', 1786),\n",
       " ('世', 1787),\n",
       " ('中', 1788),\n",
       " ('主', 1789),\n",
       " ('久', 1790),\n",
       " ('之', 1791),\n",
       " ('也', 1792),\n",
       " ('事', 1793),\n",
       " ('二', 1794),\n",
       " ('五', 1795),\n",
       " ('井', 1796),\n",
       " ('京', 1797),\n",
       " ('人', 1798),\n",
       " ('亻', 1799),\n",
       " ('仁', 1800),\n",
       " ('介', 1801),\n",
       " ('代', 1802),\n",
       " ('仮', 1803),\n",
       " ('伊', 1804),\n",
       " ('会', 1805),\n",
       " ('佐', 1806),\n",
       " ('侍', 1807),\n",
       " ('保', 1808),\n",
       " ('信', 1809),\n",
       " ('健', 1810),\n",
       " ('元', 1811),\n",
       " ('光', 1812),\n",
       " ('八', 1813),\n",
       " ('公', 1814),\n",
       " ('内', 1815),\n",
       " ('出', 1816),\n",
       " ('分', 1817),\n",
       " ('前', 1818),\n",
       " ('劉', 1819),\n",
       " ('力', 1820),\n",
       " ('加', 1821),\n",
       " ('勝', 1822),\n",
       " ('北', 1823),\n",
       " ('区', 1824),\n",
       " ('十', 1825),\n",
       " ('千', 1826),\n",
       " ('南', 1827),\n",
       " ('博', 1828),\n",
       " ('原', 1829),\n",
       " ('口', 1830),\n",
       " ('古', 1831),\n",
       " ('史', 1832),\n",
       " ('司', 1833),\n",
       " ('合', 1834),\n",
       " ('吉', 1835),\n",
       " ('同', 1836),\n",
       " ('名', 1837),\n",
       " ('和', 1838),\n",
       " ('囗', 1839),\n",
       " ('四', 1840),\n",
       " ('国', 1841),\n",
       " ('國', 1842),\n",
       " ('土', 1843),\n",
       " ('地', 1844),\n",
       " ('坂', 1845),\n",
       " ('城', 1846),\n",
       " ('堂', 1847),\n",
       " ('場', 1848),\n",
       " ('士', 1849),\n",
       " ('夏', 1850),\n",
       " ('外', 1851),\n",
       " ('大', 1852),\n",
       " ('天', 1853),\n",
       " ('太', 1854),\n",
       " ('夫', 1855),\n",
       " ('奈', 1856),\n",
       " ('女', 1857),\n",
       " ('子', 1858),\n",
       " ('学', 1859),\n",
       " ('宀', 1860),\n",
       " ('宇', 1861),\n",
       " ('安', 1862),\n",
       " ('宗', 1863),\n",
       " ('定', 1864),\n",
       " ('宣', 1865),\n",
       " ('宮', 1866),\n",
       " ('家', 1867),\n",
       " ('宿', 1868),\n",
       " ('寺', 1869),\n",
       " ('將', 1870),\n",
       " ('小', 1871),\n",
       " ('尚', 1872),\n",
       " ('山', 1873),\n",
       " ('岡', 1874),\n",
       " ('島', 1875),\n",
       " ('崎', 1876),\n",
       " ('川', 1877),\n",
       " ('州', 1878),\n",
       " ('巿', 1879),\n",
       " ('帝', 1880),\n",
       " ('平', 1881),\n",
       " ('年', 1882),\n",
       " ('幸', 1883),\n",
       " ('广', 1884),\n",
       " ('弘', 1885),\n",
       " ('張', 1886),\n",
       " ('彳', 1887),\n",
       " ('後', 1888),\n",
       " ('御', 1889),\n",
       " ('德', 1890),\n",
       " ('心', 1891),\n",
       " ('忄', 1892),\n",
       " ('志', 1893),\n",
       " ('忠', 1894),\n",
       " ('愛', 1895),\n",
       " ('成', 1896),\n",
       " ('我', 1897),\n",
       " ('戦', 1898),\n",
       " ('戸', 1899),\n",
       " ('手', 1900),\n",
       " ('扌', 1901),\n",
       " ('政', 1902),\n",
       " ('文', 1903),\n",
       " ('新', 1904),\n",
       " ('方', 1905),\n",
       " ('日', 1906),\n",
       " ('明', 1907),\n",
       " ('星', 1908),\n",
       " ('春', 1909),\n",
       " ('昭', 1910),\n",
       " ('智', 1911),\n",
       " ('曲', 1912),\n",
       " ('書', 1913),\n",
       " ('月', 1914),\n",
       " ('有', 1915),\n",
       " ('朝', 1916),\n",
       " ('木', 1917),\n",
       " ('本', 1918),\n",
       " ('李', 1919),\n",
       " ('村', 1920),\n",
       " ('東', 1921),\n",
       " ('松', 1922),\n",
       " ('林', 1923),\n",
       " ('森', 1924),\n",
       " ('楊', 1925),\n",
       " ('樹', 1926),\n",
       " ('橋', 1927),\n",
       " ('歌', 1928),\n",
       " ('止', 1929),\n",
       " ('正', 1930),\n",
       " ('武', 1931),\n",
       " ('比', 1932),\n",
       " ('氏', 1933),\n",
       " ('民', 1934),\n",
       " ('水', 1935),\n",
       " ('氵', 1936),\n",
       " ('氷', 1937),\n",
       " ('永', 1938),\n",
       " ('江', 1939),\n",
       " ('沢', 1940),\n",
       " ('河', 1941),\n",
       " ('治', 1942),\n",
       " ('法', 1943),\n",
       " ('海', 1944),\n",
       " ('清', 1945),\n",
       " ('漢', 1946),\n",
       " ('瀬', 1947),\n",
       " ('火', 1948),\n",
       " ('版', 1949),\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ss_vocab[900:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "656"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"সম্পাদক : ইমদাদুল হক মিলন, নির্বাহী সম্পাদক : মোস্তফা কামাল, ইস্ট ওয়েস্ট মিডিয়া গ্রুপ লিমিটেডের পক্ষে ময়নাল হোসেন চৌধুরী কর্তৃক প্রধান কার্যালয় : প্লট-৩৭১/এ, ব্লক-ডি, বসুন্ধরা, বারিধারা থেকে প্রকাশিত এবং প্লট-সি/৫২, ব্লক-কে, বসুন্ধরা, খিলক্ষেত, বাড্ডা, ঢাকা-১২২৯ ও সুপ্রভাত মিডিয়া লিমিটেড ৪ সিডিএ বাণিজ্যিক এলাকা, মোমিন রোড, চট্টগ্রাম-৪০০০ থেকে মুদ্রিত। পিএবিএক্স : ০৯৬১২১২০০০০, ৮৪৩২৩৭২-৭৫, বার্তা বিভাগ ফ্যাক্স : ৮৪৩২৩৬৮-৬৯, বিজ্ঞাপন ফোন : ৮৪৩২০৪৮, বিজ্ঞাপন ফ্যাক্স : ৮৪৩২০৪৭, সার্কুলেশন : ৮৪৩২৩৭৬। E-mail : info@kalerkantho.com\n",
    "মুম্বাই ইন্ডিয়ান্স আইপিএল ইতিহাসের সবচেয়ে মজবুত এবং জনপ্রিয় দলগুলির একটি। মুম্বাই ইন্ডিয়ান্সের দল মোট তিনবার আইপিএলের খেতাব...\"\"\"\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "656\n",
      "('সম্পাদক : ইমদাদুল হক মিলন, নির্বাহী সম্পাদক : মোস্তফা কামাল, ইস্ট ওয়েস্ট '\n",
      " 'মিডিয়া গ্রুপ লিমিটেডের পক্ষে ময়নাল হোসেন চৌধুরী কর্তৃক প্রধান কার্যালয় : '\n",
      " 'প্লট-৩৭১/এ, ব্লক-ডি, বসুন্ধরা, বারিধারা থেকে প্রকাশিত এবং প্লট-সি/৫২, '\n",
      " 'ব্লক-কে, বসুন্ধরা, খিলক্ষেত, বাড্ডা, ঢাকা-১২২৯ ও সুপ্রভাত মিডিয়া লিমিটেড ৪ '\n",
      " 'সিডিএ বাণিজ্যিক এলাকা, মোমিন রোড, চট্টগ্রাম-৪০০০ থেকে মুদ্রিত। পিএবিএক্স : '\n",
      " '০৯৬১২১২০০০০, ৮৪৩২৩৭২-৭৫, বার্তা বিভাগ ফ্যাক্স : ৮৪৩২৩৬৮-৬৯, বিজ্ঞাপন ফোন : '\n",
      " '৮৪৩২০৪৮, বিজ্ঞাপন ফ্যাক্স : ৮৪৩২০৪৭, সার্কুলেশন : ৮৪৩২৩৭৬। E-mail : '\n",
      " 'info@kalerkantho.com মুম্বাই ইন্ডিয়ান্স আইপিএল ইতিহাসের সবচেয়ে মজবুত এবং '\n",
      " 'জনপ্রিয় দলগুলির একটি। মুম্বাই ইন্ডিয়ান্সের দল মোট তিনবার আইপিএলের খেতাব...')\n"
     ]
    }
   ],
   "source": [
    "n_text1 = tokenizer.backend_tokenizer.normalizer.normalize_str(text)\n",
    "print(len(n_text1))\n",
    "pprint(n_text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == n_text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'সম্পাদক',\n",
       " ':',\n",
       " 'ইম',\n",
       " '##দাদুল',\n",
       " 'হক',\n",
       " 'মিলন',\n",
       " ',',\n",
       " 'নির্বাহী',\n",
       " 'সম্পাদক',\n",
       " ':',\n",
       " 'মোস্তফা',\n",
       " 'কামাল',\n",
       " ',',\n",
       " 'ইস্ট',\n",
       " '[UNK]',\n",
       " '[UNK]',\n",
       " 'গ্রুপ',\n",
       " 'লিমিটেডের',\n",
       " 'পক্ষে',\n",
       " '[UNK]',\n",
       " 'হোসেন',\n",
       " 'চৌধুরী',\n",
       " 'কর্তৃক',\n",
       " 'প্রধান',\n",
       " '[UNK]',\n",
       " ':',\n",
       " 'প্লট',\n",
       " '-',\n",
       " '৩৭',\n",
       " '##১',\n",
       " '/',\n",
       " 'এ',\n",
       " ',',\n",
       " 'ব্লক',\n",
       " '-',\n",
       " 'ডি',\n",
       " ',',\n",
       " 'বসুন্ধরা',\n",
       " ',',\n",
       " 'বারি',\n",
       " '##ধারা',\n",
       " 'থেকে',\n",
       " 'প্রকাশিত',\n",
       " 'এবং',\n",
       " 'প্লট',\n",
       " '-',\n",
       " 'সি',\n",
       " '/',\n",
       " '৫২',\n",
       " ',',\n",
       " 'ব্লক',\n",
       " '-',\n",
       " 'কে',\n",
       " ',',\n",
       " 'বসুন্ধরা',\n",
       " ',',\n",
       " 'খিল',\n",
       " '##ক্ষেত',\n",
       " ',',\n",
       " 'বা',\n",
       " '##ড্ডা',\n",
       " ',',\n",
       " 'ঢাকা',\n",
       " '-',\n",
       " '১২',\n",
       " '##২৯',\n",
       " 'ও',\n",
       " 'সুপ্র',\n",
       " '##ভাত',\n",
       " '[UNK]',\n",
       " 'লিমিটেড',\n",
       " '৪',\n",
       " 'সিডি',\n",
       " '##এ',\n",
       " 'বাণিজ্যিক',\n",
       " 'এলাকা',\n",
       " ',',\n",
       " 'মোমিন',\n",
       " 'রোড',\n",
       " ',',\n",
       " 'চট্টগ্রাম',\n",
       " '-',\n",
       " '৪০০',\n",
       " '##০',\n",
       " 'থেকে',\n",
       " 'মুদ্রিত',\n",
       " '।',\n",
       " 'পি',\n",
       " '##এব',\n",
       " '##ি',\n",
       " '##এক্স',\n",
       " ':',\n",
       " '০৯',\n",
       " '##৬',\n",
       " '##১২',\n",
       " '##১২',\n",
       " '##০০০০',\n",
       " ',',\n",
       " '৮৪',\n",
       " '##৩',\n",
       " '##২৩',\n",
       " '##৭',\n",
       " '##২',\n",
       " '-',\n",
       " '৭৫',\n",
       " ',',\n",
       " 'বার্তা',\n",
       " 'বিভাগ',\n",
       " 'ফ্যাক',\n",
       " '##্স',\n",
       " ':',\n",
       " '৮৪',\n",
       " '##৩',\n",
       " '##২৩',\n",
       " '##৬',\n",
       " '##৮',\n",
       " '-',\n",
       " '৬৯',\n",
       " ',',\n",
       " 'বিজ্ঞাপন',\n",
       " 'ফোন',\n",
       " ':',\n",
       " '৮৪',\n",
       " '##৩',\n",
       " '##২০',\n",
       " '##৪',\n",
       " '##৮',\n",
       " ',',\n",
       " 'বিজ্ঞাপন',\n",
       " 'ফ্যাক',\n",
       " '##্স',\n",
       " ':',\n",
       " '৮৪',\n",
       " '##৩',\n",
       " '##২০',\n",
       " '##৪',\n",
       " '##৭',\n",
       " ',',\n",
       " 'সার্ক',\n",
       " '##ুলেশন',\n",
       " ':',\n",
       " '৮৪',\n",
       " '##৩',\n",
       " '##২৩',\n",
       " '##৭৬',\n",
       " '।',\n",
       " 'E',\n",
       " '-',\n",
       " 'ma',\n",
       " '##il',\n",
       " ':',\n",
       " 'info',\n",
       " '@',\n",
       " 'ka',\n",
       " '##le',\n",
       " '##r',\n",
       " '##ka',\n",
       " '##nt',\n",
       " '##ho',\n",
       " '.',\n",
       " 'com',\n",
       " 'মুম্বাই',\n",
       " '[UNK]',\n",
       " 'আইপিএল',\n",
       " 'ইতিহাসের',\n",
       " '[UNK]',\n",
       " 'মজবুত',\n",
       " 'এবং',\n",
       " '[UNK]',\n",
       " 'দল',\n",
       " '##গুলির',\n",
       " 'একটি',\n",
       " '।',\n",
       " 'মুম্বাই',\n",
       " '[UNK]',\n",
       " 'দল',\n",
       " 'মোট',\n",
       " 'তিনবার',\n",
       " 'আইপিএলের',\n",
       " 'খেতাব',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode_plus(text=text).tokens() # lots of [unk] token from csenlp/banglaber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "609\n",
      "('সমপাদক : ইমদাদল হক মিলন, নিরবাহী সমপাদক : মোসতফা কামাল, ইসট ওযেসট মিডিযা '\n",
      " 'গরপ লিমিটেডের পকষে মযনাল হোসেন চৌধরী করতক পরধান কারযালয : পলট-৩৭১/এ, '\n",
      " 'বলক-ডি, বসনধরা, বারিধারা থেকে পরকাশিত এবং পলট-সি/৫২, বলক-কে, বসনধরা, '\n",
      " 'খিলকষেত, বাডডা, ঢাকা-১২২৯ ও সপরভাত মিডিযা লিমিটেড ৪ সিডিএ বাণিজযিক এলাকা, '\n",
      " 'মোমিন রোড, চটটগরাম-৪০০০ থেকে মদরিত। পিএবিএকস : ০৯৬১২১২০০০০, ৮৪৩২৩৭২-৭৫, '\n",
      " 'বারতা বিভাগ ফযাকস : ৮৪৩২৩৬৮-৬৯, বিজঞাপন ফোন : ৮৪৩২০৪৮, বিজঞাপন ফযাকস : '\n",
      " '৮৪৩২০৪৭, সারকলেশন : ৮৪৩২৩৭৬। e-mail : info@kalerkantho.com মমবাই ইনডিযানস '\n",
      " 'আইপিএল ইতিহাসের সবচেযে মজবত এবং জনপরিয দলগলির একটি। মমবাই ইনডিযানসের দল মোট '\n",
      " 'তিনবার আইপিএলের খেতাব...')\n"
     ]
    }
   ],
   "source": [
    "n_text2 = ss_tokenizer.backend_tokenizer.normalizer.normalize_str(text)\n",
    "print(len(n_text2))\n",
    "pprint(n_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'সম',\n",
       " '##পাদক',\n",
       " ':',\n",
       " 'ইমদাদ',\n",
       " '##ল',\n",
       " 'হক',\n",
       " 'মিলন',\n",
       " ',',\n",
       " 'নিরব',\n",
       " '##াহ',\n",
       " '##ী',\n",
       " 'সম',\n",
       " '##পাদক',\n",
       " ':',\n",
       " 'মে',\n",
       " '##াস',\n",
       " '##ত',\n",
       " '##ফা',\n",
       " 'কামাল',\n",
       " ',',\n",
       " 'ইস',\n",
       " '##ট',\n",
       " 'ও',\n",
       " '##যে',\n",
       " '##সট',\n",
       " 'মিডি',\n",
       " '##যা',\n",
       " 'গর',\n",
       " '##প',\n",
       " 'লিমিটেডের',\n",
       " 'পক',\n",
       " '##ষে',\n",
       " 'ম',\n",
       " '##যন',\n",
       " '##াল',\n",
       " 'হে',\n",
       " '##াসে',\n",
       " '##ন',\n",
       " '[UNK]',\n",
       " 'করত',\n",
       " '##ক',\n",
       " 'পর',\n",
       " '##ধান',\n",
       " 'কার',\n",
       " '##যা',\n",
       " '##ল',\n",
       " '##য',\n",
       " ':',\n",
       " 'পল',\n",
       " '##ট',\n",
       " '-',\n",
       " '[UNK]',\n",
       " '/',\n",
       " 'এ',\n",
       " ',',\n",
       " 'বলক',\n",
       " '-',\n",
       " 'ডি',\n",
       " ',',\n",
       " 'বসন',\n",
       " '##ধরা',\n",
       " ',',\n",
       " 'বারিধারা',\n",
       " 'থেকে',\n",
       " 'পর',\n",
       " '##কাশিত',\n",
       " 'এবং',\n",
       " 'পল',\n",
       " '##ট',\n",
       " '-',\n",
       " 'সি',\n",
       " '/',\n",
       " '[UNK]',\n",
       " ',',\n",
       " 'বলক',\n",
       " '-',\n",
       " 'কে',\n",
       " ',',\n",
       " 'বসন',\n",
       " '##ধরা',\n",
       " ',',\n",
       " 'খিল',\n",
       " '##কষ',\n",
       " '##েত',\n",
       " ',',\n",
       " 'বা',\n",
       " '##ড',\n",
       " '##ডা',\n",
       " ',',\n",
       " 'ঢাকা',\n",
       " '-',\n",
       " '[UNK]',\n",
       " 'ও',\n",
       " 'সপ',\n",
       " '##র',\n",
       " '##ভাত',\n",
       " 'মিডি',\n",
       " '##যা',\n",
       " 'লিমিটেড',\n",
       " '৪',\n",
       " 'সিডিএ',\n",
       " 'বাণিজ',\n",
       " '##যি',\n",
       " '##ক',\n",
       " 'এলাকা',\n",
       " ',',\n",
       " 'মে',\n",
       " '##ামিন',\n",
       " 'রে',\n",
       " '##াড',\n",
       " ',',\n",
       " 'চট',\n",
       " '##ট',\n",
       " '##গরা',\n",
       " '##ম',\n",
       " '-',\n",
       " '[UNK]',\n",
       " 'থেকে',\n",
       " 'মদ',\n",
       " '##রি',\n",
       " '##ত',\n",
       " '।',\n",
       " 'পিএ',\n",
       " '##বি',\n",
       " '##এক',\n",
       " '##স',\n",
       " ':',\n",
       " '[UNK]',\n",
       " ',',\n",
       " '[UNK]',\n",
       " '-',\n",
       " '[UNK]',\n",
       " ',',\n",
       " 'বারতা',\n",
       " 'বিভাগ',\n",
       " 'ফ',\n",
       " '##যাক',\n",
       " '##স',\n",
       " ':',\n",
       " '[UNK]',\n",
       " '-',\n",
       " '[UNK]',\n",
       " ',',\n",
       " 'বিজ',\n",
       " '##ঞা',\n",
       " '##পন',\n",
       " 'ফে',\n",
       " '##ান',\n",
       " ':',\n",
       " '[UNK]',\n",
       " ',',\n",
       " 'বিজ',\n",
       " '##ঞা',\n",
       " '##পন',\n",
       " 'ফ',\n",
       " '##যাক',\n",
       " '##স',\n",
       " ':',\n",
       " '[UNK]',\n",
       " ',',\n",
       " 'সার',\n",
       " '##কলে',\n",
       " '##শন',\n",
       " ':',\n",
       " '[UNK]',\n",
       " '।',\n",
       " 'e',\n",
       " '-',\n",
       " '[UNK]',\n",
       " ':',\n",
       " '[UNK]',\n",
       " '@',\n",
       " '[UNK]',\n",
       " '.',\n",
       " '[UNK]',\n",
       " 'মম',\n",
       " '##বাই',\n",
       " 'ইনডি',\n",
       " '##যান',\n",
       " '##স',\n",
       " 'আইপিএল',\n",
       " 'ইতিহাসের',\n",
       " 'সবচে',\n",
       " '##যে',\n",
       " 'মজ',\n",
       " '##বত',\n",
       " 'এবং',\n",
       " 'জন',\n",
       " '##পরি',\n",
       " '##য',\n",
       " 'দল',\n",
       " '##গলি',\n",
       " '##র',\n",
       " 'একটি',\n",
       " '।',\n",
       " 'মম',\n",
       " '##বাই',\n",
       " 'ইনডি',\n",
       " '##যান',\n",
       " '##সের',\n",
       " 'দল',\n",
       " 'মে',\n",
       " '##াট',\n",
       " 'তিনবার',\n",
       " 'আইপিএলের',\n",
       " 'খেতাব',\n",
       " '.',\n",
       " '.',\n",
       " '.',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_tokenizer.encode_plus(text=text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: ঢ়ঃ\n",
      "Unicode Points: U+09A2 U+09BC U+0983\n",
      "UTF-8 Encoding: E0 A6 A2 E0 A6 BC E0 A6 83\n",
      "NFC Normalized: ঢ়ঃ\n",
      "Unicode Points NFC: U+09A2 U+09BC U+0983\n",
      "UTF-8 Encoding NFC: E0 A6 A2 E0 A6 BC E0 A6 83\n",
      "NFD Normalized: ঢ়ঃ\n",
      "Unicode Points NFD: U+09A2 U+09BC U+0983\n",
      "UTF-8 Encoding NFD: E0 A6 A2 E0 A6 BC E0 A6 83\n",
      "NFKC Normalized: ঢ়ঃ\n",
      "Unicode Points NFKC: U+09A2 U+09BC U+0983\n",
      "UTF-8 Encoding NFKC: E0 A6 A2 E0 A6 BC E0 A6 83\n",
      "NFKD Normalized: ঢ়ঃ\n",
      "Unicode Points NFKD: U+09A2 U+09BC U+0983\n",
      "UTF-8 Encoding NFKD: E0 A6 A2 E0 A6 BC E0 A6 83\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def print_unicode_points(text):\n",
    "    return ' '.join(f'U+{ord(c):04X}' for c in text)\n",
    "\n",
    "def print_utf8_encoding(text):\n",
    "    return ' '.join(f'{b:02X}' for b in text.encode('utf-8'))\n",
    "\n",
    "def print_normalized_forms(text):\n",
    "    nfc = unicodedata.normalize('NFC', text)\n",
    "    nfd = unicodedata.normalize('NFD', text)\n",
    "    nfkc = unicodedata.normalize('NFKC', text)\n",
    "    nfkd = unicodedata.normalize('NFKD', text)\n",
    "\n",
    "    print(\"Original Text:\", text)\n",
    "    print(\"Unicode Points:\", print_unicode_points(text))\n",
    "    print(\"UTF-8 Encoding:\", print_utf8_encoding(text))\n",
    "    \n",
    "    print(\"NFC Normalized:\", nfc)\n",
    "    print(\"Unicode Points NFC:\", print_unicode_points(nfc))\n",
    "    print(\"UTF-8 Encoding NFC:\", print_utf8_encoding(nfc))\n",
    "    \n",
    "    print(\"NFD Normalized:\", nfd)\n",
    "    print(\"Unicode Points NFD:\", print_unicode_points(nfd))\n",
    "    print(\"UTF-8 Encoding NFD:\", print_utf8_encoding(nfd))\n",
    "    \n",
    "    print(\"NFKC Normalized:\", nfkc)\n",
    "    print(\"Unicode Points NFKC:\", print_unicode_points(nfkc))\n",
    "    print(\"UTF-8 Encoding NFKC:\", print_utf8_encoding(nfkc))\n",
    "    \n",
    "    print(\"NFKD Normalized:\", nfkd)\n",
    "    print(\"Unicode Points NFKD:\", print_unicode_points(nfkd))\n",
    "    print(\"UTF-8 Encoding NFKD:\", print_utf8_encoding(nfkd))\n",
    "\n",
    "# Example usage\n",
    "input_text = \"ঢ়ঃ\"\n",
    "print_normalized_forms(input_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unicode code point of 'é': U+00E9\n",
      "UTF-8 encoding of 'é': b'\\xc3\\xa9'\n"
     ]
    }
   ],
   "source": [
    "char = 'é'\n",
    "\n",
    "# Get the Unicode code point\n",
    "code_point = ord(char)\n",
    "print(f\"Unicode code point of '{char}': U+{code_point:04X}\")\n",
    "\n",
    "# Get the UTF-8 encoding\n",
    "utf8_encoding = char.encode('utf-8')\n",
    "print(f\"UTF-8 encoding of '{char}': {utf8_encoding}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PreTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('সম্পাদক', (0, 7)),\n",
       " (':', (8, 9)),\n",
       " ('ইমদাদুল', (10, 17)),\n",
       " ('হক', (18, 20)),\n",
       " ('মিলন', (21, 25)),\n",
       " (',', (25, 26)),\n",
       " ('নির্বাহী', (27, 35)),\n",
       " ('সম্পাদক', (36, 43)),\n",
       " (':', (44, 45)),\n",
       " ('মোস্তফা', (46, 53)),\n",
       " ('কামাল', (54, 59)),\n",
       " (',', (59, 60)),\n",
       " ('ইস্ট', (61, 65)),\n",
       " ('ওয়েস্ট', (66, 72)),\n",
       " ('মিডিয়া', (73, 79)),\n",
       " ('গ্রুপ', (80, 85)),\n",
       " ('লিমিটেডের', (86, 95)),\n",
       " ('পক্ষে', (96, 101)),\n",
       " ('ময়নাল', (102, 107)),\n",
       " ('হোসেন', (108, 113)),\n",
       " ('চৌধুরী', (114, 120)),\n",
       " ('কর্তৃক', (121, 127)),\n",
       " ('প্রধান', (128, 134)),\n",
       " ('কার্যালয়', (135, 143)),\n",
       " (':', (144, 145)),\n",
       " ('প্লট', (146, 150)),\n",
       " ('-', (150, 151)),\n",
       " ('৩৭১', (151, 154)),\n",
       " ('/', (154, 155)),\n",
       " ('এ', (155, 156)),\n",
       " (',', (156, 157)),\n",
       " ('ব্লক', (158, 162)),\n",
       " ('-', (162, 163)),\n",
       " ('ডি', (163, 165)),\n",
       " (',', (165, 166)),\n",
       " ('বসুন্ধরা', (167, 175)),\n",
       " (',', (175, 176)),\n",
       " ('বারিধারা', (177, 185)),\n",
       " ('থেকে', (186, 190)),\n",
       " ('প্রকাশিত', (191, 199)),\n",
       " ('এবং', (200, 203)),\n",
       " ('প্লট', (204, 208)),\n",
       " ('-', (208, 209)),\n",
       " ('সি', (209, 211)),\n",
       " ('/', (211, 212)),\n",
       " ('৫২', (212, 214)),\n",
       " (',', (214, 215)),\n",
       " ('ব্লক', (216, 220)),\n",
       " ('-', (220, 221)),\n",
       " ('কে', (221, 223)),\n",
       " (',', (223, 224)),\n",
       " ('বসুন্ধরা', (225, 233)),\n",
       " (',', (233, 234)),\n",
       " ('খিলক্ষেত', (235, 243)),\n",
       " (',', (243, 244)),\n",
       " ('বাড্ডা', (245, 251)),\n",
       " (',', (251, 252)),\n",
       " ('ঢাকা', (253, 257)),\n",
       " ('-', (257, 258)),\n",
       " ('১২২৯', (258, 262)),\n",
       " ('ও', (263, 264)),\n",
       " ('সুপ্রভাত', (265, 273)),\n",
       " ('মিডিয়া', (274, 280)),\n",
       " ('লিমিটেড', (281, 288)),\n",
       " ('৪', (289, 290)),\n",
       " ('সিডিএ', (291, 296)),\n",
       " ('বাণিজ্যিক', (297, 306)),\n",
       " ('এলাকা', (307, 312)),\n",
       " (',', (312, 313)),\n",
       " ('মোমিন', (314, 319)),\n",
       " ('রোড', (320, 323)),\n",
       " (',', (323, 324)),\n",
       " ('চট্টগ্রাম', (325, 334)),\n",
       " ('-', (334, 335)),\n",
       " ('৪০০০', (335, 339)),\n",
       " ('থেকে', (340, 344)),\n",
       " ('মুদ্রিত', (345, 352)),\n",
       " ('।', (352, 353)),\n",
       " ('পিএবিএক্স', (354, 363)),\n",
       " (':', (364, 365)),\n",
       " ('০৯৬১২১২০০০০', (366, 377)),\n",
       " (',', (377, 378)),\n",
       " ('৮৪৩২৩৭২', (379, 386)),\n",
       " ('-', (386, 387)),\n",
       " ('৭৫', (387, 389)),\n",
       " (',', (389, 390)),\n",
       " ('বার্তা', (391, 397)),\n",
       " ('বিভাগ', (398, 403)),\n",
       " ('ফ্যাক্স', (404, 411)),\n",
       " (':', (412, 413)),\n",
       " ('৮৪৩২৩৬৮', (414, 421)),\n",
       " ('-', (421, 422)),\n",
       " ('৬৯', (422, 424)),\n",
       " (',', (424, 425)),\n",
       " ('বিজ্ঞাপন', (426, 434)),\n",
       " ('ফোন', (435, 438)),\n",
       " (':', (439, 440)),\n",
       " ('৮৪৩২০৪৮', (441, 448)),\n",
       " (',', (448, 449)),\n",
       " ('বিজ্ঞাপন', (450, 458)),\n",
       " ('ফ্যাক্স', (459, 466)),\n",
       " (':', (467, 468)),\n",
       " ('৮৪৩২০৪৭', (469, 476)),\n",
       " (',', (476, 477)),\n",
       " ('সার্কুলেশন', (478, 488)),\n",
       " (':', (489, 490)),\n",
       " ('৮৪৩২৩৭৬', (491, 498)),\n",
       " ('।', (498, 499)),\n",
       " ('E', (500, 501)),\n",
       " ('-', (501, 502)),\n",
       " ('mail', (502, 506)),\n",
       " (':', (507, 508)),\n",
       " ('info', (509, 513)),\n",
       " ('@', (513, 514)),\n",
       " ('kalerkantho', (514, 525)),\n",
       " ('.', (525, 526)),\n",
       " ('com', (526, 529)),\n",
       " ('মুম্বাই', (530, 537)),\n",
       " ('ইন্ডিয়ান্স', (538, 548)),\n",
       " ('আইপিএল', (549, 555)),\n",
       " ('ইতিহাসের', (556, 564)),\n",
       " ('সবচেয়ে', (565, 571)),\n",
       " ('মজবুত', (572, 577)),\n",
       " ('এবং', (578, 581)),\n",
       " ('জনপ্রিয়', (582, 589)),\n",
       " ('দলগুলির', (590, 597)),\n",
       " ('একটি', (598, 602)),\n",
       " ('।', (602, 603)),\n",
       " ('মুম্বাই', (604, 611)),\n",
       " ('ইন্ডিয়ান্সের', (612, 624)),\n",
       " ('দল', (625, 627)),\n",
       " ('মোট', (628, 631)),\n",
       " ('তিনবার', (632, 638)),\n",
       " ('আইপিএলের', (639, 647)),\n",
       " ('খেতাব', (648, 653)),\n",
       " ('.', (653, 654)),\n",
       " ('.', (654, 655)),\n",
       " ('.', (655, 656))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('সম্পাদক', (0, 7)),\n",
       " (':', (8, 9)),\n",
       " ('ইমদাদুল', (10, 17)),\n",
       " ('হক', (18, 20)),\n",
       " ('মিলন', (21, 25)),\n",
       " (',', (25, 26)),\n",
       " ('নির্বাহী', (27, 35)),\n",
       " ('সম্পাদক', (36, 43)),\n",
       " (':', (44, 45)),\n",
       " ('মোস্তফা', (46, 53)),\n",
       " ('কামাল', (54, 59)),\n",
       " (',', (59, 60)),\n",
       " ('ইস্ট', (61, 65)),\n",
       " ('ওয়েস্ট', (66, 72)),\n",
       " ('মিডিয়া', (73, 79)),\n",
       " ('গ্রুপ', (80, 85)),\n",
       " ('লিমিটেডের', (86, 95)),\n",
       " ('পক্ষে', (96, 101)),\n",
       " ('ময়নাল', (102, 107)),\n",
       " ('হোসেন', (108, 113)),\n",
       " ('চৌধুরী', (114, 120)),\n",
       " ('কর্তৃক', (121, 127)),\n",
       " ('প্রধান', (128, 134)),\n",
       " ('কার্যালয়', (135, 143)),\n",
       " (':', (144, 145)),\n",
       " ('প্লট', (146, 150)),\n",
       " ('-', (150, 151)),\n",
       " ('৩৭১', (151, 154)),\n",
       " ('/', (154, 155)),\n",
       " ('এ', (155, 156)),\n",
       " (',', (156, 157)),\n",
       " ('ব্লক', (158, 162)),\n",
       " ('-', (162, 163)),\n",
       " ('ডি', (163, 165)),\n",
       " (',', (165, 166)),\n",
       " ('বসুন্ধরা', (167, 175)),\n",
       " (',', (175, 176)),\n",
       " ('বারিধারা', (177, 185)),\n",
       " ('থেকে', (186, 190)),\n",
       " ('প্রকাশিত', (191, 199)),\n",
       " ('এবং', (200, 203)),\n",
       " ('প্লট', (204, 208)),\n",
       " ('-', (208, 209)),\n",
       " ('সি', (209, 211)),\n",
       " ('/', (211, 212)),\n",
       " ('৫২', (212, 214)),\n",
       " (',', (214, 215)),\n",
       " ('ব্লক', (216, 220)),\n",
       " ('-', (220, 221)),\n",
       " ('কে', (221, 223)),\n",
       " (',', (223, 224)),\n",
       " ('বসুন্ধরা', (225, 233)),\n",
       " (',', (233, 234)),\n",
       " ('খিলক্ষেত', (235, 243)),\n",
       " (',', (243, 244)),\n",
       " ('বাড্ডা', (245, 251)),\n",
       " (',', (251, 252)),\n",
       " ('ঢাকা', (253, 257)),\n",
       " ('-', (257, 258)),\n",
       " ('১২২৯', (258, 262)),\n",
       " ('ও', (263, 264)),\n",
       " ('সুপ্রভাত', (265, 273)),\n",
       " ('মিডিয়া', (274, 280)),\n",
       " ('লিমিটেড', (281, 288)),\n",
       " ('৪', (289, 290)),\n",
       " ('সিডিএ', (291, 296)),\n",
       " ('বাণিজ্যিক', (297, 306)),\n",
       " ('এলাকা', (307, 312)),\n",
       " (',', (312, 313)),\n",
       " ('মোমিন', (314, 319)),\n",
       " ('রোড', (320, 323)),\n",
       " (',', (323, 324)),\n",
       " ('চট্টগ্রাম', (325, 334)),\n",
       " ('-', (334, 335)),\n",
       " ('৪০০০', (335, 339)),\n",
       " ('থেকে', (340, 344)),\n",
       " ('মুদ্রিত', (345, 352)),\n",
       " ('।', (352, 353)),\n",
       " ('পিএবিএক্স', (354, 363)),\n",
       " (':', (364, 365)),\n",
       " ('০৯৬১২১২০০০০', (366, 377)),\n",
       " (',', (377, 378)),\n",
       " ('৮৪৩২৩৭২', (379, 386)),\n",
       " ('-', (386, 387)),\n",
       " ('৭৫', (387, 389)),\n",
       " (',', (389, 390)),\n",
       " ('বার্তা', (391, 397)),\n",
       " ('বিভাগ', (398, 403)),\n",
       " ('ফ্যাক্স', (404, 411)),\n",
       " (':', (412, 413)),\n",
       " ('৮৪৩২৩৬৮', (414, 421)),\n",
       " ('-', (421, 422)),\n",
       " ('৬৯', (422, 424)),\n",
       " (',', (424, 425)),\n",
       " ('বিজ্ঞাপন', (426, 434)),\n",
       " ('ফোন', (435, 438)),\n",
       " (':', (439, 440)),\n",
       " ('৮৪৩২০৪৮', (441, 448)),\n",
       " (',', (448, 449)),\n",
       " ('বিজ্ঞাপন', (450, 458)),\n",
       " ('ফ্যাক্স', (459, 466)),\n",
       " (':', (467, 468)),\n",
       " ('৮৪৩২০৪৭', (469, 476)),\n",
       " (',', (476, 477)),\n",
       " ('সার্কুলেশন', (478, 488)),\n",
       " (':', (489, 490)),\n",
       " ('৮৪৩২৩৭৬', (491, 498)),\n",
       " ('।', (498, 499)),\n",
       " ('E', (500, 501)),\n",
       " ('-', (501, 502)),\n",
       " ('mail', (502, 506)),\n",
       " (':', (507, 508)),\n",
       " ('info', (509, 513)),\n",
       " ('@', (513, 514)),\n",
       " ('kalerkantho', (514, 525)),\n",
       " ('.', (525, 526)),\n",
       " ('com', (526, 529)),\n",
       " ('মুম্বাই', (530, 537)),\n",
       " ('ইন্ডিয়ান্স', (538, 548)),\n",
       " ('আইপিএল', (549, 555)),\n",
       " ('ইতিহাসের', (556, 564)),\n",
       " ('সবচেয়ে', (565, 571)),\n",
       " ('মজবুত', (572, 577)),\n",
       " ('এবং', (578, 581)),\n",
       " ('জনপ্রিয়', (582, 589)),\n",
       " ('দলগুলির', (590, 597)),\n",
       " ('একটি', (598, 602)),\n",
       " ('।', (602, 603)),\n",
       " ('মুম্বাই', (604, 611)),\n",
       " ('ইন্ডিয়ান্সের', (612, 624)),\n",
       " ('দল', (625, 627)),\n",
       " ('মোট', (628, 631)),\n",
       " ('তিনবার', (632, 638)),\n",
       " ('আইপিএলের', (639, 647)),\n",
       " ('খেতাব', (648, 653)),\n",
       " ('.', (653, 654)),\n",
       " ('.', (654, 655)),\n",
       " ('.', (655, 656))]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_tokenizer.backend_tokenizer.pre_tokenizer.pre_tokenize_str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BertPreTokenizer',\n",
       " 'ByteLevel',\n",
       " 'CharDelimiterSplit',\n",
       " 'Digits',\n",
       " 'Metaspace',\n",
       " 'PreTokenizer',\n",
       " 'Punctuation',\n",
       " 'Sequence',\n",
       " 'Split',\n",
       " 'UnicodeScripts',\n",
       " 'Whitespace',\n",
       " 'WhitespaceSplit',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'pre_tokenizers']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir(tokenizers.pre_tokenizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import Tokenizer, normalizers, pre_tokenizers, processors, trainers, models\n",
    "from tokenizers.normalizers import Lowercase, NFC\n",
    "from tokenizers.pre_tokenizers import Whitespace, Metaspace\n",
    "from tokenizers.processors import TemplateProcessing\n",
    "from tokenizers.implementations import SentencePieceBPETokenizer\n",
    "\n",
    "class CustomTokenizer:\n",
    "    def __init__(self, predefined_words=None):\n",
    "        self.predefined_words = predefined_words if predefined_words else []\n",
    "        self.tokenizer = SentencePieceBPETokenizer(\n",
    "            # vocab=\"/home/virus_proton/Projects/P_Projects/LLM_Mastery/Tokenizer_train/Trails/tokenizer_jul_13/test_vocab.json\",\n",
    "            add_prefix_space=True,\n",
    "            unk_token='<unk>',\n",
    "            replacement='_'\n",
    "        )\n",
    "\n",
    "        # Set custom normalization (lowercase)\n",
    "        self.tokenizer.normalizer = normalizers.Sequence([NFC()])\n",
    "\n",
    "        # Set custom pre-tokenizer (whitespace)\n",
    "        self.tokenizer.pre_tokenizer = pre_tokenizers.Sequence([Metaspace()])\n",
    "\n",
    "    def train(self, files):\n",
    "        # Train the tokenizer on the provided files\n",
    "        self.tokenizer.train(\n",
    "            files=files,\n",
    "            vocab_size=30522,\n",
    "            min_frequency=2,\n",
    "            special_tokens=[\"<pad>\", \"<s>\", \"</s>\", \"<mask>\"]\n",
    "        )\n",
    "        \n",
    "        # Add predefined words to the tokenizer vocabulary\n",
    "        self.tokenizer.add_tokens(self.predefined_words)\n",
    "\n",
    "        # Define post-processing\n",
    "        self.tokenizer.post_processor = TemplateProcessing(\n",
    "            single=\"<s> $A </s>\",\n",
    "            # pair=\"<s> $A [SEP] $B:1 [SEP]:1\",\n",
    "            special_tokens=[\n",
    "                (\"<s>\", self.tokenizer.token_to_id(\"<s>\")),\n",
    "                (\"</s>\", self.tokenizer.token_to_id(\"</s>\")),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def save(self, path):\n",
    "        self.tokenizer.save_model(path)\n",
    "\n",
    "    def encode(self, text):\n",
    "        return self.tokenizer.encode(text)\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.tokenizer.decode(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_tokenizer = CustomTokenizer(predefined_words=[\"custom\", \"token\", \"words\"])\n",
    "custom_tokenizer.tokenizer.get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Encoded: ['<s>', '▁This', '▁is', '▁a', '▁sample', '▁tex', 't', '.', '</s>']\n",
      "Decoded: ▁This▁is▁a▁sample▁text.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage:\n",
    "# Initialize with predefined words\n",
    "custom_tokenizer = CustomTokenizer(predefined_words=[\"custom\", \"token\", \"words\"])\n",
    "\n",
    "# Train on a corpus\n",
    "corpus_files = [\"/home/virus_proton/Projects/P_Projects/LLM_Mastery/Tokenizer_train/demo.txt\"]\n",
    "custom_tokenizer.train(corpus_files)\n",
    "\n",
    "# Save the tokenizer to a file\n",
    "custom_tokenizer.save(\"./Trails/tokenizer_jul_13\")\n",
    "\n",
    "# Encode a sample text\n",
    "encoded = custom_tokenizer.encode(\"This is a sample text.\")\n",
    "print(\"Encoded:\", encoded.tokens)\n",
    "\n",
    "# Decode the tokens back to text\n",
    "decoded = custom_tokenizer.decode(encoded.ids)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<pad>', 0),\n",
       " ('<s>', 1),\n",
       " ('</s>', 2),\n",
       " ('<mask>', 3),\n",
       " ('\\n', 4),\n",
       " ('!', 5),\n",
       " ('\"', 6),\n",
       " ('#', 7),\n",
       " (\"'\", 8),\n",
       " ('(', 9),\n",
       " (')', 10),\n",
       " ('+', 11),\n",
       " (',', 12),\n",
       " ('-', 13),\n",
       " ('.', 14),\n",
       " ('/', 15),\n",
       " ('0', 16),\n",
       " ('1', 17),\n",
       " ('2', 18),\n",
       " ('3', 19),\n",
       " ('4', 20),\n",
       " ('5', 21),\n",
       " ('6', 22),\n",
       " ('7', 23),\n",
       " ('8', 24),\n",
       " ('9', 25),\n",
       " (':', 26),\n",
       " (';', 27),\n",
       " ('=', 28),\n",
       " ('?', 29),\n",
       " ('@', 30),\n",
       " ('[', 31),\n",
       " (']', 32),\n",
       " ('_', 33),\n",
       " ('`', 34),\n",
       " ('a', 35),\n",
       " ('b', 36),\n",
       " ('c', 37),\n",
       " ('d', 38),\n",
       " ('e', 39),\n",
       " ('f', 40),\n",
       " ('g', 41),\n",
       " ('h', 42),\n",
       " ('i', 43),\n",
       " ('j', 44),\n",
       " ('k', 45),\n",
       " ('l', 46),\n",
       " ('m', 47),\n",
       " ('n', 48),\n",
       " ('o', 49),\n",
       " ('p', 50),\n",
       " ('q', 51),\n",
       " ('r', 52),\n",
       " ('s', 53),\n",
       " ('t', 54),\n",
       " ('u', 55),\n",
       " ('v', 56),\n",
       " ('w', 57),\n",
       " ('x', 58),\n",
       " ('y', 59),\n",
       " ('z', 60),\n",
       " ('{', 61),\n",
       " ('}', 62),\n",
       " ('ċ', 63),\n",
       " ('ġ', 64),\n",
       " ('ক', 65),\n",
       " ('ট', 66),\n",
       " ('ত', 67),\n",
       " ('ন', 68),\n",
       " ('ব', 69),\n",
       " ('ম', 70),\n",
       " ('য', 71),\n",
       " ('র', 72),\n",
       " ('্', 73),\n",
       " ('—', 74),\n",
       " ('’', 75),\n",
       " ('“', 76),\n",
       " ('”', 77),\n",
       " ('←', 78),\n",
       " ('→', 79),\n",
       " ('▁', 80),\n",
       " ('⚠', 81),\n",
       " ('️', 82),\n",
       " ('🤗', 83),\n",
       " ('▁t', 84),\n",
       " ('in', 85),\n",
       " ('▁a', 86),\n",
       " ('en', 87),\n",
       " ('▁th', 88),\n",
       " ('er', 89),\n",
       " ('▁to', 90),\n",
       " (\"',\", 91),\n",
       " (\"▁'\", 92),\n",
       " ('at', 93),\n",
       " ('▁w', 94),\n",
       " ('or', 95),\n",
       " ('se', 96),\n",
       " ('▁the', 97),\n",
       " ('on', 98),\n",
       " ('iz', 99),\n",
       " ('ing', 100),\n",
       " ('ken', 101),\n",
       " ('ra', 102),\n",
       " ('▁c', 103),\n",
       " ('▁f', 104),\n",
       " ('ou', 105),\n",
       " ('▁l', 106),\n",
       " ('keniz', 107),\n",
       " ('re', 108),\n",
       " ('st', 109),\n",
       " ('kenizer', 110),\n",
       " ('▁\\n', 111),\n",
       " ('▁s', 112),\n",
       " ('▁in', 113),\n",
       " ('it', 114),\n",
       " ('de', 115),\n",
       " ('▁b', 116),\n",
       " ('▁o', 117),\n",
       " ('▁tokenizer', 118),\n",
       " ('an', 119),\n",
       " ('▁n', 120),\n",
       " ('ll', 121),\n",
       " ('rain', 122),\n",
       " ('▁y', 123),\n",
       " ('is', 124),\n",
       " ('▁an', 125),\n",
       " (\"▁'ġ\", 126),\n",
       " ('▁you', 127),\n",
       " ('▁p', 128),\n",
       " ('me', 129),\n",
       " ('le', 130),\n",
       " ('▁d', 131),\n",
       " ('ce', 132),\n",
       " ('▁of', 133),\n",
       " ('ch', 134),\n",
       " ('ion', 135),\n",
       " ('ts', 136),\n",
       " ('▁we', 137),\n",
       " ('ex', 138),\n",
       " ('▁h', 139),\n",
       " ('ge', 140),\n",
       " ('pu', 141),\n",
       " ('ro', 142),\n",
       " ('th', 143),\n",
       " ('ġġ', 144),\n",
       " ('to', 145),\n",
       " ('▁u', 146),\n",
       " ('▁on', 147),\n",
       " ('ata', 148),\n",
       " ('▁m', 149),\n",
       " ('ode', 150),\n",
       " ('▁train', 151),\n",
       " ('atase', 152),\n",
       " (':\\n', 153),\n",
       " ('ar', 154),\n",
       " ('ct', 155),\n",
       " ('ed', 156),\n",
       " ('▁lo', 157),\n",
       " ('▁for', 158),\n",
       " ('▁ne', 159),\n",
       " ('▁and', 160),\n",
       " ('▁se', 161),\n",
       " ('▁that', 162),\n",
       " ('▁g', 163),\n",
       " ('mp', 164),\n",
       " ('▁re', 165),\n",
       " ('▁this', 166),\n",
       " ('▁wh', 167),\n",
       " (')\\n', 168),\n",
       " ('un', 169),\n",
       " ('▁i', 170),\n",
       " ('train', 171),\n",
       " ('▁li', 172),\n",
       " ('rom', 173),\n",
       " ('00', 174),\n",
       " ('pus', 175),\n",
       " ('▁training', 176),\n",
       " ('ad', 177),\n",
       " ('▁is', 178),\n",
       " ('▁ex', 179),\n",
       " ('\"\"', 180),\n",
       " ('ame', 181),\n",
       " ('ill', 182),\n",
       " ('ent', 183),\n",
       " ('ation', 184),\n",
       " ('orpus', 185),\n",
       " ('▁can', 186),\n",
       " ('▁sp', 187),\n",
       " ('▁be', 188),\n",
       " ('es', 189),\n",
       " ('ua', 190),\n",
       " ('▁1', 191),\n",
       " ('▁your', 192),\n",
       " ('▁new', 193),\n",
       " ('ld', 194),\n",
       " ('yth', 195),\n",
       " ('▁it', 196),\n",
       " ('▁will', 197),\n",
       " ('ith', 198),\n",
       " ('▁datase', 199),\n",
       " ('▁use', 200),\n",
       " ('mple', 201),\n",
       " ('ly', 202),\n",
       " ('ve', 203),\n",
       " ('▁e', 204),\n",
       " ('ran', 205),\n",
       " ('.\\n', 206),\n",
       " ('la', 207),\n",
       " ('t_', 208),\n",
       " ('▁de', 209),\n",
       " ('▁as', 210),\n",
       " ('▁from', 211),\n",
       " ('our', 212),\n",
       " ('ample', 213),\n",
       " ('ke', 214),\n",
       " ('ow', 215),\n",
       " ('▁=', 216),\n",
       " ('▁fa', 217),\n",
       " ('▁mode', 218),\n",
       " ('▁model', 219),\n",
       " ('\"]', 220),\n",
       " ('[\"', 221),\n",
       " ('_c', 222),\n",
       " ('_d', 223),\n",
       " ('al', 224),\n",
       " ('lf', 225),\n",
       " ('ot', 226),\n",
       " ('ss', 227),\n",
       " ('ere', 228),\n",
       " ('tokenizer', 229),\n",
       " ('ec', 230),\n",
       " ('et', 231),\n",
       " ('fun', 232),\n",
       " ('gua', 233),\n",
       " ('pt', 234),\n",
       " ('ut', 235),\n",
       " ('’s', 236),\n",
       " ('▁at', 237),\n",
       " ('▁are', 238),\n",
       " ('erat', 239),\n",
       " ('▁corpus', 240),\n",
       " ('angua', 241),\n",
       " ('▁ha', 242),\n",
       " ('ction', 243),\n",
       " ('▁dataset', 244),\n",
       " ('func', 245),\n",
       " ('erator', 246),\n",
       " ('anguage', 247),\n",
       " ('all', 248),\n",
       " ('ic', 249),\n",
       " ('ok', 250),\n",
       " ('ur', 251),\n",
       " ('ine', 252),\n",
       " ('ers', 253),\n",
       " ('▁token', 254),\n",
       " ('▁with', 255),\n",
       " ('▁co', 256),\n",
       " ('▁language', 257),\n",
       " ('▁tokenizers', 258),\n",
       " ('ython', 259),\n",
       " ('_datase', 260),\n",
       " ('ver', 261),\n",
       " ('▁\"', 262),\n",
       " ('▁me', 263),\n",
       " ('▁tex', 264),\n",
       " ('▁al', 265),\n",
       " ('▁ch', 266),\n",
       " ('▁python', 267),\n",
       " ('▁whi', 268),\n",
       " ('▁if', 269),\n",
       " ('▁fast', 270),\n",
       " ('()', 271),\n",
       " ('ace', 272),\n",
       " ('mb', 273),\n",
       " ('ring', 274),\n",
       " ('tur', 275),\n",
       " ('▁(', 276),\n",
       " ('ize', 277),\n",
       " ('string', 278),\n",
       " ('▁not', 279),\n",
       " ('▁do', 280),\n",
       " ('▁us', 281),\n",
       " ('▁see', 282),\n",
       " ('000', 283),\n",
       " ('▁texts', 284),\n",
       " ('▁which', 285),\n",
       " ('turn', 286),\n",
       " ('_n', 287),\n",
       " ('as', 288),\n",
       " ('for', 289),\n",
       " ('id', 290),\n",
       " ('ir', 291),\n",
       " ('lo', 292),\n",
       " ('ry', 293),\n",
       " ('size', 294),\n",
       " ('w_datase', 295),\n",
       " ('ċġġ', 296),\n",
       " ('▁🤗', 297),\n",
       " ('▁st', 298),\n",
       " ('▁our', 299),\n",
       " ('▁tokeniz', 300),\n",
       " ('raw_datase', 301),\n",
       " ('▁code', 302),\n",
       " ('▁same', 303),\n",
       " ('▁by', 304),\n",
       " ('▁but', 305),\n",
       " ('▁pro', 306),\n",
       " ('▁load', 307),\n",
       " ('▁example', 308),\n",
       " ('\"\"\"', 309),\n",
       " ('▁spec', 310),\n",
       " ('raw_datasets', 311),\n",
       " ('▁speci', 312),\n",
       " ('\":', 313),\n",
       " (',\\n', 314),\n",
       " (\"_',\", 315),\n",
       " ('_string', 316),\n",
       " ('bra', 317),\n",
       " ('ig', 318),\n",
       " ('sp', 319),\n",
       " ('ust', 320),\n",
       " ('ক্', 321),\n",
       " ('atch', 322),\n",
       " ('▁fun', 323),\n",
       " ('▁so', 324),\n",
       " ('▁tokenizer.', 325),\n",
       " ('▁one', 326),\n",
       " ('▁need', 327),\n",
       " ('train\"]', 328),\n",
       " ('▁list', 329),\n",
       " ('▁libra', 330),\n",
       " ('[\"train\"]', 331),\n",
       " ('▁have', 332),\n",
       " ('▁\"ক্', 333),\n",
       " ('raw_datasets[\"train\"]', 334),\n",
       " ('▁function', 335),\n",
       " ('ake', 336),\n",
       " ('ble', 337),\n",
       " ('ds', 338),\n",
       " ('gg', 339),\n",
       " ('pre', 340),\n",
       " ('qu', 341),\n",
       " ('s\\n', 342),\n",
       " ('sfor', 343),\n",
       " ('’ll', 344),\n",
       " ('▁tran', 345),\n",
       " ('sear', 346),\n",
       " ('self', 347),\n",
       " ('out', 348),\n",
       " ('and', 349),\n",
       " ('ant', 350),\n",
       " ('le_', 351),\n",
       " ('▁hu', 352),\n",
       " ('▁look', 353),\n",
       " ('▁return', 354),\n",
       " ('▁when', 355),\n",
       " ('▁1000', 356),\n",
       " ('▁tokenization', 357),\n",
       " ('▁special', 358),\n",
       " ('▁library', 359),\n",
       " ('gging', 360),\n",
       " ('sform', 361),\n",
       " ('▁transform', 362),\n",
       " ('search', 363),\n",
       " ('),', 364),\n",
       " (']\\n', 365),\n",
       " (\"`',\", 366),\n",
       " ('ay', 367),\n",
       " ('ain', 368),\n",
       " ('apt', 369),\n",
       " ('dent', 370),\n",
       " ('ew', 371),\n",
       " ('from', 372),\n",
       " ('ime', 373),\n",
       " ('lit', 374),\n",
       " ('net', 375),\n",
       " ('ole_', 376),\n",
       " ('wh', 377),\n",
       " (\"ġ',\", 378),\n",
       " ('’t', 379),\n",
       " ('▁[', 380),\n",
       " ('▁r', 381),\n",
       " ('▁ge', 382),\n",
       " ('int', 383),\n",
       " (\"▁'.\", 384),\n",
       " (\"▁'func\", 385),\n",
       " (\"▁'ċġġ\", 386),\n",
       " (\"▁'_',\", 387),\n",
       " ('▁want', 388),\n",
       " ('ory', 389),\n",
       " ('▁cre', 390),\n",
       " ('▁fir', 391),\n",
       " ('ould', 392),\n",
       " ('▁name', 393),\n",
       " ('▁pr', 394),\n",
       " ('▁we’ll', 395),\n",
       " ('▁self', 396),\n",
       " ('▁gen', 397),\n",
       " ('▁def', 398),\n",
       " ('_corpus', 399),\n",
       " ('tokenizer.', 400),\n",
       " ('func_string', 401),\n",
       " ('▁using', 402),\n",
       " ('igh', 403),\n",
       " ('from_', 404),\n",
       " ('ole_func_string', 405),\n",
       " ('▁first', 406),\n",
       " (\"(',\", 407),\n",
       " ('):\\n', 408),\n",
       " ('ac', 409),\n",
       " (\"a',\", 410),\n",
       " ('ach', 411),\n",
       " ('act', 412),\n",
       " ('el', 413),\n",
       " ('ist', 414),\n",
       " ('mm', 415),\n",
       " ('od', 416),\n",
       " ('os', 417),\n",
       " ('ost', 418),\n",
       " ('pen', 419),\n",
       " (\"t',\", 420),\n",
       " ('ub', 421),\n",
       " ('ul', 422),\n",
       " ('ure', 423),\n",
       " ('uto', 424),\n",
       " ('umb', 425),\n",
       " ('ven', 426),\n",
       " ('ving', 427),\n",
       " ('▁+', 428),\n",
       " ('▁en', 429),\n",
       " (\"▁',\", 430),\n",
       " ('▁or', 431),\n",
       " ('▁ran', 432),\n",
       " ('▁take', 433),\n",
       " ('▁time', 434),\n",
       " ('▁av', 435),\n",
       " ('▁auto', 436),\n",
       " ('en(', 437),\n",
       " (\"▁')\", 438),\n",
       " ('▁wor', 439),\n",
       " ('▁fo', 440),\n",
       " ('▁sa', 441),\n",
       " ('▁into', 442),\n",
       " ('def', 443),\n",
       " ('▁old', 444),\n",
       " ('llow', 445),\n",
       " (\"▁'ġ',\", 446),\n",
       " ('cess', 447),\n",
       " ('▁here', 448),\n",
       " ('▁go', 449),\n",
       " ('trained', 450),\n",
       " ('▁like', 451),\n",
       " ('▁split', 452),\n",
       " ('ything', 453),\n",
       " ('▁it’s', 454),\n",
       " ('▁note', 455),\n",
       " ('▁some', 456),\n",
       " (\"self',\", 457),\n",
       " ('outpu', 458),\n",
       " ('apter', 459),\n",
       " ('whole_func_string', 460),\n",
       " (\"▁'.',\", 461),\n",
       " ('▁creat', 462),\n",
       " ('▁print', 463),\n",
       " ('▁generator', 464),\n",
       " ('umbers', 465),\n",
       " (\"▁',',\", 466),\n",
       " ('\")\\n', 467),\n",
       " ('(\"', 468),\n",
       " ('))\\n', 469),\n",
       " ('-tokenizer', 470),\n",
       " ('-search', 471),\n",
       " ('-net', 472),\n",
       " ('0,', 473),\n",
       " (\":',\", 474),\n",
       " ('__', 475),\n",
       " ('_from_', 476),\n",
       " ('cr', 477),\n",
       " ('gor', 478),\n",
       " ('just', 479),\n",
       " ('ms', 480),\n",
       " ('so', 481),\n",
       " ('ten', 482),\n",
       " ('um', 483),\n",
       " ('▁2', 484),\n",
       " ('▁3', 485),\n",
       " ('▁\"\"\"', 486),\n",
       " ('▁qu', 487),\n",
       " ('▁just', 488),\n",
       " (\"▁'size\", 489),\n",
       " ('▁cor', 490),\n",
       " ('▁con', 491),\n",
       " ('▁call', 492),\n",
       " ('▁le', 493),\n",
       " ('▁let', 494),\n",
       " ('▁line', 495),\n",
       " ('▁sh', 496),\n",
       " ('▁inst', 497),\n",
       " ('iterator', 498),\n",
       " ('▁batch', 499),\n",
       " ('▁tokenizer\\n', 500),\n",
       " ('ge(', 501),\n",
       " ('ther', 502),\n",
       " ('tokeniz', 503),\n",
       " ('▁un', 504),\n",
       " ('▁only', 505),\n",
       " ('▁most', 506),\n",
       " ('▁log', 507),\n",
       " ('training', 508),\n",
       " ('add', 509),\n",
       " ('▁exact', 510),\n",
       " ('▁space', 511),\n",
       " ('▁datasets', 512),\n",
       " ('▁used', 513),\n",
       " ('▁each', 514),\n",
       " ('lay', 515),\n",
       " ('t_size', 516),\n",
       " ('[\"whole_func_string', 517),\n",
       " ('▁tokens', 518),\n",
       " ('very', 519),\n",
       " ('▁meth', 520),\n",
       " ('▁algor', 521),\n",
       " ('▁also', 522),\n",
       " ('▁chapter', 523),\n",
       " ('_new', 524),\n",
       " ('spon', 525),\n",
       " ('pretrained', 526),\n",
       " ('▁hugging', 527),\n",
       " ('▁self.', 528),\n",
       " ('▁range(', 529),\n",
       " ('▁follow', 530),\n",
       " ('▁print(', 531),\n",
       " ('-search-net', 532),\n",
       " ('_from_iterator', 533),\n",
       " (\"▁'size',\", 534),\n",
       " ('▁let’s', 535),\n",
       " ('[\"whole_func_string\"]', 536),\n",
       " ('▁algorith', 537),\n",
       " ('_new_from_iterator', 538),\n",
       " ('▁following', 539),\n",
       " ('-search-net-tokenizer', 540),\n",
       " ('(ex', 541),\n",
       " ('-c', 542),\n",
       " ('][\"whole_func_string\"]', 543),\n",
       " ('ai', 544),\n",
       " ('ara', 545),\n",
       " ('bi', 546),\n",
       " ('bo', 547),\n",
       " (\"b',\", 548),\n",
       " ('code', 549),\n",
       " ('di', 550),\n",
       " ('eigh', 551),\n",
       " ('e(ex', 552),\n",
       " ('face', 553),\n",
       " ('ie', 554),\n",
       " ('if', 555),\n",
       " ('mory', 556),\n",
       " ('ri', 557),\n",
       " ('rit', 558),\n",
       " ('s:', 559),\n",
       " ('tain', 560),\n",
       " ('vi', 561),\n",
       " ('wo', 562),\n",
       " ('weigh', 563),\n",
       " ('▁#', 564),\n",
       " ('▁5', 565),\n",
       " ('▁7', 566),\n",
       " ('▁9', 567),\n",
       " ('▁_', 568),\n",
       " ('▁raw_datasets[\"train\"]', 569),\n",
       " ('▁very', 570),\n",
       " ('▁tas', 571),\n",
       " ('▁ad', 572),\n",
       " ('▁all', 573),\n",
       " ('ents', 574),\n",
       " (\"▁'(',\", 575),\n",
       " (\"▁'a',\", 576),\n",
       " ('▁won', 577),\n",
       " ('▁would', 578),\n",
       " ('▁writ', 579),\n",
       " ('ses', 580),\n",
       " ('▁them', 581),\n",
       " ('ized', 582),\n",
       " ('out_', 583),\n",
       " ('▁len(', 584),\n",
       " ('▁scr', 585),\n",
       " ('▁int', 586),\n",
       " ('▁indent', 587),\n",
       " (\"▁'ġt\", 588),\n",
       " (\"▁'ġ`',\", 589),\n",
       " (\"▁'ġself',\", 590),\n",
       " ('▁you’', 591),\n",
       " ('the', 592),\n",
       " ('ġġġġ', 593),\n",
       " ('▁once', 594),\n",
       " ('arn', 595),\n",
       " ('ual', 596),\n",
       " ('▁even', 597),\n",
       " ('rand', 598),\n",
       " ('lass', 599),\n",
       " ('ourse', 600),\n",
       " ('▁models', 601),\n",
       " ('▁memory', 602),\n",
       " ('():\\n', 603),\n",
       " ('▁star', 604),\n",
       " ('▁process', 605),\n",
       " ('▁transformers', 606),\n",
       " (\"▁['\", 607),\n",
       " ('▁get', 608),\n",
       " ('▁autotokenizer.', 609),\n",
       " (\"▁'):',\", 610),\n",
       " (\"def',\", 611),\n",
       " ('▁notebo', 612),\n",
       " ('▁create', 613),\n",
       " (\"umbers',\", 614),\n",
       " ('▁contain', 615),\n",
       " ('▁learn', 616),\n",
       " ('tokenize(ex', 617),\n",
       " ('training_corpus', 618),\n",
       " (\"add',\", 619),\n",
       " ('layer', 620),\n",
       " ('▁method', 621),\n",
       " ('▁range(0,', 622),\n",
       " ('▁print(l', 623),\n",
       " ('▁algorithm', 624),\n",
       " ('bias', 625),\n",
       " ('▁task', 626),\n",
       " ('▁won’t', 627),\n",
       " ('▁written', 628),\n",
       " ('out_ms', 629),\n",
       " ('▁scratch', 630),\n",
       " ('▁indentation', 631),\n",
       " ('▁notebook', 632),\n",
       " ('tokenize(example', 633),\n",
       " ('!\\n', 634),\n",
       " (\"''\", 635),\n",
       " (\"']\\n\", 636),\n",
       " (\"+',\", 637),\n",
       " ('-2', 638),\n",
       " ('[i', 639),\n",
       " ('_to', 640),\n",
       " ('_tokenizer.', 641),\n",
       " ('_pretrained', 642),\n",
       " ('ade', 643),\n",
       " ('age', 644),\n",
       " ('du', 645),\n",
       " ('ect', 646),\n",
       " ('ead', 647),\n",
       " ('fo', 648),\n",
       " ('gl', 649),\n",
       " ('ire', 650),\n",
       " ('ive', 651),\n",
       " ('ls', 652),\n",
       " ('min', 653),\n",
       " (\"numbers',\", 654),\n",
       " ('oc', 655),\n",
       " ('op', 656),\n",
       " ('oid', 657),\n",
       " ('pl', 658),\n",
       " ('pos', 659),\n",
       " ('wor', 660),\n",
       " ('yp', 661),\n",
       " ('▁4', 662),\n",
       " ('▁6', 663),\n",
       " ('▁8', 664),\n",
       " ('▁:', 665),\n",
       " ('▁ġ', 666),\n",
       " ('▁typ', 667),\n",
       " ('inpu', 668),\n",
       " ('▁ap', 669),\n",
       " ('▁act', 670),\n",
       " ('ence', 671),\n",
       " ('▁there', 672),\n",
       " ('ermin', 673),\n",
       " (\"▁'ċ\", 674),\n",
       " (\"▁'`',\", 675),\n",
       " ('ath', 676),\n",
       " ('ature', 677),\n",
       " ('ort', 678),\n",
       " ('semb', 679),\n",
       " ('one', 680),\n",
       " ('kens', 681),\n",
       " ('return', 682),\n",
       " ('respon', 683),\n",
       " ('▁sub', 684),\n",
       " ('▁inpu', 685),\n",
       " ('▁info', 686),\n",
       " ('itory', 687),\n",
       " ('▁bit', 688),\n",
       " ('▁open', 689),\n",
       " ('ish', 690),\n",
       " ('▁anything', 691),\n",
       " (\"▁'ġ+',\", 692),\n",
       " (\"▁'ġreturn\", 693),\n",
       " ('▁pre', 694),\n",
       " ('les', 695),\n",
       " ('▁data', 696),\n",
       " ('▁how', 697),\n",
       " ('▁hand', 698),\n",
       " ('▁hel', 699),\n",
       " ('▁loop', 700),\n",
       " ('▁set', 701),\n",
       " ('▁gpt', 702),\n",
       " ('mport', 703),\n",
       " ('▁repre', 704),\n",
       " ('▁import', 705),\n",
       " ('train_new_from_iterator', 706),\n",
       " ('▁training_corpus', 707),\n",
       " (\"ame',\", 708),\n",
       " ('entation', 709),\n",
       " ('▁1,', 710),\n",
       " ('▁iterator', 711),\n",
       " ('▁ever', 712),\n",
       " ('lable', 713),\n",
       " ('t_id', 714),\n",
       " ('t_training_corpus', 715),\n",
       " ('▁det', 716),\n",
       " ('▁assemb', 717),\n",
       " ('▁face', 718),\n",
       " ('_cb', 719),\n",
       " ('_code', 720),\n",
       " ('ication', 721),\n",
       " ('▁comp', 722),\n",
       " ('▁comm', 723),\n",
       " ('_dataset', 724),\n",
       " ('▁doc', 725),\n",
       " ('▁does', 726),\n",
       " (\"_name',\", 727),\n",
       " ('load', 728),\n",
       " ('▁load_dataset', 729),\n",
       " ('\"\"\"\\',', 730),\n",
       " ('▁one\\n', 731),\n",
       " ('▁needs', 732),\n",
       " ('▁lists', 733),\n",
       " ('raw_datasets[\"train\"]),', 734),\n",
       " ('▁returns', 735),\n",
       " ('▁1000][\"whole_func_string\"]', 736),\n",
       " ('▁tokenization\\n', 737),\n",
       " ('▁transformer', 738),\n",
       " ('▁ru', 739),\n",
       " ('▁rust', 740),\n",
       " ('▁get_training_corpus', 741),\n",
       " (\"▁'func_code\", 742),\n",
       " (\"▁'ċġġġ',\", 743),\n",
       " (\"▁'ċġġġġġġ\", 744),\n",
       " ('ack', 745),\n",
       " ('istic', 746),\n",
       " ('▁engl', 747),\n",
       " ('▁timeout_ms', 748),\n",
       " ('▁avai', 749),\n",
       " ('▁avoid', 750),\n",
       " ('▁work', 751),\n",
       " (\"output',\", 752),\n",
       " ('output_size', 753),\n",
       " ('(\"code', 754),\n",
       " ('▁2,', 755),\n",
       " ('▁instead', 756),\n",
       " ('▁spaces', 757),\n",
       " ('-search-net-tokenizer\")\\n', 758),\n",
       " ('face-c', 759),\n",
       " ('▁len(raw_datasets[\"train\"]),', 760),\n",
       " ('▁you’re', 761),\n",
       " ('tokenize(example)\\n', 762),\n",
       " ('aded', 763),\n",
       " ('pository', 764),\n",
       " ('▁subwor', 765),\n",
       " ('▁info_cb', 766),\n",
       " (\"▁'ġreturn',\", 767),\n",
       " ('▁help', 768),\n",
       " ('▁gpt-2', 769),\n",
       " ('▁repres', 770),\n",
       " ('▁everything', 771),\n",
       " ('t_idx', 772),\n",
       " (\"▁'ċġġġġġġġ',\", 773),\n",
       " ('▁english', 774),\n",
       " ('▁available', 775),\n",
       " ('\",', 776),\n",
       " (\"'\\n\", 777),\n",
       " (\"'s\", 778),\n",
       " ('(g', 779),\n",
       " ('()\\n', 780),\n",
       " ('(self', 781),\n",
       " (').', 782),\n",
       " ('-t', 783),\n",
       " ('12', 784),\n",
       " ('3\\n', 785),\n",
       " (\"=',\", 786),\n",
       " ('_h', 787),\n",
       " ('_lo', 788),\n",
       " (\"__',\", 789),\n",
       " ('`.', 790),\n",
       " ('a,', 791),\n",
       " ('ab', 792),\n",
       " ('ast', 793),\n",
       " ('ait', 794),\n",
       " ('air', 795),\n",
       " ('bj', 796),\n",
       " (\"b']\\n\", 797),\n",
       " ('back', 798),\n",
       " ('cc', 799),\n",
       " ('ci', 800),\n",
       " ('ck', 801),\n",
       " ('con', 802),\n",
       " ('class', 803),\n",
       " ('ding', 804),\n",
       " ('ea', 805),\n",
       " ('ep', 806),\n",
       " ('est', 807),\n",
       " ('eature', 808),\n",
       " ('ff', 809),\n",
       " ('gin', 810),\n",
       " ('gra', 811),\n",
       " ('hu', 812),\n",
       " ('ice', 813),\n",
       " ('ild', 814),\n",
       " ('imple', 815),\n",
       " ('iving', 816),\n",
       " ('lp', 817),\n",
       " ('lin', 818),\n",
       " ('ling', 819),\n",
       " ('low', 820),\n",
       " ('line', 821),\n",
       " ('lum', 822),\n",
       " ('mal', 823),\n",
       " ('mall', 824),\n",
       " ('ments', 825),\n",
       " ('mized', 826),\n",
       " (\"n',\", 827),\n",
       " ('n’t', 828),\n",
       " ('other', 829),\n",
       " ('ols', 830),\n",
       " ('pla', 831),\n",
       " ('rch', 832),\n",
       " ('s.', 833),\n",
       " ('sul', 834),\n",
       " ('ti', 835),\n",
       " ('ting', 836),\n",
       " ('ud', 837),\n",
       " ('ues', 838),\n",
       " ('uild', 839),\n",
       " ('vid', 840),\n",
       " ('way', 841),\n",
       " ('wice', 842),\n",
       " (\"x',\", 843),\n",
       " ('ymb', 844),\n",
       " ('zer', 845),\n",
       " ('{\\n', 846),\n",
       " ('র\":', 847),\n",
       " ('্র\":', 848),\n",
       " ('▁`', 849),\n",
       " ('▁x', 850),\n",
       " ('▁}', 851),\n",
       " ('▁ċ', 852),\n",
       " ('▁—', 853),\n",
       " ('▁)\\n', 854),\n",
       " ('▁ent', 855),\n",
       " ('▁ċġġ', 856),\n",
       " ('▁output_size', 857),\n",
       " ('▁two', 858),\n",
       " ('▁twice', 859),\n",
       " ('init', 860),\n",
       " ('inut', 861),\n",
       " ('▁ar', 862),\n",
       " ('▁able', 863),\n",
       " ('enot', 864),\n",
       " ('en))\\n', 865),\n",
       " ('▁then', 866),\n",
       " ('▁thing', 867),\n",
       " ('▁thre', 868),\n",
       " ('▁than', 869),\n",
       " ('er.\\n', 870),\n",
       " ('▁torch', 871),\n",
       " (\"▁'self',\", 872),\n",
       " (\"▁'__\", 873),\n",
       " (\"▁'b',\", 874),\n",
       " (\"▁'weigh\", 875),\n",
       " (\"▁'add',\", 876),\n",
       " (\"▁'bias\", 877),\n",
       " ('ater', 878),\n",
       " ('▁was', 879),\n",
       " ('▁way', 880),\n",
       " ('▁wait', 881),\n",
       " ('ore', 882),\n",
       " ('orch', 883),\n",
       " ('ormal', 884),\n",
       " ('ram', 885),\n",
       " ('▁class', 886),\n",
       " ('▁course', 887),\n",
       " ('▁cud', 888),\n",
       " ('▁fi', 889),\n",
       " ('▁fine', 890),\n",
       " ('▁few', 891),\n",
       " ('▁feature', 892),\n",
       " ('▁later', 893),\n",
       " ('rect', 894),\n",
       " ('repository', 895),\n",
       " ('▁su', 896),\n",
       " ('▁sent', 897),\n",
       " ('▁sour', 898),\n",
       " ('▁sample', 899),\n",
       " ('▁small', 900),\n",
       " ('▁symb', 901),\n",
       " ('▁in,', 902),\n",
       " ('▁indi', 903),\n",
       " ('▁bo', 904),\n",
       " ('▁blo', 905),\n",
       " ('▁brand', 906),\n",
       " ('▁build', 907),\n",
       " ('▁opt', 908),\n",
       " ('▁other', 909),\n",
       " ('▁obj', 910),\n",
       " ('▁tokenizer,', 911),\n",
       " ('aning', 912),\n",
       " ('ance', 913),\n",
       " ('▁nex', 914),\n",
       " ('▁now', 915),\n",
       " ('▁nlp', 916),\n",
       " ('▁normal', 917),\n",
       " ('lly', 918),\n",
       " ('llel', 919),\n",
       " ('▁yie', 920),\n",
       " ('▁any', 921),\n",
       " ('▁another', 922),\n",
       " (\"▁'ġand\", 923),\n",
       " (\"▁'ġa',\", 924),\n",
       " (\"▁'ġb',\", 925),\n",
       " (\"▁'ġthe\", 926),\n",
       " (\"▁'ġdef',\", 927),\n",
       " (\"▁'ġadd',\", 928),\n",
       " (\"▁'ġnumbers',\", 929),\n",
       " ('▁\\'ġ\"\"\"\\',', 930),\n",
       " (\"▁'ġoutput',\", 931),\n",
       " (\"▁'ġ=',\", 932),\n",
       " (\"▁'ġ__',\", 933),\n",
       " (\"▁'ġb']\\n\", 934),\n",
       " (\"▁'ġx',\", 935),\n",
       " ('▁par', 936),\n",
       " ('▁pow', 937),\n",
       " ('▁pic', 938),\n",
       " ('▁pure', 939),\n",
       " ('▁para', 940),\n",
       " ('lements', 941),\n",
       " ('▁dis', 942),\n",
       " ('▁denot', 943),\n",
       " ('cep', 944),\n",
       " ('ions', 945),\n",
       " ('ge,', 946),\n",
       " ('rodu', 947),\n",
       " ('▁mill', 948),\n",
       " ('▁make', 949),\n",
       " ('▁main', 950),\n",
       " ('▁minut', 951),\n",
       " ('▁train_new_from_iterator', 952),\n",
       " ('ary', 953),\n",
       " ('arat', 954),\n",
       " ('aring', 955),\n",
       " ('arlayer', 956),\n",
       " ('▁loaded', 957),\n",
       " ('▁section', 958),\n",
       " ('▁gra', 959),\n",
       " ('▁requ', 960),\n",
       " ('▁respon', 961),\n",
       " ('▁repla', 962),\n",
       " ('▁resul', 963),\n",
       " ('▁this,', 964),\n",
       " ('▁why', 965),\n",
       " ('▁what', 966),\n",
       " ('uning', 967),\n",
       " ('▁ident', 968),\n",
       " ('▁exec', 969),\n",
       " ('▁befor', 970),\n",
       " ('es)', 971),\n",
       " ('es,', 972),\n",
       " ('ually', 973),\n",
       " ('▁1.', 974),\n",
       " ('▁10', 975),\n",
       " ('▁12', 976),\n",
       " ('▁newlin', 977),\n",
       " ('ly,', 978),\n",
       " ('ve_pretrained', 979),\n",
       " ('▁elements', 980),\n",
       " ('▁depen', 981),\n",
       " ('▁ask', 982),\n",
       " ('▁models\\n', 983),\n",
       " ('_call', 984),\n",
       " ('_doc', 985),\n",
       " ('ssage', 986),\n",
       " ('erest', 987),\n",
       " ('eck', 988),\n",
       " ('▁corpus\\n', 989),\n",
       " ('▁corpus.\\n', 990),\n",
       " ('▁has', 991),\n",
       " ('▁having', 992),\n",
       " ('ction\\n', 993),\n",
       " ('▁dataset.', 994),\n",
       " ('ally', 995),\n",
       " ('▁tokens\\n', 996),\n",
       " ('▁colum', 997),\n",
       " ('▁language.', 998),\n",
       " (\"▁tokenizers'\", 999),\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(custom_tokenizer.tokenizer.get_vocab().items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import SentencePieceBPETokenizer\n",
    "\n",
    "# Create a list of initial words you want in the vocabulary\n",
    "initial_words = [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\"]\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = SentencePieceBPETokenizer()\n",
    "\n",
    "# Train the tokenizer with the initial_alphabet parameter\n",
    "tokenizer.train(\n",
    "    files=[\"demo.txt\"],\n",
    "    vocab_size=10000,\n",
    "    min_frequency=2,\n",
    "    initial_alphabet=initial_words,\n",
    "    special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from spe_tokenizer_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tokenizer = CustomTokenizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='', vocab_size=1234, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer = _tokenizer.train(\n",
    "    files=['demo.txt']\n",
    ")\n",
    "hf_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 104, 90, 0, 0, 97, 90, 104, 0, 96, 0, 345, 0, 0, 96, 104, 96, 0, 90, 0, 92, 104, 0, 0, 0, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_tokenizer.encode_plus(\"টেস্ট পরীক্ষার রুটিন ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizer_config.json', './special_tokens_map.json', './tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<unk>', 0),\n",
       " ('<pad>', 1),\n",
       " ('<s>', 2),\n",
       " ('</s>', 3),\n",
       " ('<mask>', 4),\n",
       " ('\\n', 5),\n",
       " ('!', 6),\n",
       " ('\"', 7),\n",
       " ('#', 8),\n",
       " (\"'\", 9),\n",
       " ('(', 10),\n",
       " (')', 11),\n",
       " ('+', 12),\n",
       " (',', 13),\n",
       " ('-', 14),\n",
       " ('.', 15),\n",
       " ('/', 16),\n",
       " ('0', 17),\n",
       " ('1', 18),\n",
       " ('2', 19),\n",
       " ('3', 20),\n",
       " ('4', 21),\n",
       " ('5', 22),\n",
       " ('6', 23),\n",
       " ('7', 24),\n",
       " ('8', 25),\n",
       " ('9', 26),\n",
       " (':', 27),\n",
       " (';', 28),\n",
       " ('=', 29),\n",
       " ('?', 30),\n",
       " ('@', 31),\n",
       " ('A', 32),\n",
       " ('B', 33),\n",
       " ('C', 34),\n",
       " ('D', 35),\n",
       " ('E', 36),\n",
       " ('F', 37),\n",
       " ('G', 38),\n",
       " ('H', 39),\n",
       " ('I', 40),\n",
       " ('K', 41),\n",
       " ('L', 42),\n",
       " ('M', 43),\n",
       " ('N', 44),\n",
       " ('O', 45),\n",
       " ('P', 46),\n",
       " ('Q', 47),\n",
       " ('R', 48),\n",
       " ('S', 49),\n",
       " ('T', 50),\n",
       " ('U', 51),\n",
       " ('W', 52),\n",
       " ('X', 53),\n",
       " ('Y', 54),\n",
       " ('[', 55),\n",
       " (']', 56),\n",
       " ('_', 57),\n",
       " ('`', 58),\n",
       " ('a', 59),\n",
       " ('b', 60),\n",
       " ('c', 61),\n",
       " ('d', 62),\n",
       " ('e', 63),\n",
       " ('f', 64),\n",
       " ('g', 65),\n",
       " ('h', 66),\n",
       " ('i', 67),\n",
       " ('j', 68),\n",
       " ('k', 69),\n",
       " ('l', 70),\n",
       " ('m', 71),\n",
       " ('n', 72),\n",
       " ('o', 73),\n",
       " ('p', 74),\n",
       " ('q', 75),\n",
       " ('r', 76),\n",
       " ('s', 77),\n",
       " ('t', 78),\n",
       " ('u', 79),\n",
       " ('v', 80),\n",
       " ('w', 81),\n",
       " ('x', 82),\n",
       " ('y', 83),\n",
       " ('z', 84),\n",
       " ('{', 85),\n",
       " ('}', 86),\n",
       " ('Ċ', 87),\n",
       " ('Ġ', 88),\n",
       " ('ক', 89),\n",
       " ('ট', 90),\n",
       " ('ত', 91),\n",
       " ('ন', 92),\n",
       " ('ব', 93),\n",
       " ('ম', 94),\n",
       " ('য', 95),\n",
       " ('র', 96),\n",
       " ('্', 97),\n",
       " ('—', 98),\n",
       " ('’', 99),\n",
       " ('“', 100),\n",
       " ('”', 101),\n",
       " ('←', 102),\n",
       " ('→', 103),\n",
       " ('▁', 104),\n",
       " ('⚠', 105),\n",
       " ('️', 106),\n",
       " ('🤗', 107),\n",
       " ('▁t', 108),\n",
       " ('in', 109),\n",
       " ('▁a', 110),\n",
       " ('en', 111),\n",
       " ('er', 112),\n",
       " ('▁th', 113),\n",
       " (\"',\", 114),\n",
       " ('▁to', 115),\n",
       " (\"▁'\", 116),\n",
       " ('at', 117),\n",
       " ('▁w', 118),\n",
       " ('or', 119),\n",
       " ('on', 120),\n",
       " ('se', 121),\n",
       " ('iz', 122),\n",
       " ('ing', 123),\n",
       " ('ken', 124),\n",
       " ('ra', 125),\n",
       " ('▁the', 126),\n",
       " ('keniz', 127),\n",
       " ('ou', 128),\n",
       " ('▁c', 129),\n",
       " ('▁f', 130),\n",
       " ('▁l', 131),\n",
       " ('st', 132),\n",
       " ('re', 133),\n",
       " ('kenizer', 134),\n",
       " ('▁\\n', 135),\n",
       " ('▁s', 136),\n",
       " ('▁in', 137),\n",
       " ('it', 138),\n",
       " ('de', 139),\n",
       " ('an', 140),\n",
       " ('▁o', 141),\n",
       " ('▁b', 142),\n",
       " ('▁tokenizer', 143),\n",
       " ('ll', 144),\n",
       " ('rain', 145),\n",
       " ('is', 146),\n",
       " ('▁n', 147),\n",
       " ('▁an', 148),\n",
       " (\"▁'Ġ\", 149),\n",
       " ('▁y', 150),\n",
       " ('▁T', 151),\n",
       " ('▁you', 152),\n",
       " ('me', 153),\n",
       " ('le', 154),\n",
       " ('ce', 155),\n",
       " ('▁of', 156),\n",
       " ('ch', 157),\n",
       " ('ion', 158),\n",
       " ('ts', 159),\n",
       " ('ex', 160),\n",
       " ('pu', 161),\n",
       " ('ge', 162),\n",
       " ('ro', 163),\n",
       " ('th', 164),\n",
       " ('ĠĠ', 165),\n",
       " ('▁d', 166),\n",
       " ('ata', 167),\n",
       " ('▁we', 168),\n",
       " ('▁on', 169),\n",
       " ('ode', 170),\n",
       " ('atase', 171),\n",
       " ('▁p', 172),\n",
       " ('▁u', 173),\n",
       " (':\\n', 174),\n",
       " ('ar', 175),\n",
       " ('ct', 176),\n",
       " ('ed', 177),\n",
       " ('▁h', 178),\n",
       " ('▁lo', 179),\n",
       " ('to', 180),\n",
       " ('▁m', 181),\n",
       " ('▁ne', 182),\n",
       " ('▁and', 183),\n",
       " ('▁se', 184),\n",
       " ('▁for', 185),\n",
       " ('raining', 186),\n",
       " ('mp', 187),\n",
       " ('▁that', 188),\n",
       " (')\\n', 189),\n",
       " ('un', 190),\n",
       " ('▁wh', 191),\n",
       " ('▁re', 192),\n",
       " ('▁Th', 193),\n",
       " ('rom', 194),\n",
       " ('00', 195),\n",
       " ('▁li', 196),\n",
       " ('pus', 197),\n",
       " ('▁is', 198),\n",
       " ('▁ex', 199),\n",
       " ('\"\"', 200),\n",
       " ('ame', 201),\n",
       " ('ill', 202),\n",
       " ('ent', 203),\n",
       " ('ation', 204),\n",
       " ('orpus', 205),\n",
       " ('▁can', 206),\n",
       " ('es', 207),\n",
       " ('ua', 208),\n",
       " ('▁1', 209),\n",
       " ('▁g', 210),\n",
       " ('▁i', 211),\n",
       " ('▁sp', 212),\n",
       " ('▁be', 213),\n",
       " ('▁your', 214),\n",
       " ('▁new', 215),\n",
       " ('ad', 216),\n",
       " ('ld', 217),\n",
       " ('train', 218),\n",
       " ('yth', 219),\n",
       " ('▁will', 220),\n",
       " ('▁use', 221),\n",
       " ('mple', 222),\n",
       " ('ly', 223),\n",
       " ('ve', 224),\n",
       " ('ran', 225),\n",
       " ('ith', 226),\n",
       " ('ataset', 227),\n",
       " ('.\\n', 228),\n",
       " ('et', 229),\n",
       " ('▁de', 230),\n",
       " ('▁from', 231),\n",
       " ('as', 232),\n",
       " ('ace', 233),\n",
       " ('ample', 234),\n",
       " ('ow', 235),\n",
       " ('t_', 236),\n",
       " ('▁=', 237),\n",
       " ('▁e', 238),\n",
       " ('▁it', 239),\n",
       " ('our', 240),\n",
       " ('odel', 241),\n",
       " ('\"]', 242),\n",
       " ('[\"', 243),\n",
       " ('_d', 244),\n",
       " ('al', 245),\n",
       " ('ke', 246),\n",
       " ('lf', 247),\n",
       " ('ot', 248),\n",
       " ('▁A', 249),\n",
       " ('▁training', 250),\n",
       " ('ere', 251),\n",
       " ('▁this', 252),\n",
       " ('atasets', 253),\n",
       " ('_c', 254),\n",
       " ('ast', 255),\n",
       " ('ec', 256),\n",
       " ('fun', 257),\n",
       " ('gua', 258),\n",
       " ('ur', 259),\n",
       " ('ut', 260),\n",
       " ('’s', 261),\n",
       " ('▁P', 262),\n",
       " ('▁at', 263),\n",
       " ('▁are', 264),\n",
       " ('erat', 265),\n",
       " ('▁corpus', 266),\n",
       " ('angua', 267),\n",
       " ('ction', 268),\n",
       " ('▁model', 269),\n",
       " ('func', 270),\n",
       " ('erator', 271),\n",
       " ('anguage', 272),\n",
       " ('ic', 273),\n",
       " ('▁C', 274),\n",
       " ('▁I', 275),\n",
       " ('ine', 276),\n",
       " ('ers', 277),\n",
       " ('▁token', 278),\n",
       " ('▁with', 279),\n",
       " ('▁language', 280),\n",
       " ('▁dataset', 281),\n",
       " ('ython', 282),\n",
       " ('all', 283),\n",
       " ('ave', 284),\n",
       " ('ok', 285),\n",
       " ('ver', 286),\n",
       " ('▁\"', 287),\n",
       " ('▁me', 288),\n",
       " ('▁tex', 289),\n",
       " ('▁al', 290),\n",
       " ('▁as', 291),\n",
       " ('▁co', 292),\n",
       " ('▁whi', 293),\n",
       " ('▁Python', 294),\n",
       " ('()', 295),\n",
       " ('mb', 296),\n",
       " ('okenizer', 297),\n",
       " ('pt', 298),\n",
       " ('ring', 299),\n",
       " ('▁(', 300),\n",
       " ('ize', 301),\n",
       " ('string', 302),\n",
       " ('▁see', 303),\n",
       " ('▁This', 304),\n",
       " ('000', 305),\n",
       " ('urn', 306),\n",
       " ('▁texts', 307),\n",
       " ('▁which', 308),\n",
       " ('_n', 309),\n",
       " ('ay', 310),\n",
       " ('for', 311),\n",
       " ('id', 312),\n",
       " ('ir', 313),\n",
       " ('lo', 314),\n",
       " ('ss', 315),\n",
       " ('size', 316),\n",
       " ('turn', 317),\n",
       " ('w_d', 318),\n",
       " ('ĊĠĠ', 319),\n",
       " ('▁F', 320),\n",
       " ('▁🤗', 321),\n",
       " ('▁train', 322),\n",
       " ('▁tokeniz', 323),\n",
       " ('raw_d', 324),\n",
       " ('▁same', 325),\n",
       " ('▁pro', 326),\n",
       " ('▁load', 327),\n",
       " ('▁The', 328),\n",
       " ('▁example', 329),\n",
       " ('\"\"\"', 330),\n",
       " ('▁spec', 331),\n",
       " ('raw_datasets', 332),\n",
       " ('▁speci', 333),\n",
       " ('\":', 334),\n",
       " (',\\n', 335),\n",
       " (\"_',\", 336),\n",
       " ('_string', 337),\n",
       " ('bra', 338),\n",
       " ('ha', 339),\n",
       " ('ig', 340),\n",
       " ('ry', 341),\n",
       " ('s\\n', 342),\n",
       " ('sp', 343),\n",
       " ('ust', 344),\n",
       " ('ক্', 345),\n",
       " ('▁st', 346),\n",
       " ('▁our', 347),\n",
       " ('atch', 348),\n",
       " ('▁fun', 349),\n",
       " ('▁fast', 350),\n",
       " ('▁by', 351),\n",
       " ('▁but', 352),\n",
       " ('▁tokenizer.', 353),\n",
       " ('▁not', 354),\n",
       " ('▁do', 355),\n",
       " ('▁one', 356),\n",
       " ('▁have', 357),\n",
       " ('tokenizer', 358),\n",
       " ('▁need', 359),\n",
       " ('▁list', 360),\n",
       " ('▁libra', 361),\n",
       " ('train\"]', 362),\n",
       " ('[\"train\"]', 363),\n",
       " ('▁\"ক্', 364),\n",
       " ('raw_datasets[\"train\"]', 365),\n",
       " ('▁function', 366),\n",
       " ('ain', 367),\n",
       " ('ake', 368),\n",
       " ('ble', 369),\n",
       " ('ds', 370),\n",
       " ('gg', 371),\n",
       " ('pre', 372),\n",
       " ('sfor', 373),\n",
       " ('’ll', 374),\n",
       " ('▁D', 375),\n",
       " ('▁H', 376),\n",
       " ('▁R', 377),\n",
       " ('self', 378),\n",
       " ('out', 379),\n",
       " ('▁code', 380),\n",
       " ('▁so', 381),\n",
       " ('and', 382),\n",
       " ('ant', 383),\n",
       " ('▁Training', 384),\n",
       " ('le_', 385),\n",
       " ('▁us', 386),\n",
       " ('arch', 387),\n",
       " ('▁look', 388),\n",
       " ('▁1000', 389),\n",
       " ('ransfor', 390),\n",
       " ('▁tokenization', 391),\n",
       " ('▁special', 392),\n",
       " ('▁library', 393),\n",
       " ('gging', 394),\n",
       " ('ransform', 395),\n",
       " ('),', 396),\n",
       " (']\\n', 397),\n",
       " (\"`',\", 398),\n",
       " ('act', 399),\n",
       " ('dent', 400),\n",
       " ('ew', 401),\n",
       " ('from', 402),\n",
       " ('ime', 403),\n",
       " ('lit', 404),\n",
       " ('ole_', 405),\n",
       " ('qu', 406),\n",
       " ('ub', 407),\n",
       " ('ugging', 408),\n",
       " ('wh', 409),\n",
       " (\"Ġ',\", 410),\n",
       " ('’t', 411),\n",
       " ('▁E', 412),\n",
       " ('▁G', 413),\n",
       " ('▁S', 414),\n",
       " ('▁W', 415),\n",
       " ('▁[', 416),\n",
       " ('▁ge', 417),\n",
       " (\"▁'.\", 418),\n",
       " (\"▁'func\", 419),\n",
       " (\"▁'ĊĠĠ\", 420),\n",
       " (\"▁'_',\", 421),\n",
       " ('▁want', 422),\n",
       " ('ory', 423),\n",
       " ('ould', 424),\n",
       " ('▁cre', 425),\n",
       " ('▁tokenizers', 426),\n",
       " ('▁name', 427),\n",
       " ('▁self', 428),\n",
       " ('▁when', 429),\n",
       " ('▁return', 430),\n",
       " ('▁gen', 431),\n",
       " ('▁if', 432),\n",
       " ('▁def', 433),\n",
       " ('_corpus', 434),\n",
       " ('func_string', 435),\n",
       " ('irst', 436),\n",
       " ('igh', 437),\n",
       " ('from_', 438),\n",
       " ('ole_func_string', 439),\n",
       " (\"(',\", 440),\n",
       " ('):\\n', 441),\n",
       " ('Tokenizer', 442),\n",
       " (\"a',\", 443),\n",
       " ('ach', 444),\n",
       " ('el', 445),\n",
       " ('ist', 446),\n",
       " ('mm', 447),\n",
       " ('od', 448),\n",
       " ('os', 449),\n",
       " ('ost', 450),\n",
       " ('pl', 451),\n",
       " ('pen', 452),\n",
       " ('rin', 453),\n",
       " (\"t',\", 454),\n",
       " ('uto', 455),\n",
       " ('umb', 456),\n",
       " ('ven', 457),\n",
       " ('ving', 458),\n",
       " ('▁+', 459),\n",
       " ('▁L', 460),\n",
       " ('▁N', 461),\n",
       " ('▁O', 462),\n",
       " (\"▁',\", 463),\n",
       " ('▁or', 464),\n",
       " ('▁ran', 465),\n",
       " ('▁take', 466),\n",
       " ('▁av', 467),\n",
       " ('en(', 468),\n",
       " (\"▁')\", 469),\n",
       " ('search', 470),\n",
       " ('▁fo', 471),\n",
       " ('▁first', 472),\n",
       " ('▁into', 473),\n",
       " ('▁old', 474),\n",
       " ('llow', 475),\n",
       " (\"▁'Ġ',\", 476),\n",
       " ('▁To', 477),\n",
       " ('▁Transform', 478),\n",
       " ('cess', 479),\n",
       " ('▁prin', 480),\n",
       " ('▁go', 481),\n",
       " ('▁split', 482),\n",
       " ('trained', 483),\n",
       " ('ything', 484),\n",
       " ('▁Auto', 485),\n",
       " ('pter', 486),\n",
       " (\"self',\", 487),\n",
       " ('outpu', 488),\n",
       " ('▁some', 489),\n",
       " ('whole_func_string', 490),\n",
       " (\"▁'.',\", 491),\n",
       " ('▁creat', 492),\n",
       " ('▁generator', 493),\n",
       " ('umbers', 494),\n",
       " (\"▁',',\", 495),\n",
       " ('▁print', 496),\n",
       " ('▁AutoTokenizer', 497),\n",
       " ('\")\\n', 498),\n",
       " ('(\"', 499),\n",
       " ('))\\n', 500),\n",
       " ('-n', 501),\n",
       " ('-tokenizer', 502),\n",
       " ('-search', 503),\n",
       " ('0,', 504),\n",
       " (\":',\", 505),\n",
       " ('__', 506),\n",
       " ('_from_', 507),\n",
       " ('ck', 508),\n",
       " ('cr', 509),\n",
       " ('dd', 510),\n",
       " ('gor', 511),\n",
       " ('il', 512),\n",
       " ('just', 513),\n",
       " ('ms', 514),\n",
       " ('s,', 515),\n",
       " ('so', 516),\n",
       " ('ten', 517),\n",
       " ('training', 518),\n",
       " ('ul', 519),\n",
       " ('um', 520),\n",
       " ('▁2', 521),\n",
       " ('▁3', 522),\n",
       " ('▁B', 523),\n",
       " ('▁\"\"\"', 524),\n",
       " ('▁just', 525),\n",
       " ('▁time', 526),\n",
       " (\"▁'size\", 527),\n",
       " ('▁wor', 528),\n",
       " ('▁cor', 529),\n",
       " ('▁con', 530),\n",
       " ('▁call', 531),\n",
       " ('▁le', 532),\n",
       " ('▁inst', 533),\n",
       " ('iterator', 534),\n",
       " ('def', 535),\n",
       " ('▁batch', 536),\n",
       " ('▁tokenizer\\n', 537),\n",
       " ('▁Tokenizer', 538),\n",
       " ('ge(', 539),\n",
       " ('ther', 540),\n",
       " ('▁we’ll', 541),\n",
       " ('▁only', 542),\n",
       " ('▁log', 543),\n",
       " ('tokeniz', 544),\n",
       " ('▁like', 545),\n",
       " ('▁exact', 546),\n",
       " ('▁used', 547),\n",
       " ('et’s', 548),\n",
       " ('et-tokenizer', 549),\n",
       " ('t_size', 550),\n",
       " ('▁each', 551),\n",
       " ('[\"whole_func_string', 552),\n",
       " ('▁As', 553),\n",
       " ('▁If', 554),\n",
       " ('▁In', 555),\n",
       " ('▁tokens', 556),\n",
       " ('very', 557),\n",
       " ('▁meth', 558),\n",
       " ('▁algor', 559),\n",
       " ('▁also', 560),\n",
       " ('_new', 561),\n",
       " ('hapter', 562),\n",
       " ('spon', 563),\n",
       " ('pretrained', 564),\n",
       " ('▁En', 565),\n",
       " ('▁GP', 566),\n",
       " ('▁We', 567),\n",
       " ('▁self.', 568),\n",
       " ('▁range(', 569),\n",
       " ('▁follow', 570),\n",
       " ('▁print(', 571),\n",
       " ('-net-tokenizer', 572),\n",
       " ('-search-net-tokenizer', 573),\n",
       " ('_from_iterator', 574),\n",
       " (\"▁'size',\", 575),\n",
       " ('[\"whole_func_string\"]', 576),\n",
       " ('▁algorith', 577),\n",
       " ('_new_from_iterator', 578),\n",
       " ('▁following', 579),\n",
       " ('(ex', 580),\n",
       " ('-c', 581),\n",
       " ('Lay', 582),\n",
       " ('Us', 583),\n",
       " ('][\"whole_func_string\"]', 584),\n",
       " ('_tokenizer', 585),\n",
       " ('able', 586),\n",
       " ('aving', 587),\n",
       " ('ail', 588),\n",
       " ('bi', 589),\n",
       " ('bo', 590),\n",
       " (\"b',\", 591),\n",
       " ('code', 592),\n",
       " ('di', 593),\n",
       " ('eigh', 594),\n",
       " ('e(ex', 595),\n",
       " ('ebo', 596),\n",
       " ('face', 597),\n",
       " ('ie', 598),\n",
       " ('if', 599),\n",
       " ('las', 600),\n",
       " ('mory', 601),\n",
       " ('oc', 602),\n",
       " ('ri', 603),\n",
       " ('rit', 604),\n",
       " ('s:', 605),\n",
       " ('tain', 606),\n",
       " ('ure', 607),\n",
       " ('vi', 608),\n",
       " ('wo', 609),\n",
       " ('weigh', 610),\n",
       " ('▁#', 611),\n",
       " ('▁5', 612),\n",
       " ('▁7', 613),\n",
       " ('▁9', 614),\n",
       " ('▁M', 615),\n",
       " ('▁_', 616),\n",
       " ('▁raw_datasets[\"train\"]', 617),\n",
       " ('▁qu', 618),\n",
       " ('▁very', 619),\n",
       " ('▁tas', 620),\n",
       " ('▁all', 621),\n",
       " ('ents', 622),\n",
       " (\"▁'(',\", 623),\n",
       " (\"▁'a',\", 624),\n",
       " ('▁won', 625),\n",
       " ('▁would', 626),\n",
       " ('▁writ', 627),\n",
       " ('ses', 628),\n",
       " ('ized', 629),\n",
       " ('▁them', 630),\n",
       " ('out_', 631),\n",
       " ('▁ch', 632),\n",
       " ('▁len(', 633),\n",
       " ('▁scr', 634),\n",
       " ('▁indent', 635),\n",
       " (\"▁'Ġt\", 636),\n",
       " (\"▁'Ġ`',\", 637),\n",
       " (\"▁'Ġself',\", 638),\n",
       " ('the', 639),\n",
       " ('ĠĠĠĠ', 640),\n",
       " ('▁pa', 641),\n",
       " ('▁un', 642),\n",
       " ('arn', 643),\n",
       " ('▁most', 644),\n",
       " ('ual', 645),\n",
       " ('▁space', 646),\n",
       " ('rand', 647),\n",
       " ('▁it’s', 648),\n",
       " ('ourse', 649),\n",
       " ('ote', 650),\n",
       " ('inear', 651),\n",
       " ('▁memory', 652),\n",
       " ('():\\n', 653),\n",
       " ('▁process', 654),\n",
       " ('▁star', 655),\n",
       " ('▁notebo', 656),\n",
       " ('▁Datasets', 657),\n",
       " ('▁using', 658),\n",
       " ('uggingface', 659),\n",
       " (\"▁['\", 660),\n",
       " ('▁get', 661),\n",
       " (\"▁'):',\", 662),\n",
       " ('▁create', 663),\n",
       " (\"umbers',\", 664),\n",
       " ('▁AutoTokenizer.', 665),\n",
       " ('training_corpus', 666),\n",
       " ('▁contain', 667),\n",
       " ('▁learn', 668),\n",
       " (\"def',\", 669),\n",
       " ('▁Tokenizers', 670),\n",
       " ('tokenize(ex', 671),\n",
       " ('▁method', 672),\n",
       " ('▁range(0,', 673),\n",
       " ('▁print(l', 674),\n",
       " ('▁algorithm', 675),\n",
       " ('Layer', 676),\n",
       " ('bias', 677),\n",
       " ('▁task', 678),\n",
       " ('▁won’t', 679),\n",
       " ('▁written', 680),\n",
       " ('out_ms', 681),\n",
       " ('▁scratch', 682),\n",
       " ('▁indentation', 683),\n",
       " ('▁notebook', 684),\n",
       " ('tokenize(example', 685),\n",
       " ('!\\n', 686),\n",
       " (\"''\", 687),\n",
       " (\"']\\n\", 688),\n",
       " (\"+',\", 689),\n",
       " ('-2', 690),\n",
       " ('Add', 691),\n",
       " ('T-2', 692),\n",
       " ('You', 693),\n",
       " ('[i', 694),\n",
       " ('_to', 695),\n",
       " ('_pretrained', 696),\n",
       " ('ab', 697),\n",
       " ('ade', 698),\n",
       " ('du', 699),\n",
       " ('ect', 700),\n",
       " ('ead', 701),\n",
       " ('fo', 702),\n",
       " ('gl', 703),\n",
       " ('ire', 704),\n",
       " ('ive', 705),\n",
       " ('min', 706),\n",
       " (\"numbers',\", 707),\n",
       " ('ol', 708),\n",
       " ('op', 709),\n",
       " ('oid', 710),\n",
       " ('pos', 711),\n",
       " (\"s',\", 712),\n",
       " ('ter', 713),\n",
       " ('wor', 714),\n",
       " ('yp', 715),\n",
       " ('’re', 716),\n",
       " ('▁4', 717),\n",
       " ('▁6', 718),\n",
       " ('▁8', 719),\n",
       " ('▁:', 720),\n",
       " ('▁r', 721),\n",
       " ('▁Ġ', 722),\n",
       " ('▁Us', 723),\n",
       " ('▁You', 724),\n",
       " ('▁typ', 725),\n",
       " ('inpu', 726),\n",
       " ('▁act', 727),\n",
       " ('ence', 728),\n",
       " (\"▁'Ċ\", 729),\n",
       " (\"▁'`',\", 730),\n",
       " ('ath', 731),\n",
       " ('ature', 732),\n",
       " ('ort', 733),\n",
       " ('one', 734),\n",
       " ('semb', 735),\n",
       " ('▁line', 736),\n",
       " ('▁let’s', 737),\n",
       " ('return', 738),\n",
       " ('respon', 739),\n",
       " ('▁sh', 740),\n",
       " ('▁sub', 741),\n",
       " ('▁inpu', 742),\n",
       " ('▁info', 743),\n",
       " ('itory', 744),\n",
       " ('▁bit', 745),\n",
       " ('ish', 746),\n",
       " ('▁anything', 747),\n",
       " (\"▁'Ġ+',\", 748),\n",
       " (\"▁'Ġreturn\", 749),\n",
       " ('les', 750),\n",
       " ('▁data', 751),\n",
       " ('▁once', 752),\n",
       " ('▁pre', 753),\n",
       " ('▁here', 754),\n",
       " ('▁hand', 755),\n",
       " ('▁hel', 756),\n",
       " ('▁loop', 757),\n",
       " ('mport', 758),\n",
       " ('▁repre', 759),\n",
       " (\"ame',\", 760),\n",
       " ('entation', 761),\n",
       " ('▁1,', 762),\n",
       " ('▁import', 763),\n",
       " ('train_new_from_iterator', 764),\n",
       " ('t_id', 765),\n",
       " ('t_training_corpus', 766),\n",
       " ('▁ever', 767),\n",
       " ('▁iterator', 768),\n",
       " ('_dataset', 769),\n",
       " ('▁training_corpus', 770),\n",
       " ('_cb', 771),\n",
       " ('_code', 772),\n",
       " ('▁models', 773),\n",
       " ('ication', 774),\n",
       " ('▁Chapter', 775),\n",
       " ('▁It', 776),\n",
       " ('▁comp', 777),\n",
       " ('▁comm', 778),\n",
       " (\"_name',\", 779),\n",
       " ('load', 780),\n",
       " ('▁Face', 781),\n",
       " ('▁Fast', 782),\n",
       " ('▁load_dataset', 783),\n",
       " ('\"\"\"\\',', 784),\n",
       " ('▁does', 785),\n",
       " ('▁one\\n', 786),\n",
       " ('▁needs', 787),\n",
       " ('▁lists', 788),\n",
       " ('raw_datasets[\"train\"]),', 789),\n",
       " ('▁Here', 790),\n",
       " ('▁Hugging', 791),\n",
       " ('▁Rust', 792),\n",
       " ('▁1000][\"whole_func_string\"]', 793),\n",
       " ('▁tokenization\\n', 794),\n",
       " ('▁get_training_corpus', 795),\n",
       " (\"▁'func_code\", 796),\n",
       " (\"▁'ĊĠĠĠ',\", 797),\n",
       " (\"▁'ĊĠĠĠĠĠĠ\", 798),\n",
       " ('istic', 799),\n",
       " ('▁avail', 800),\n",
       " ('▁avoid', 801),\n",
       " ('▁old_tokenizer', 802),\n",
       " ('▁Transformer', 803),\n",
       " ('▁Transformers', 804),\n",
       " (\"output',\", 805),\n",
       " ('output_size', 806),\n",
       " ('(\"code', 807),\n",
       " ('▁2,', 808),\n",
       " ('▁timeout_ms', 809),\n",
       " ('▁work', 810),\n",
       " ('▁instead', 811),\n",
       " ('▁Engl', 812),\n",
       " ('▁GPT-2', 813),\n",
       " ('-search-net-tokenizer\")\\n', 814),\n",
       " ('▁len(raw_datasets[\"train\"]),', 815),\n",
       " ('▁spaces', 816),\n",
       " ('uggingface-c', 817),\n",
       " ('tokenize(example)\\n', 818),\n",
       " ('aded', 819),\n",
       " ('pository', 820),\n",
       " ('▁Using', 821),\n",
       " ('▁subwor', 822),\n",
       " ('▁info_cb', 823),\n",
       " (\"▁'Ġreturn',\", 824),\n",
       " ('▁help', 825),\n",
       " ('▁repres', 826),\n",
       " ('t_idx', 827),\n",
       " ('▁everything', 828),\n",
       " (\"▁'ĊĠĠĠĠĠĠĠ',\", 829),\n",
       " ('▁available', 830),\n",
       " ('▁English', 831),\n",
       " ('\",', 832),\n",
       " (\"'\\n\", 833),\n",
       " (\"'s\", 834),\n",
       " ('(g', 835),\n",
       " ('()\\n', 836),\n",
       " ('(self', 837),\n",
       " (').', 838),\n",
       " ('-t', 839),\n",
       " ('12', 840),\n",
       " ('3\\n', 841),\n",
       " (\"=',\", 842),\n",
       " ('AY', 843),\n",
       " ('DA', 844),\n",
       " ('KAY', 845),\n",
       " ('LP', 846),\n",
       " ('Linear', 847),\n",
       " ('Net', 848),\n",
       " ('PI', 849),\n",
       " ('Se', 850),\n",
       " ('UDA', 851),\n",
       " ('_h', 852),\n",
       " ('_lo', 853),\n",
       " (\"__',\", 854),\n",
       " ('`.', 855),\n",
       " ('aw', 856),\n",
       " ('ait', 857),\n",
       " ('age', 858),\n",
       " ('ack', 859),\n",
       " ('bj', 860),\n",
       " (\"b']\\n\", 861),\n",
       " ('cc', 862),\n",
       " ('ci', 863),\n",
       " ('con', 864),\n",
       " ('cce', 865),\n",
       " ('cstring', 866),\n",
       " ('clas', 867),\n",
       " (\"d',\", 868),\n",
       " ('ding', 869),\n",
       " ('ea', 870),\n",
       " ('ep', 871),\n",
       " ('est', 872),\n",
       " ('eature', 873),\n",
       " ('ff', 874),\n",
       " ('gin', 875),\n",
       " ('gra', 876),\n",
       " ('hen', 877),\n",
       " ('huggingface-c', 878),\n",
       " ('ice', 879),\n",
       " ('ild', 880),\n",
       " ('imple', 881),\n",
       " ('iving', 882),\n",
       " ('lin', 883),\n",
       " ('ling', 884),\n",
       " ('low', 885),\n",
       " ('lum', 886),\n",
       " ('mal', 887),\n",
       " ('mall', 888),\n",
       " ('ments', 889),\n",
       " ('mized', 890),\n",
       " ('nt', 891),\n",
       " (\"n',\", 892),\n",
       " ('n’t', 893),\n",
       " ('other', 894),\n",
       " ('rch', 895),\n",
       " ('s.', 896),\n",
       " ('s:\\n', 897),\n",
       " ('sul', 898),\n",
       " ('ting', 899),\n",
       " ('tere', 900),\n",
       " ('uge', 901),\n",
       " ('ues', 902),\n",
       " ('ules', 903),\n",
       " ('uild', 904),\n",
       " ('vid', 905),\n",
       " ('way', 906),\n",
       " ('wice', 907),\n",
       " (\"x',\", 908),\n",
       " ('ymb', 909),\n",
       " ('zer', 910),\n",
       " ('{\\n', 911),\n",
       " ('র\":', 912),\n",
       " ('্র\":', 913),\n",
       " ('▁Q', 914),\n",
       " ('▁`', 915),\n",
       " ('▁x', 916),\n",
       " ('▁}', 917),\n",
       " ('▁Ċ', 918),\n",
       " ('▁—', 919),\n",
       " ('▁pu', 920),\n",
       " ('▁)\\n', 921),\n",
       " ('▁ent', 922),\n",
       " ('▁ĊĠĠ', 923),\n",
       " ('▁output_size', 924),\n",
       " ('▁transform', 925),\n",
       " ('▁two', 926),\n",
       " ('▁twice', 927),\n",
       " ('init', 928),\n",
       " ('inut', 929),\n",
       " ('▁ad', 930),\n",
       " ('▁able', 931),\n",
       " ('▁add', 932),\n",
       " ('en))\\n', 933),\n",
       " ('enote', 934),\n",
       " ('er.\\n', 935),\n",
       " ('▁then', 936),\n",
       " ('▁thing', 937),\n",
       " ('▁thre', 938),\n",
       " ('▁than', 939),\n",
       " ('▁there', 940),\n",
       " ('▁torch', 941),\n",
       " (\"▁'self',\", 942),\n",
       " (\"▁'__\", 943),\n",
       " (\"▁'b',\", 944),\n",
       " (\"▁'weigh\", 945),\n",
       " (\"▁'bias\", 946),\n",
       " (\"▁'Add\", 947),\n",
       " ('ater', 948),\n",
       " ('▁was', 949),\n",
       " ('▁way', 950),\n",
       " ('▁wait', 951),\n",
       " ('ore', 952),\n",
       " ('orch', 953),\n",
       " ('ormal', 954),\n",
       " (\"kens',\", 955),\n",
       " ('rall', 956),\n",
       " ('ract', 957),\n",
       " ('▁cha', 958),\n",
       " ('▁chapter', 959),\n",
       " ('▁clas', 960),\n",
       " ('▁fi', 961),\n",
       " ('▁few', 962),\n",
       " ('▁feature', 963),\n",
       " ('▁later', 964),\n",
       " ('rect', 965),\n",
       " ('repository', 966),\n",
       " ('▁su', 967),\n",
       " ('▁sent', 968),\n",
       " ('▁sample', 969),\n",
       " ('▁sour', 970),\n",
       " ('▁save', 971),\n",
       " ('▁saw', 972),\n",
       " ('▁small', 973),\n",
       " ('▁symb', 974),\n",
       " ('▁in,', 975),\n",
       " ('▁indi', 976),\n",
       " ('▁intere', 977),\n",
       " ('aning', 978),\n",
       " ('ance', 979),\n",
       " ('▁other', 980),\n",
       " ('▁obj', 981),\n",
       " ('▁bo', 982),\n",
       " ('▁blo', 983),\n",
       " ('▁brand', 984),\n",
       " ('▁tokenizer,', 985),\n",
       " ('lly', 986),\n",
       " ('▁nex', 987),\n",
       " ('▁any', 988),\n",
       " ('▁another', 989),\n",
       " (\"▁'Ġad\", 990),\n",
       " (\"▁'Ġand\", 991),\n",
       " (\"▁'Ġa',\", 992),\n",
       " (\"▁'Ġb',\", 993),\n",
       " (\"▁'Ġthe\", 994),\n",
       " (\"▁'Ġdef',\", 995),\n",
       " (\"▁'Ġnumbers',\", 996),\n",
       " ('▁\\'Ġ\"\"\"\\',', 997),\n",
       " (\"▁'Ġoutput',\", 998),\n",
       " (\"▁'Ġ=',\", 999),\n",
       " ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = hf_tokenizer.get_vocab()\n",
    "\n",
    "sorted(vocab.items(), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_m_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
